<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Who’s Tweeting? Trump or Trudeau?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="TweetClassification_files/libs/clipboard/clipboard.min.js"></script>
<script src="TweetClassification_files/libs/quarto-html/quarto.js"></script>
<script src="TweetClassification_files/libs/quarto-html/popper.min.js"></script>
<script src="TweetClassification_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="TweetClassification_files/libs/quarto-html/anchor.min.js"></script>
<link href="TweetClassification_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="TweetClassification_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="TweetClassification_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="TweetClassification_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="TweetClassification_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#tweet-classification-trump-vs.-trudeau" id="toc-tweet-classification-trump-vs.-trudeau" class="nav-link active" data-scroll-target="#tweet-classification-trump-vs.-trudeau">1. Tweet classification: Trump vs.&nbsp;Trudeau</a></li>
  <li><a href="#transforming-our-collected-data" id="toc-transforming-our-collected-data" class="nav-link" data-scroll-target="#transforming-our-collected-data">2. Transforming our collected data</a></li>
  <li><a href="#vectorize-the-tweets" id="toc-vectorize-the-tweets" class="nav-link" data-scroll-target="#vectorize-the-tweets">3. Vectorize the tweets</a></li>
  <li><a href="#training-a-multinomial-naive-bayes-model" id="toc-training-a-multinomial-naive-bayes-model" class="nav-link" data-scroll-target="#training-a-multinomial-naive-bayes-model">4. Training a multinomial naive Bayes model</a></li>
  <li><a href="#evaluating-our-model-using-a-confusion-matrix" id="toc-evaluating-our-model-using-a-confusion-matrix" class="nav-link" data-scroll-target="#evaluating-our-model-using-a-confusion-matrix">5. Evaluating our model using a confusion matrix</a></li>
  <li><a href="#trying-out-another-classifier-linear-svc" id="toc-trying-out-another-classifier-linear-svc" class="nav-link" data-scroll-target="#trying-out-another-classifier-linear-svc">6. Trying out another classifier: Linear SVC</a></li>
  <li><a href="#introspecting-our-top-model" id="toc-introspecting-our-top-model" class="nav-link" data-scroll-target="#introspecting-our-top-model">7. Introspecting our top model</a></li>
  <li><a href="#bonus-can-you-write-a-trump-or-trudeau-tweet" id="toc-bonus-can-you-write-a-trump-or-trudeau-tweet" class="nav-link" data-scroll-target="#bonus-can-you-write-a-trump-or-trudeau-tweet">8. Bonus: can you write a Trump or Trudeau tweet?</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Who’s Tweeting? Trump or Trudeau?</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="tweet-classification-trump-vs.-trudeau" class="level2">
<h2 class="anchored" data-anchor-id="tweet-classification-trump-vs.-trudeau">1. Tweet classification: Trump vs.&nbsp;Trudeau</h2>
<p>
So you think you can classify text? How about tweets? In this notebook, we’ll take a dive into the world of social media text classification by investigating how to properly classify tweets from two prominent North American politicians: Donald Trump and Justin Trudeau.
</p>
<p>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference%2C_February_13%2C_2017.jpg/800px-President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference%2C_February_13%2C_2017.jpg" alt="Donald Trump and Justin Trudeau shaking hands." height="50%" width="50%">
</p>
<p>
<a href="https://commons.wikimedia.org/wiki/File:President_Donald_Trump_and_Prime_Minister_Justin_Trudeau_Joint_Press_Conference,_February_13,_2017.jpg">Photo Credit: Executive Office of the President of the United States</a>
</p>
<p>
Tweets pose specific problems to NLP, including the fact they are shorter texts. There are also plenty of platform-specific conventions to give you hassles: mentions, #hashtags, emoji, links and short-hand phrases (ikr?). Can we overcome those challenges and build a useful classifier for these two tweeters? Yes! Let’s get started.
</p>
<p>
To begin, we will import all the tools we need from scikit-learn. We will need to properly vectorize our data (<code>CountVectorizer</code> and <code>TfidfVectorizer</code>). And we will also want to import some models, including <code>MultinomialNB</code> from the <code>naive_bayes</code> module, <code>LinearSVC</code> from the <code>svm</code> module and <code>PassiveAggressiveClassifier</code> from the <code>linear_model</code> module. Finally, we’ll need <code>sklearn.metrics</code> and <code>train_test_split</code> and <code>GridSearchCV</code> from the <code>model_selection</code> module to evaluate and optimize our model.
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;4&quot;}" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[&quot;sample_code&quot;]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random<span class="op">;</span> random.seed(<span class="dv">53</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Import all we need from sklearn</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer,TfidfVectorizer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="transforming-our-collected-data" class="level2">
<h2 class="anchored" data-anchor-id="transforming-our-collected-data">2. Transforming our collected data</h2>
<p>
To begin, let’s start with a corpus of tweets which were collected in November 2017. They are available in CSV format. We’ll use a Pandas DataFrame to help import the data and pass it to scikit-learn for further processing.
</p>
<p>
Since the data has been collected via the Twitter API and not split into test and training sets, we’ll need to do this. Let’s use <code>train_test_split()</code> with <code>random_state=53</code> and a test size of 0.33, just as we did in the DataCamp course. This will ensure we have enough test data and we’ll get the same results no matter where or when we run this code.
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;11&quot;}" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[&quot;sample_code&quot;]" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>tweet_df <span class="op">=</span> pd.read_csv(<span class="st">'datasets/tweets.csv'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create target</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> tweet_df.author</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Split training and testing data</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(tweet_df.status,y,test_size <span class="op">=</span> <span class="fl">.33</span>, random_state<span class="op">=</span><span class="dv">53</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="vectorize-the-tweets" class="level2">
<h2 class="anchored" data-anchor-id="vectorize-the-tweets">3. Vectorize the tweets</h2>
<p>
We have the training and testing data all set up, but we need to create vectorized representations of the tweets in order to apply machine learning.
</p>
<p>
To do so, we will utilize the <code>CountVectorizer</code> and <code>TfidfVectorizer</code> classes which we will first need to fit to the data.
</p>
<p>
Once this is complete, we can start modeling with the new vectorized tweets!
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;18&quot;}" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-tags="[&quot;sample_code&quot;]" data-execution_count="6">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize count vectorizer</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>count_vectorizer <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>,min_df<span class="op">=</span><span class="fl">0.05</span>,max_df<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create count train and test variables</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>count_train <span class="op">=</span> count_vectorizer.fit_transform(X_train)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>count_test <span class="op">=</span> count_vectorizer.transform(X_test)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize tfidf vectorizer</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>,min_df<span class="op">=</span><span class="fl">0.05</span>,max_df<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tfidf train and test variables</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>tfidf_train <span class="op">=</span> tfidf_vectorizer.fit_transform(X_train)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>tfidf_test <span class="op">=</span> tfidf_vectorizer.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-a-multinomial-naive-bayes-model" class="level2">
<h2 class="anchored" data-anchor-id="training-a-multinomial-naive-bayes-model">4. Training a multinomial naive Bayes model</h2>
<p>
Now that we have the data in vectorized form, we can train the first model. Investigate using the Multinomial Naive Bayes model with both the <code>CountVectorizer</code> and <code>TfidfVectorizer</code> data. Which do will perform better? How come?
</p>
<p>
To assess the accuracies, we will print the test sets accuracy scores for both models.
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;25&quot;}" data-tags="[&quot;sample_code&quot;]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a MulitnomialNB model</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>tfidf_nb <span class="op">=</span> MultinomialNB()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>tfidf_nb.fit(tfidf_train,y_train)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run predict on your TF-IDF test data to get your predictions</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>tfidf_nb_pred <span class="op">=</span> tfidf_nb.predict(tfidf_test)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the accuracy of your predictions</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>tfidf_nb_score <span class="op">=</span> metrics.accuracy_score(y_test,tfidf_nb_pred)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a MulitnomialNB model</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>count_nb <span class="op">=</span> MultinomialNB()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>count_nb.fit(count_train,y_train)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Run predict on your count test data to get your predictions</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>count_nb_pred <span class="op">=</span> count_nb.predict(count_test)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the accuracy of your predictions</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>count_nb_score <span class="op">=</span> metrics.accuracy_score(y_test,count_nb_pred)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'NaiveBayes Tfidf Score: '</span>, tfidf_nb_score)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'NaiveBayes Count Score: '</span>, count_nb_score)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>NaiveBayes Tfidf Score:  0.803030303030303
NaiveBayes Count Score:  0.7954545454545454</code></pre>
</div>
</div>
</section>
<section id="evaluating-our-model-using-a-confusion-matrix" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-our-model-using-a-confusion-matrix">5. Evaluating our model using a confusion matrix</h2>
<p>
We see that the TF-IDF model performs better than the count-based approach. Based on what we know from the NLP fundamentals course, why might that be? We know that TF-IDF allows unique tokens to have a greater weight - perhaps tweeters are using specific important words that identify them! Let’s continue the investigation.
</p>
<p>
For classification tasks, an accuracy score doesn’t tell the whole picture. A better evaluation can be made if we look at the confusion matrix, which shows the number correct and incorrect classifications based on each class. We can use the metrics, True Positives, False Positives, False Negatives, and True Negatives, to determine how well the model performed on a given class. How many times was Trump misclassified as Trudeau?
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;32&quot;}" data-tags="[&quot;sample_code&quot;]" data-execution_count="10">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets.helper_functions <span class="im">import</span> plot_confusion_matrix</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the confusion matrices for the tfidf_nb model and count_nb models</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>tfidf_nb_cm <span class="op">=</span> metrics.confusion_matrix(y_test,tfidf_nb_pred,labels<span class="op">=</span>[<span class="st">'Donald J. Trump'</span>,<span class="st">'Justin Trudeau'</span>])</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>count_nb_cm <span class="op">=</span> metrics.confusion_matrix(y_test,count_nb_pred,labels<span class="op">=</span>[<span class="st">'Donald J. Trump'</span>,<span class="st">'Justin Trudeau'</span>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the tfidf_nb_cm confusion matrix</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(tfidf_nb_cm, classes<span class="op">=</span>[<span class="st">'Donald J. Trump'</span>,<span class="st">'Justin Trudeau'</span>], title<span class="op">=</span><span class="st">"TF-IDF NB Confusion Matrix"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the count_nb_cm confusion matrix without overwriting the first plot </span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(count_nb_cm, classes<span class="op">=</span>[<span class="st">'Donald J. Trump'</span>,<span class="st">'Justin Trudeau'</span>], title<span class="op">=</span><span class="st">"Count NB Confusion Matrix"</span>, figure<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion matrix, without normalization
Confusion matrix, without normalization</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TweetClassification_files/figure-html/cell-6-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="TweetClassification_files/figure-html/cell-6-output-3.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="trying-out-another-classifier-linear-svc" class="level2">
<h2 class="anchored" data-anchor-id="trying-out-another-classifier-linear-svc">6. Trying out another classifier: Linear SVC</h2>
<p>
So the Bayesian model only has one prediction difference between the TF-IDF and count vectorizers – fairly impressive! Interestingly, there is some confusion when the predicted label is Trump but the actual tweeter is Trudeau. If we were going to use this model, we would want to investigate what tokens are causing the confusion in order to improve the model.
</p>
<p>
Now that we’ve seen what the Bayesian model can do, how about trying a different approach? <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html">LinearSVC</a> is another popular choice for text classification. Let’s see if using it with the TF-IDF vectors improves the accuracy of the classifier!
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;39&quot;}" data-tags="[&quot;sample_code&quot;]" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a LinearSVM model</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>tfidf_svc <span class="op">=</span> LinearSVC()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>tfidf_svc.fit(tfidf_train,y_train)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run predict on your tfidf test data to get your predictions</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>tfidf_svc_pred <span class="op">=</span> tfidf_svc.predict(tfidf_test)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate your accuracy using the metrics module</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>tfidf_svc_score <span class="op">=</span> metrics.accuracy_score(y_test,tfidf_svc_pred)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LinearSVC Score:   </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> tfidf_svc_score)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the confusion matrices for the tfidf_svc model</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>svc_cm <span class="op">=</span> metrics.confusion_matrix(y_test,tfidf_svc_pred)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the confusion matrix using the plot_confusion_matrix function</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(svc_cm, classes<span class="op">=</span>[<span class="st">'Donald J. Trump'</span>,<span class="st">'Justin Trudeau'</span>], title<span class="op">=</span><span class="st">"TF-IDF LinearSVC Confusion Matrix"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>LinearSVC Score:   0.841
Confusion matrix, without normalization</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="TweetClassification_files/figure-html/cell-7-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="introspecting-our-top-model" class="level2">
<h2 class="anchored" data-anchor-id="introspecting-our-top-model">7. Introspecting our top model</h2>
<p>
Wow, the LinearSVC model is even better than the Multinomial Bayesian one. Nice work! Via the confusion matrix we can see that, although there is still some confusion where Trudeau’s tweets are classified as Trump’s, the False Positive rate is better than the previous model. So, we have a performant model, right?
</p>
<p>
We might be able to continue tweaking and improving all of the previous models by learning more about parameter optimization or applying some better preprocessing of the tweets.
</p>
<p>
Now let’s see what the model has learned. Using the LinearSVC Classifier with two classes (Trump and Trudeau) we can sort the features (tokens), by their weight and see the most important tokens for both Trump and Trudeau. What are the most Trump-like or Trudeau-like words? Did the model learn something useful to distinguish between these two men?
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;46&quot;}" data-tags="[&quot;sample_code&quot;]" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets.helper_functions <span class="im">import</span> plot_and_return_top_features</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Import pprint from pprint</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the top features using the plot_and_return_top_features function and your top model and tfidf vectorizer</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>top_features <span class="op">=</span> plot_and_return_top_features(tfidf_svc,tfidf_vectorizer)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># pprint the top features</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>pprint(top_features)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="TweetClassification_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[(-0.39598614237287494, 'great'),
 (-0.24645914582625575, 'thank'),
 (0.06257683513498034, 'president'),
 (0.48212854678591816, 'https'),
 (0.5960413132193568, 'vietnam'),
 (0.615552965005265, 'amp'),
 (0.7725767667231686, 'le'),
 (0.8213759619789418, 'les'),
 (0.8286559388239808, 'today'),
 (1.1869091061283303, 'du'),
 (1.31435432871772, 'pour'),
 (1.4122491299028315, 'nous'),
 (1.4612822126886333, 'rt'),
 (1.4991802679197872, 'et'),
 (1.5056392366848128, 'la'),
 (1.6568001495404134, 'canada')]</code></pre>
</div>
</div>
</section>
<section id="bonus-can-you-write-a-trump-or-trudeau-tweet" class="level2">
<h2 class="anchored" data-anchor-id="bonus-can-you-write-a-trump-or-trudeau-tweet">8. Bonus: can you write a Trump or Trudeau tweet?</h2>
<p>
So, what did our model learn? It seems like it learned that Trudeau tweets in French!
</p>
<p>
I challenge you to write your own tweet using the knowledge gained to trick the model! Use the printed list or plot above to make some inferences about what words will classify your text as Trump or Trudeau. Can you fool the model into thinking you are Trump or Trudeau?
</p>
<p>
If you can write French, feel free to make your Trudeau-impersonation tweet in French! As you may have noticed, these French words are common words, or, “stop words”. You could remove both English and French stop words from the tweets as a preprocessing step, but that might decrease the accuracy of the model because Trudeau is the only French-speaker in the group. If you had a dataset with more than one French speaker, this would be a useful preprocessing step.
</p>
<p>
Future work on this dataset could involve:
</p>
<ul>
<li>
Add extra preprocessing (such as removing URLs or French stop words) and see the effects
</li>
<li>
Use GridSearchCV to improve both your Bayesian and LinearSVC models by finding the optimal parameters
</li>
<li>
Introspect your Bayesian model to determine what words are more Trump- or Trudeau- like
</li>
<li>
Add more recent tweets to your dataset using tweepy and retrain
</li>
</ul>
<p>
Good luck writing your impersonation tweets – feel free to share them on Twitter!
</p>
<div class="cell" data-dc="{&quot;key&quot;:&quot;53&quot;}" data-tags="[&quot;sample_code&quot;]" data-execution_count="16">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write two tweets as strings, one which you want to classify as Trump and one as Trudeau</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>trump_tweet <span class="op">=</span> <span class="st">"Make America Great Again"</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>trudeau_tweet <span class="op">=</span> <span class="st">"Beautiful day in Canada today"</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorize each tweet using the TF-IDF vectorizer's transform method</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: `transform` needs the string in a list object (i.e. [trump_tweet])</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>trump_tweet_vectorized <span class="op">=</span> tfidf_vectorizer.transform([trump_tweet])</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>trudeau_tweet_vectorized <span class="op">=</span> tfidf_vectorizer.transform([trudeau_tweet])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the predict method on your vectorized tweets</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>trump_tweet_pred <span class="op">=</span> tfidf_svc.predict(trump_tweet_vectorized)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>trudeau_tweet_pred <span class="op">=</span> tfidf_svc.predict(trudeau_tweet_vectorized)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted Trump tweet"</span>, trump_tweet_pred)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted Trudeau tweet"</span>, trudeau_tweet_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted Trump tweet ['Donald J. Trump']
Predicted Trudeau tweet ['Justin Trudeau']</code></pre>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>