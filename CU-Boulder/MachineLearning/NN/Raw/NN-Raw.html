<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Professor Ami Gates">

<title>Gates Neural Networks Raw-code</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="NN-Raw_files/libs/clipboard/clipboard.min.js"></script>
<script src="NN-Raw_files/libs/quarto-html/quarto.js"></script>
<script src="NN-Raw_files/libs/quarto-html/popper.min.js"></script>
<script src="NN-Raw_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="NN-Raw_files/libs/quarto-html/anchor.min.js"></script>
<link href="NN-Raw_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="NN-Raw_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="NN-Raw_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="NN-Raw_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="NN-Raw_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#neural-networks-sample-code-from-machine-learning-course---dr.-gates-full-raw-unedited-code" id="toc-neural-networks-sample-code-from-machine-learning-course---dr.-gates-full-raw-unedited-code" class="nav-link active" data-scroll-target="#neural-networks-sample-code-from-machine-learning-course---dr.-gates-full-raw-unedited-code">Neural Networks sample code (from <strong>Machine Learning Course</strong>) - Dr.&nbsp;Gates’ full, raw (unedited) code</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Gates Neural Networks Raw-code</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Professor Ami Gates </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="neural-networks-sample-code-from-machine-learning-course---dr.-gates-full-raw-unedited-code" class="level1">
<h1>Neural Networks sample code (from <a href="../CUB-ML.md"><strong>Machine Learning Course</strong></a>) - Dr.&nbsp;Gates’ full, raw (unedited) code</h1>
<p>Reference: Professor Ami Gates, Dept. Applied Math, Data Science, University of Colorado</p>
<p><a href="https://gatesboltonanalytics.com/">Dr.&nbsp;Gates’ Website</a></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">Created on Thu Nov  3 12:50:30 2022</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">@author: profa</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud, STOPWORDS</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.probability <span class="im">import</span> FreqDist</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">## For Stemming</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> PorterStemmer</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize, word_tokenize</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.wordnet <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('stopwords')</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">################</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co">## ANN - CNN - RNN</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co">## Movies Dataset</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co">## https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">####  Gates</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co">##################################################################################</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> <span class="st">"C:/Users/profa/Desktop/UCB/NNCSCI5922/Code/IMDB_Movie_Datasets_Train_Test_Valid/"</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>TrainData <span class="op">=</span> pd.read_csv(<span class="bu">str</span>(path<span class="op">+</span><span class="st">"Train.csv"</span>))</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co"># print(TrainData.shape)</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TrainData.head(<span class="dv">10</span>))</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co"># print(type(TrainData))</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>TestData <span class="op">=</span> pd.read_csv(<span class="bu">str</span>(path<span class="op">+</span><span class="st">"Test.csv"</span>))</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TestData.shape)</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>TestData.head(<span class="dv">10</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>ValidData <span class="op">=</span> pd.read_csv(<span class="bu">str</span>(path<span class="op">+</span><span class="st">"Valid.csv"</span>))</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">#print(ValidData.shape)</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>ValidData.head(<span class="dv">10</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">## Concat requires a list</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">## Place all data from above into one dataframe</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>FullDataset<span class="op">=</span>pd.concat([TrainData,TestData, ValidData])</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co">#print(FullDataset.shape)</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="co">###################################################</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co">## The following code represents a more</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="co">## hands-on option for tokenizing/vectorizing</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co">## the data. I am leaving it here as a reference</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="co">## BELOW this comment area - CountVectorizer is used</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="co">## to perform the same tasks. </span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="co">###########################################################</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co"># def remove_html(text):</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="co">#     bs = BeautifulSoup(text, "html.parser")</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="co">#     return ' ' + bs.get_text() + ' '</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="co"># def keep_only_letters(text):</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="co">#     text=re.sub(r'[^a-zA-Z\s]',' ',text)</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="co">#     return text</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="co"># def convert_to_lowercase(text):</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="co">#     return text.lower()</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="co"># def remove_small_words(text):</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="co">#     text=" ".join(word for word in text.split() if len(word)&gt;=3)</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="co">#     return text</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co"># def clean_reviews(text):</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="co">#     text = remove_html(text)</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="co">#     text = keep_only_letters(text)</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="co">#     text = convert_to_lowercase(text)</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="co">#     text = remove_small_words(text)</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="co">#     return text</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="co"># def returnNewDF(oldDF):</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="co">#     newDF=pd.DataFrame(columns=["key", "value"])</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="co">#     if not oldDF["key"] in stopwords.words():</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="co">#         newDF["key"] = oldDF["value"]</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="co">#     return newDF</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="co"># TrainData["text"] = TrainData["text"].apply(lambda text: clean_reviews(text))</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="co"># print(TrainData.head(30))</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="co"># TestData["text"] = TestData["text"].apply(lambda text: clean_reviews(text))</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="co"># print(TestData.head(30))</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co"># ValidData["text"] = ValidData["text"].apply(lambda text: clean_reviews(text))</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="co"># print(ValidData.head(30))</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="co"># ## Create Vocab</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="co"># counter = Counter([words for reviews in TrainData["text"] for words in reviews.split()])</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="co"># df = pd.DataFrame()</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="co"># df['key'] = counter.keys()</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="co"># df['value'] = counter.values()</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="co"># df.sort_values(by='value', ascending=False, inplace=True)</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="co"># print(df.head(10))</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="co"># ## Drop all the stopwords - OPTIONAL - .............</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="co"># #df = df[~df.key.isin(stopwords.words())]</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="co"># #print(stopwords.words())</span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################################</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="co">## Clean Up TrainData</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="co">## Get the vocab</span></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TrainData.head())</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing iterating the columns </span></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> TrainData.columns: </span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(col) </span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="co">## Check Content   --------------------</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TrainData["text"])</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TrainData["label"]) ##0 is negative, 1 is positive</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="co">### Tokenize and Vectorize </span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="co">## Create the list </span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="co">## Keep the labels</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>ReviewsLIST<span class="op">=</span>[]  <span class="co">## from the text column</span></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>LabelLIST<span class="op">=</span>[]    </span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> nextreview, nextlabel <span class="kw">in</span> <span class="bu">zip</span>(TrainData[<span class="st">"text"</span>], TrainData[<span class="st">"label"</span>]):</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>    ReviewsLIST.append(nextreview)</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>    LabelLIST.append(nextlabel)</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"A Look at some of the reviews list is:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ReviewsLIST[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"A Look at some of the labels list is:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(LabelLIST[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="co">######################################</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="co">## Optional - for Stemming the data</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="co">################################################</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="co">## Instantiate it</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>A_STEMMER<span class="op">=</span>PorterStemmer()</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="co">## test it</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A_STEMMER.stem(<span class="st">"fishers"</span>))</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="co">#----------------------------------------</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="co"># Use NLTK's PorterStemmer in a function - DEFINE THE FUNCTION</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="co">#-------------------------------------------------------</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> MY_STEMMER(str_input):</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Only use letters, no punct, no nums, make lowercase...</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> re.sub(<span class="vs">r"[^A-Za-z\-]"</span>, <span class="st">" "</span>, str_input).lower().split()</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [A_STEMMER.stem(word) <span class="cf">for</span> word <span class="kw">in</span> words] <span class="co">## Use the Stemmer...</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> words</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################</span></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a><span class="co">##  Build the labeled dataframe</span></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="co">##  Get the Vocab  - here keeping top 10,000</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="co">######################################################</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="co">### Vectorize</span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="co">## Instantiate your CV</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>MyCountV<span class="op">=</span>CountVectorizer(</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>        <span class="bu">input</span><span class="op">=</span><span class="st">"content"</span>,  </span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>        lowercase<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>        <span class="co">#stop_words = "english", ## This is optional</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>        <span class="co">#tokenizer=MY_STEMMER, ## Stemming is optional</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>        max_features<span class="op">=</span><span class="dv">11000</span>  <span class="co">## This can be updated</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="co">## Use your CV </span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>MyDTM <span class="op">=</span> MyCountV.fit_transform(ReviewsLIST)  <span class="co"># create a sparse matrix</span></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="co">#print(type(MyDTM))</span></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>ColumnNames<span class="op">=</span>MyCountV.get_feature_names() <span class="co">## This is the vocab</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a><span class="co">#print(ColumnNames)</span></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="co">#print(type(ColumnNames))</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="co">## Here we can clean up the columns</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="co">## Build the data frame</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>MyDTM_DF<span class="op">=</span>pd.DataFrame(MyDTM.toarray(),columns<span class="op">=</span>ColumnNames)</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a><span class="co">## Convert the labels from list to df</span></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>Labels_DF <span class="op">=</span> pd.DataFrame(LabelLIST,columns<span class="op">=</span>[<span class="st">'LABEL'</span>])</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="co">## Check your new DF and you new Labels df:</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Labels\n")</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Labels_DF)</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a><span class="co"># print("DF\n")</span></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(MyDTM_DF.iloc[:,<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(MyDTM_DF.shape) <span class="co">## 40,000 by 11000</span></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a><span class="co">############################################</span></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="co">##  Remove any columns that contain numbers</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="co">##  Remove columns with words not the size </span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="co">##  you want. For example, words&lt;3 chars</span></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="co">##############################################</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a><span class="co">##------------------------------------------------------</span></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a><span class="co">### DEFINE A FUNCTION that returns True if numbers</span></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="co">##  are in a string </span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Logical_Numbers_Present(anyString):</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">any</span>(char.isdigit() <span class="cf">for</span> char <span class="kw">in</span> anyString)</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a><span class="co">##----------------------------------------------------</span></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> nextcol <span class="kw">in</span> MyDTM_DF.columns:</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(nextcol)</span></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Remove unwanted columns</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Result=str.isdigit(nextcol) ## Fast way to check numbers</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(Result)</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>    <span class="co">##-------------call the function -------</span></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>    LogResult<span class="op">=</span>Logical_Numbers_Present(nextcol)</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(LogResult)</span></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>    <span class="co">## The above returns a logical of True or False</span></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>    <span class="co">## The following will remove all columns that contains numbers</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(LogResult<span class="op">==</span><span class="va">True</span>):</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(LogResult)</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(nextcol)</span></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>        MyDTM_DF<span class="op">=</span>MyDTM_DF.drop([nextcol], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>    <span class="co">## The following will remove any column with name</span></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>    <span class="co">## of 3 or smaller - like "it" or "of" or "pre".</span></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>    <span class="co">##print(len(nextcol))  ## check it first</span></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>    <span class="co">## </span><span class="al">NOTE</span><span class="co">: You can also use this code to CONTROL</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>    <span class="co">## the words in the columns. For example - you can</span></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>    <span class="co">## have only words between lengths 5 and 9. </span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>    <span class="co">## In this case, we remove columns with words &lt;= 3.</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span>(<span class="bu">len</span>(<span class="bu">str</span>(nextcol))<span class="op">&lt;</span><span class="dv">3</span>):</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(nextcol)</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>        MyDTM_DF<span class="op">=</span>MyDTM_DF.drop([nextcol], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a><span class="co">##Save original DF - without the lables</span></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>My_Orig_DF<span class="op">=</span>MyDTM_DF</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="co">#print(My_Orig_DF)</span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="co">## Now - let's create a complete and labeled</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="co">## dataframe:</span></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> [Labels_DF, MyDTM_DF]</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dfs)</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"shape of labels</span><span class="ch">\n</span><span class="st">"</span>, Labels_DF)</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"shape of data</span><span class="ch">\n</span><span class="st">"</span>, MyDTM_DF)</span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>Final_DF_Labeled <span class="op">=</span> pd.concat(dfs,axis<span class="op">=</span><span class="dv">1</span>, join<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="co">## DF with labels</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Final_DF_Labeled.iloc[:, <span class="dv">0</span>:<span class="dv">2</span>])</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Final_DF_Labeled.shape)</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="co">################################################</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="co">## FYI</span></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a><span class="co">## An alternative option for most frequent 10,000 words </span></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="co">## Not needed here as we used CountVectorizer with option</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="co">## max_features</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="co"># print (df.shape[0])</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="co"># print (df[:10000].value.sum()/df.value.sum())</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="co"># top_words = list(df[:10000].key.values)</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="co"># print(top_words)</span></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="co"># ## Example using index</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="co"># index = top_words.index("humiliating")</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="co"># print(index)</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="co">##############################################</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="co">## Create list of all words</span></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Final_DF_Labeled.columns[<span class="dv">0</span>])</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>NumCols<span class="op">=</span>Final_DF_Labeled.shape[<span class="dv">1</span>]</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(NumCols)</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(<span class="bu">list</span>(Final_DF_Labeled.columns)))</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a>top_words<span class="op">=</span><span class="bu">list</span>(Final_DF_Labeled.columns[<span class="dv">1</span>:NumCols<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="co">## Exclude the Label</span></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_words[<span class="dv">0</span>])</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_words[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(top_words))</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_words.index(<span class="st">"aamir"</span>)) <span class="co">## index 0 in top_words</span></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(top_words.index(<span class="st">"zucco"</span>)) <span class="co">#index NumCols - 2 in top_words</span></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="co">## Encoding the data</span></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Encode(review):</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> review.split()</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>   <span class="co"># print(words)</span></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(words) <span class="op">&gt;</span> <span class="dv">500</span>:</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> words[:<span class="dv">500</span>]</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(words)</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>    encoding <span class="op">=</span> []</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>            index <span class="op">=</span> top_words.index(word)</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>            index <span class="op">=</span> (NumCols <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>        encoding.append(index)</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="bu">len</span>(encoding) <span class="op">&lt;</span> <span class="dv">500</span>:</span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>        encoding.append(NumCols)</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> encoding</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="co">##-------------------------------------------------------</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="co">## Test the code to assure that it is</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="co">## doing what you think it should </span></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>result1 <span class="op">=</span> Encode(<span class="st">"aaron aamir abbey abbott abilities zucco "</span>)</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result1)</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a>result2 <span class="op">=</span> Encode(<span class="st">"york young younger youngest youngsters youth youthful youtube zach zane zany zealand zellweger"</span>)</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result2)</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(result2)) <span class="co">## Will be 500 because we set it that way above</span></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="co">##-----------------------------------------------------------</span></span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="co">###################################</span></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a><span class="co">## Now we are ready to encode all of our</span></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a><span class="co">## reviews - which are called "text" in</span></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="co">## our dataset. </span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="co"># Using vocab from above i -  convert reviews (text) into numerical form </span></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="co"># Replacing each word with its corresponding integer index value from the </span></span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="co"># vocabulary. Words not in the vocab will</span></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="co"># be assigned  as the max length of the vocab + 1 </span></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a><span class="co">## ########################################################</span></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode our training and testing datasets</span></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a><span class="co"># with same vocab. </span></span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TestData.head(<span class="dv">10</span>))</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TestData.shape)</span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TrainData.shape)</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a><span class="co">############### Final Training and Testing data and labels-----------------</span></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a>training_data <span class="op">=</span> np.array([Encode(review) <span class="cf">for</span> review <span class="kw">in</span> TrainData[<span class="st">"text"</span>]])</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_data[<span class="dv">20</span>])</span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_data.shape)</span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>testing_data <span class="op">=</span> np.array([Encode(review) <span class="cf">for</span> review <span class="kw">in</span> TestData[<span class="st">'text'</span>]])</span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(testing_data[<span class="dv">20</span>])</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>validation_data <span class="op">=</span> np.array([Encode(review) <span class="cf">for</span> review <span class="kw">in</span> ValidData[<span class="st">'text'</span>]])</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (training_data.shape, testing_data.shape)</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a><span class="co">## Prepare the labels if they are not already 0 and 1. In our case they are</span></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a><span class="co">## so these lines are commented out and just FYI</span></span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a><span class="co">#train_labels = [1 if label=='positive' else 0 for sentiment in TrainData['label']]</span></span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a><span class="co">#test_labels = [1 if label=='positive' else 0 for sentiment in TestData['label']]</span></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a>train_labels <span class="op">=</span> np.array([TrainData[<span class="st">'label'</span>]])</span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>train_labels<span class="op">=</span>train_labels.T</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_labels.shape)</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> np.array([TestData[<span class="st">'label'</span>]])</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a>test_labels<span class="op">=</span>test_labels.T</span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_labels.shape)</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="co">###############################</span></span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="co">## ANN</span></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a><span class="co">#################################</span></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="co">## Simple Dense NN for sentiment analysis (classification 0 neg, 1 pos)</span></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="co"># First layer: Embedding Layer (Keras Embedding Layer) that will learn embeddings </span></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a><span class="co"># for different words .</span></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="co">## RE: ## https://keras.io/api/layers/core_layers/embedding/</span></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="co">## input_dim: Integer. Size of the vocabulary</span></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="co">## input_length: Length of input sequences, when it is constant.</span></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(NumCols)   </span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> NumCols <span class="op">+</span> <span class="dv">1</span> </span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow</span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Activation</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a> <span class="co">#https://www.tensorflow.org/api_docs/python/tf/keras/Input</span></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> tensorflow.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">500</span>))</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a> <span class="co">#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding</span></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Embedding(input_dim<span class="op">=</span>input_dim, output_dim<span class="op">=</span><span class="dv">64</span>, input_length<span class="op">=</span><span class="dv">500</span>)(input_data)</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="co">##input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1</span></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a><span class="co">## Good tutorial for this concept:</span></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a>    <span class="co">## https://medium.com/analytics-vidhya/understanding-embedding-layer-in-keras-bbe3ff1327ce</span></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a> <span class="co">#output_dim: Integer. Dimension of the dense embedding.</span></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a> <span class="co"># output_dim: This is the size of the vector space in which words will be embedded. </span></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a> <span class="co">#It defines the size of the output vectors from this layer for each word. </span></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a> <span class="co"># For example, it could be 32 or 100 or even larger.</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a> <span class="co">#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="co">#  In an embedding, words are represented by dense vectors where a vector represents </span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a><span class="co">#  the projection of the word into a continuous vector space.</span></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="co"># The position of a word within the vector space is learned </span></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="co"># from text and is based on the words that surround the word when it is used.</span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="co"># The position of a word in the learned vector space is referred to as its embedding.</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="co"># data = tensorflow.keras.layers.Flatten()(data)</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a> <span class="co">#Dense layers require inputs as (batch_size, input_size) </span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">16</span>)(data)</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'relu'</span>)(data)</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="co">#data = tensorflow.keras.layers.Dropout(0.5)(data)</span></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">8</span>)(data)</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'relu'</span>)(data)</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="co">#data = tensorflow.keras.layers.Dropout(0.5)(data)</span></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">4</span>)(data)</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'sigmoid'</span>)(data)</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="co">#data = tensorflow.keras.layers.Dropout(0.5)(data)</span></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">1</span>)(data)</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'sigmoid'</span>)(data)</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tensorflow.keras.models.Model(inputs<span class="op">=</span>input_data, outputs<span class="op">=</span>output_data)</span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_data[<span class="dv">0</span>:<span class="dv">3</span>, <span class="dv">0</span>:<span class="dv">3</span>])</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_data.shape)</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>model.fit(training_data, train_labels, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">256</span>, validation_data<span class="op">=</span>(testing_data, test_labels))</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="co">###################################</span></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="co">## RNN</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################</span></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Activation</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> tensorflow.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">500</span>))</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Embedding(input_dim<span class="op">=</span>input_dim, output_dim<span class="op">=</span><span class="dv">32</span>, input_length<span class="op">=</span><span class="dv">500</span>)(input_data)</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a> <span class="co">#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional</span></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Bidirectional(tensorflow.keras.layers.SimpleRNN(<span class="dv">50</span>))(data)</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">1</span>)(data)</span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'sigmoid'</span>)(data)</span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tensorflow.keras.models.Model(inputs<span class="op">=</span>input_data, outputs<span class="op">=</span>output_data)</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a>model.fit(training_data, train_labels, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">256</span>, validation_data<span class="op">=</span>(testing_data, test_labels))</span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="co">############################################</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a><span class="co">## LSTM</span></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow</span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Activation</span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> tensorflow.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">500</span>))</span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Embedding(input_dim<span class="op">=</span>input_dim, output_dim<span class="op">=</span><span class="dv">32</span>, input_length<span class="op">=</span><span class="dv">500</span>)(input_data)</span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Bidirectional(tensorflow.keras.layers.LSTM(<span class="dv">50</span>))(data)</span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">1</span>)(data)</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'sigmoid'</span>)(data)</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tensorflow.keras.models.Model(inputs<span class="op">=</span>input_data, outputs<span class="op">=</span>output_data)</span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a>model.fit(training_data, train_labels, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">128</span>, validation_data<span class="op">=</span>(testing_data, test_labels))</span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a><span class="co">######################################</span></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a><span class="co">## CNN</span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a><span class="co">########################################</span></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow</span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> tensorflow.keras.layers.Input(shape<span class="op">=</span>(<span class="dv">500</span>))</span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Embedding(input_dim<span class="op">=</span>input_dim, output_dim<span class="op">=</span><span class="dv">32</span>, input_length<span class="op">=</span><span class="dv">500</span>)(input_data)</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Conv1D(<span class="dv">50</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(data)</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>)(data)</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Conv1D(<span class="dv">40</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(data)</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>)(data)</span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Conv1D(<span class="dv">30</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(data)</span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>)(data)</span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Conv1D(<span class="dv">30</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(data)</span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>)(data)</span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Flatten()(data)</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">20</span>)(data)</span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dropout(<span class="fl">0.5</span>)(data)</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tensorflow.keras.layers.Dense(<span class="dv">1</span>)(data)</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>output_data <span class="op">=</span> tensorflow.keras.layers.Activation(<span class="st">'sigmoid'</span>)(data)</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tensorflow.keras.models.Model(inputs<span class="op">=</span>input_data, outputs<span class="op">=</span>output_data)</span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>, metrics<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>model.fit(training_data, train_labels, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">256</span>, validation_data<span class="op">=</span>(testing_data, test_labels))</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evaluate model on test data"</span>)</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.evaluate(testing_data, test_labels, batch_size<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test loss, test acc:"</span>, results)</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a prediction using model.predict() </span></span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a><span class="co"># and calculate it's shape:</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Generate a prediction"</span>)</span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> model.predict(testing_data)</span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(prediction)</span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"prediction shape:"</span>, prediction.shape)</span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(prediction))</span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a>prediction[prediction <span class="op">&gt;</span> <span class="fl">.5</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a>prediction[prediction <span class="op">&lt;=</span> <span class="fl">.5</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(prediction)</span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(prediction, test_labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>