<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Professor Ami Gates">

<title>Gates Decision Trees Raw-code-Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Python-DecisionTrees-Raw_files/libs/clipboard/clipboard.min.js"></script>
<script src="Python-DecisionTrees-Raw_files/libs/quarto-html/quarto.js"></script>
<script src="Python-DecisionTrees-Raw_files/libs/quarto-html/popper.min.js"></script>
<script src="Python-DecisionTrees-Raw_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Python-DecisionTrees-Raw_files/libs/quarto-html/anchor.min.js"></script>
<link href="Python-DecisionTrees-Raw_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Python-DecisionTrees-Raw_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Python-DecisionTrees-Raw_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Python-DecisionTrees-Raw_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Python-DecisionTrees-Raw_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#decision-trees-and-other-supervised-learning-in-python---dr.-gates-full-raw-unedited-code" id="toc-decision-trees-and-other-supervised-learning-in-python---dr.-gates-full-raw-unedited-code" class="nav-link active" data-scroll-target="#decision-trees-and-other-supervised-learning-in-python---dr.-gates-full-raw-unedited-code">Decision Trees (and other supervised learning) in Python - Dr.&nbsp;Gates’ full, raw (unedited) code</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Gates Decision Trees Raw-code-Python</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Professor Ami Gates </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="decision-trees-and-other-supervised-learning-in-python---dr.-gates-full-raw-unedited-code" class="level1">
<h1>Decision Trees (and other supervised learning) in Python - Dr.&nbsp;Gates’ full, raw (unedited) code</h1>
<p>Reference: Professor Ami Gates, Dept. Applied Math, Data Science, University of Colorado</p>
<p><a href="https://gatesboltonanalytics.com/">Dr.&nbsp;Gates’ Website</a></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">###############</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">## Supervised Learning Example Code</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">## Naive Bayes</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">## Bernoulli</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Note 1: It is better to make your own data and update</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">## the code for YOUR data.</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">## Note 2: This code focusses on text data but can easily</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">## be updated for record data. </span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">## Datasets (corpus) can be found HERE:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">## DOG</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">## https://drive.google.com/drive/folders/1UZSCzKyTKOOKqD2dPrmjIxS_IA9nnsDi?usp=sharing</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">## HIKE</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">## https://drive.google.com/drive/folders/141yq5AosVWiQSgk0fixcOn9RWIWmj2DH?usp=sharing</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">## Note that the other datasets for Record data are below in that section....</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">######################################</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">## Textmining Naive Bayes Example</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re  </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer, TfidfVectorizer</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.probability <span class="im">import</span> FreqDist</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co">## For Stemming</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize, word_tokenize</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="im">as</span> rd</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> BernoulliNB</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install python-graphviz</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co">## restart kernel (click the little red x next to the Console)</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">#from mpl_toolkits.mplot3d import Axes3D </span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install python-graphviz</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co">## restart kernel (click the little red x next to the Console)</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> export_graphviz</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.externals.six import StringIO  </span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image  </span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install pydotplus</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pydotplus</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="co">#from nltk.stem import WordNetLemmatizer </span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="co">#LEMMER = WordNetLemmatizer() </span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="co">##############################################################</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="co">##       A Stemmer is a function that truncates and combines</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="co">##       words such as hikings and hikers. </span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>STEMMER<span class="op">=</span>PorterStemmer()</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(STEMMER.stem(<span class="st">"fishings"</span>))</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Use NLTK's PorterStemmer in a function</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> MY_STEMMER(str_input):   <span class="co">#I like dogs a lot111 !!"</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> re.sub(<span class="vs">r"[^A-Za-z\-]"</span>, <span class="st">" "</span>, str_input).lower().split()   <span class="co"># I, like, dogs, a</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    words <span class="op">=</span> [STEMMER.stem(w) <span class="cf">for</span> w <span class="kw">in</span> words]</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> words</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="co">##import spacy</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="co">## https://spacy.io/usage/spacy-101</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="co"># create a spaCy tokenizer</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="co">###########################</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="co">## Stemming and Lemming</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="co">## Stemming is different to Lemmatization </span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="co">## in the approach it uses to produce root </span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="co">## forms of words and the word produced.</span></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="co">##  !!! Stemming can result in words</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="co">##      That are not actually words. </span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="co">##    trouble, troubling, troubled, troubles ....</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="co">##    all become troubl</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co">##Lemmatization is the process of grouping together </span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="co">##the different inflected forms of a word so they can</span></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="co">## be analysed as a single item. Lemmatization is similar</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="co">## to stemming but it brings context to the words. So it </span></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="co">## links words with similar meaning to one word. </span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="co">#####################################################################</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="co">##   Here, I am creating a few vectorizers - some with stemming</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="co">##   and some without. One for Bernoulli, and some that normalize</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="co">##   using Tf-Idf</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="co">#####################################################################</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>MyVect_STEM<span class="op">=</span>CountVectorizer(<span class="bu">input</span><span class="op">=</span><span class="st">'filename'</span>,</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>                        analyzer <span class="op">=</span> <span class="st">'word'</span>,</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>                        stop_words<span class="op">=</span><span class="st">'english'</span>,</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>                        <span class="co">##stop_words=["and", "or", "but"],</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#token_pattern='(?u)[a-zA-Z]+',</span></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#token_pattern=pattern,</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>                        tokenizer<span class="op">=</span>MY_STEMMER,</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#strip_accents = 'unicode', </span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>                        lowercase <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>MyVect_STEM_Bern<span class="op">=</span>CountVectorizer(<span class="bu">input</span><span class="op">=</span><span class="st">'filename'</span>,</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>                        analyzer <span class="op">=</span> <span class="st">'word'</span>,</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>                        stop_words<span class="op">=</span><span class="st">'english'</span>,</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>                        <span class="co">##stop_words=["and", "or", "but"],</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#token_pattern='(?u)[a-zA-Z]+',</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#token_pattern=pattern,</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>                        tokenizer<span class="op">=</span>MY_STEMMER,</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#strip_accents = 'unicode', </span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>                        lowercase <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>                        binary<span class="op">=</span><span class="va">True</span>    <span class="co">#  0 if the word is not in the doc  and a 1 if it is</span></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>MyVect_IFIDF<span class="op">=</span>TfidfVectorizer(<span class="bu">input</span><span class="op">=</span><span class="st">'filename'</span>,</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>                        analyzer <span class="op">=</span> <span class="st">'word'</span>,</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>                        stop_words<span class="op">=</span><span class="st">'english'</span>,</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>                        lowercase <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#binary=True</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>MyVect_IFIDF_STEM<span class="op">=</span>TfidfVectorizer(<span class="bu">input</span><span class="op">=</span><span class="st">'filename'</span>,</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>                        analyzer <span class="op">=</span> <span class="st">'word'</span>,</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>                        stop_words<span class="op">=</span><span class="st">'english'</span>,</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>                        tokenizer<span class="op">=</span>MY_STEMMER,</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#strip_accents = 'unicode', </span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>                        lowercase <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>                        <span class="co">#binary=True</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="co">#We will be creating new data frames - one for NB and one for Bern. </span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="co">## These are the two new and currently empty DFs</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="co">## Notice there are FOUR (4) of these because I have 4 </span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="co">## vectorizers</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM<span class="op">=</span>pd.DataFrame()</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM_Bern<span class="op">=</span>pd.DataFrame()</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF<span class="op">=</span>pd.DataFrame()</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF_STEM<span class="op">=</span>pd.DataFrame()</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="co">## You will need to know where things are on your computer.</span></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="co">## This code assumes that it is in the same folder/location</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="co">## as the folders DOG and HIKE. It will loop through the files in</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="co">## these two folders and will build the list needed to use</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a><span class="co">## CounterVectorizer. </span></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="co">## </span><span class="al">NOTICE</span><span class="co">: My loop has a path in it. This is for MY computer - not yours!</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a><span class="co">## You will need to adjust the path.</span></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> [<span class="st">"DOG"</span>, <span class="st">"HIKE"</span>]:</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>    builder<span class="op">=</span>name<span class="op">+</span><span class="st">"DF"</span>    <span class="co">#DOGDF</span></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(builder)</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>    builderB<span class="op">=</span>name<span class="op">+</span><span class="st">"DFB"</span></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span><span class="st">"C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">profa</span><span class="ch">\\</span><span class="st">Documents</span><span class="ch">\\</span><span class="st">Python Scripts</span><span class="ch">\\</span><span class="st">TextMining</span><span class="ch">\\</span><span class="st">Week4_7</span><span class="ch">\\</span><span class="st">"</span><span class="op">+</span>name</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>    FileList<span class="op">=</span>[]</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> os.listdir(path):</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(path+ "\\" + item)</span></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>        next1<span class="op">=</span>path<span class="op">+</span> <span class="st">"/"</span> <span class="op">+</span> item</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>        FileList.append(next1)  </span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"full list..."</span>)</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(FileList)</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>        <span class="co">## Do for all three</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>        <span class="co">## MyVect_STEM  and MyVect_IFIDF and MyVect_IFIDF_STEM</span></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>        X1<span class="op">=</span>MyVect_STEM.fit_transform(FileList)</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>        X2<span class="op">=</span>MyVect_IFIDF.fit_transform(FileList)</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>        X3<span class="op">=</span>MyVect_IFIDF_STEM.fit_transform(FileList)</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>        XB<span class="op">=</span>MyVect_STEM_Bern.fit_transform(FileList)</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>        ColumnNames1<span class="op">=</span>MyVect_STEM.get_feature_names()</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>        NumFeatures1<span class="op">=</span><span class="bu">len</span>(ColumnNames1)</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>        ColumnNames2<span class="op">=</span>MyVect_IFIDF.get_feature_names()</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>        NumFeatures2<span class="op">=</span><span class="bu">len</span>(ColumnNames2)</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>        ColumnNames3<span class="op">=</span>MyVect_IFIDF_STEM.get_feature_names()</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>        NumFeatures3<span class="op">=</span><span class="bu">len</span>(ColumnNames3)</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>        ColumnNamesB<span class="op">=</span>MyVect_STEM_Bern.get_feature_names()</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>        NumFeatures4<span class="op">=</span><span class="bu">len</span>(ColumnNamesB)</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print("Column names: ", ColumnNames2)</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>        <span class="co">#Create a name</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>    builderS<span class="op">=</span>pd.DataFrame(X1.toarray(),columns<span class="op">=</span>ColumnNames1)</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>    builderT<span class="op">=</span>pd.DataFrame(X2.toarray(),columns<span class="op">=</span>ColumnNames2)</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>    builderTS<span class="op">=</span>pd.DataFrame(X3.toarray(),columns<span class="op">=</span>ColumnNames3)</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>    builderB<span class="op">=</span>pd.DataFrame(XB.toarray(),columns<span class="op">=</span>ColumnNamesB)</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Add column</span></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print("Adding new column....")</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>    builderS[<span class="st">"Label"</span>]<span class="op">=</span>name</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>    builderT[<span class="st">"Label"</span>]<span class="op">=</span>name</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>    builderTS[<span class="st">"Label"</span>]<span class="op">=</span>name</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>    builderB[<span class="st">"Label"</span>]<span class="op">=</span>name</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(builderS)</span></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>    FinalDF_STEM<span class="op">=</span> FinalDF_STEM.append(builderS)</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>    FinalDF_STEM_Bern<span class="op">=</span> FinalDF_STEM_Bern.append(builderB)</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>    FinalDF_TFIDF<span class="op">=</span> FinalDF_TFIDF.append(builderT)</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>    FinalDF_TFIDF_STEM<span class="op">=</span> FinalDF_TFIDF_STEM.append(builderTS)</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(FinalDF_STEM.head())</span></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="co">## Replace the NaN with 0 because it actually </span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="co">## means none in this case</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM<span class="op">=</span>FinalDF_STEM.fillna(<span class="dv">0</span>)</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM_Bern<span class="op">=</span>FinalDF_STEM_Bern.fillna(<span class="dv">0</span>)</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF<span class="op">=</span>FinalDF_TFIDF.fillna(<span class="dv">0</span>)</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF_STEM<span class="op">=</span>FinalDF_TFIDF_STEM.fillna(<span class="dv">0</span>)</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="co">###### REMOVE number columns</span></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="co">## Remove columns with number from this one</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a><span class="co">##-------------------------------------------------------------------</span></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="co">####### Create a function that removes columns that are/contain nums</span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="co">##-------------------------------------------------------------------</span></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> RemoveNums(SomeDF):</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(SomeDF)</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Running Remove Numbers function....</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>    temp<span class="op">=</span>SomeDF</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>    MyList<span class="op">=</span>[]</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> temp.columns:</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(col)</span></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>        <span class="co">#Logical1=col.isdigit()  ## is a num</span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>        Logical2<span class="op">=</span><span class="bu">str</span>.isalpha(col) <span class="co">## this checks for anything</span></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>        <span class="co">## that is not a letter</span></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(Logical2<span class="op">==</span><span class="va">False</span>):<span class="co"># or Logical2==True):</span></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>            <span class="co">#print(col)</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>            MyList.append(<span class="bu">str</span>(col))</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>            <span class="co">#print(MyList)       </span></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>    temp.drop(MyList, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>            <span class="co">#print(temp)</span></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>            <span class="co">#return temp</span></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> temp</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="co">##########################################################</span></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="co">## Call the function ....</span></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM<span class="op">=</span>RemoveNums(FinalDF_STEM)</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>FinalDF_STEM_Bern<span class="op">=</span>RemoveNums(FinalDF_STEM_Bern)</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF<span class="op">=</span>RemoveNums(FinalDF_TFIDF)</span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>FinalDF_TFIDF_STEM<span class="op">=</span>RemoveNums(FinalDF_TFIDF_STEM)</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="co">## Have a look:</span></span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a><span class="co">## These print statements help you to see where you are</span></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="co">#print(FinalDF_STEM)</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a><span class="co">## Remove columns that contain "-"  HOW TO....</span></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="co">#cols = [c for c in FinalDF_STEM.columns if "-" in c[:] ]</span></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a><span class="co">#FinalDF_STEM=FinalDF_STEM.drop(cols, axis = 1) </span></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(FinalDF_STEM)  <span class="co">#1</span></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(FinalDF_STEM_Bern) <span class="co">#4</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(FinalDF_TFIDF)  <span class="co">#2</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(FinalDF_TFIDF_STEM) <span class="co">#3</span></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="co">##################################################</span></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="co">##        Now we have 4 labeled dataframes!</span></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="co">##        Let's model them.....</span></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="co">######################################################</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="co">## Create the testing set - grab a sample from the training set. </span></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="co">## Be careful. Notice that right now, our train set is sorted by label.</span></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a><span class="co">## If your train set is large enough, you can take a random sample.</span></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="im">as</span> rd</span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="co">#rd.seed(1234)</span></span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a>TrainDF1, TestDF1 <span class="op">=</span> train_test_split(FinalDF_STEM, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TrainDF1)</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TestDF1)</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a>TrainDF2, TestDF2 <span class="op">=</span> train_test_split(FinalDF_TFIDF, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a>TrainDF3, TestDF3 <span class="op">=</span> train_test_split(FinalDF_TFIDF_STEM, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a>TrainDF4, TestDF4 <span class="op">=</span> train_test_split(FinalDF_STEM_Bern, test_size<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TestDF4)</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a><span class="co">### OK - at this point we have Train and Test data for the text data</span></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="co">## in DOG and HIKE. </span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a><span class="co">## Of course, this can be updated to work from sentiment (like POS and NEG)</span></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a><span class="co">## and can be update for multiple folders or one folder..</span></span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################</span></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a><span class="co">## For all FOUR DFs - separate LABELS</span></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a><span class="co">#################################################</span></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a><span class="co">## IMPORTANT - YOU CANNOT LEAVE LABELS ON THE </span><span class="al">TEST</span><span class="co"> SET</span></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a><span class="co">## Save labels</span></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="al">TEST</span><span class="co"> ---------------------</span></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a>Test1Labels<span class="op">=</span>TestDF1[<span class="st">"Label"</span>]</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test1Labels)</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a>Test2Labels<span class="op">=</span>TestDF2[<span class="st">"Label"</span>]</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a>Test3Labels<span class="op">=</span>TestDF3[<span class="st">"Label"</span>]</span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>Test4Labels<span class="op">=</span>TestDF4[<span class="st">"Label"</span>]</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test2Labels)</span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="co">## remove labels</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a>TestDF1 <span class="op">=</span> TestDF1.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>TestDF2 <span class="op">=</span> TestDF2.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>TestDF3 <span class="op">=</span> TestDF3.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a>TestDF4 <span class="op">=</span> TestDF4.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TestDF1)</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="co">## TRAIN ----------------------------</span></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a>Train1Labels<span class="op">=</span>TrainDF1[<span class="st">"Label"</span>]</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a>Train2Labels<span class="op">=</span>TrainDF2[<span class="st">"Label"</span>]</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a>Train3Labels<span class="op">=</span>TrainDF3[<span class="st">"Label"</span>]</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a>Train4Labels<span class="op">=</span>TrainDF4[<span class="st">"Label"</span>]</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Train3Labels)</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a><span class="co">## remove labels</span></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a>TrainDF1 <span class="op">=</span> TrainDF1.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>TrainDF2 <span class="op">=</span> TrainDF2.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>TrainDF3 <span class="op">=</span> TrainDF3.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a>TrainDF4 <span class="op">=</span> TrainDF4.drop([<span class="st">"Label"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TrainDF3)</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################################</span></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="co">########################### Naive Bayes ############################</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################################</span></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a><span class="co">#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit</span></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="co">#Create the modeler</span></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a>MyModelNB<span class="op">=</span> MultinomialNB()</span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a><span class="co">## Run on all three Dfs.................</span></span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>NB1<span class="op">=</span>MyModelNB.fit(TrainDF1, Train1Labels)</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>Prediction1 <span class="op">=</span> MyModelNB.predict(TestDF1)</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(MyModelNB.predict_proba(TestDF1),<span class="dv">2</span>))</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>NB2<span class="op">=</span>MyModelNB.fit(TrainDF2, Train2Labels)</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>Prediction2 <span class="op">=</span> MyModelNB.predict(TestDF2)</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(MyModelNB.predict_proba(TestDF2),<span class="dv">2</span>))</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a>NB3<span class="op">=</span>MyModelNB.fit(TrainDF3, Train3Labels)</span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>Prediction3 <span class="op">=</span> MyModelNB.predict(TestDF3)</span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(MyModelNB.predict_proba(TestDF3),<span class="dv">2</span>))</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>NB4<span class="op">=</span>MyModelNB.fit(TrainDF4, Train4Labels)</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a>Prediction4 <span class="op">=</span> MyModelNB.predict(TestDF4)</span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(MyModelNB.predict_proba(TestDF4),<span class="dv">2</span>))</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The prediction from NB is:"</span>)</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Prediction1)</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The actual labels are:"</span>)</span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test1Labels)</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The prediction from NB is:"</span>)</span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Prediction2)</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The actual labels are:"</span>)</span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test2Labels)</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The prediction from NB is:"</span>)</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Prediction3)</span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The actual labels are:"</span>)</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test3Labels)</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The prediction from NB is:"</span>)</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Prediction4)</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The actual labels are:"</span>)</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test4Labels)</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="co">## confusion matrix</span></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="co">## The confusion matrix is square and is labels X labels</span></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a><span class="co">## We ahve two labels, so ours will be 2X2</span></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="co">#The matrix shows</span></span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a><span class="co">## rows are the true labels</span></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="co">## columns are predicted</span></span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a><span class="co">## it is al[habetical</span></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="co">## The numbers are how many </span></span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a>cnf_matrix1 <span class="op">=</span> confusion_matrix(Test1Labels, Prediction1)</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix1)</span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a>cnf_matrix2 <span class="op">=</span> confusion_matrix(Test2Labels, Prediction2)</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix2)</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a>cnf_matrix3 <span class="op">=</span> confusion_matrix(Test3Labels, Prediction3)</span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix3)</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a>cnf_matrix4 <span class="op">=</span> confusion_matrix(Test4Labels, Prediction4)</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix4)</span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="co">#######################################################</span></span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a><span class="co">### Bernoulli #########################################</span></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="co">#######################################################</span></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> BernoulliNB</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a>BernModel <span class="op">=</span> BernoulliNB()</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a>BernModel.fit(TrainDF4, Train4Labels)</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="co">##BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)</span></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Bernoulli prediction:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a>Prediction<span class="op">=</span>BernModel.predict(TestDF4)</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Actual:"</span>)</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Test4Labels)</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"\The prediction</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(Prediction)</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a>bn_matrix <span class="op">=</span> confusion_matrix(Test4Labels, Prediction)</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bn_matrix)</span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a><span class="co">#############    Decision Trees   #######################</span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install python-graphviz</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a><span class="co">## restart kernel (click the little red x next to the Console)</span></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz </span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a><span class="co">#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</span></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>MyDT<span class="op">=</span>DecisionTreeClassifier(criterion<span class="op">=</span><span class="st">'entropy'</span>, <span class="co">##"entropy" or "gini"</span></span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a>                            splitter<span class="op">=</span><span class="st">'best'</span>,  <span class="co">## or "random" or "best"</span></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a>                            min_samples_split<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>                            min_samples_leaf<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a>                            min_weight_fraction_leaf<span class="op">=</span><span class="fl">0.0</span>, </span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a>                            max_features<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a>                            random_state<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>                            max_leaf_nodes<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a>                            min_impurity_decrease<span class="op">=</span><span class="fl">0.0</span>, </span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a>                            min_impurity_split<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a>                            class_weight<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a><span class="co">## ------------------------------</span></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a><span class="co">## This for loop will fit and predict Decision Trees for </span></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a><span class="co">## all 4 of the dataframes. Notice that this uses dynamic variables</span></span>
<span id="cb1-482"><a href="#cb1-482" aria-hidden="true" tabindex="-1"></a><span class="co">## and eval</span></span>
<span id="cb1-483"><a href="#cb1-483" aria-hidden="true" tabindex="-1"></a><span class="co">##--------------------------</span></span>
<span id="cb1-484"><a href="#cb1-484" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-485"><a href="#cb1-485" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TrainDF1)</span>
<span id="cb1-486"><a href="#cb1-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-487"><a href="#cb1-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-488"><a href="#cb1-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-489"><a href="#cb1-489" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]:</span>
<span id="cb1-490"><a href="#cb1-490" aria-hidden="true" tabindex="-1"></a>    temp1<span class="op">=</span><span class="bu">str</span>(<span class="st">"TrainDF"</span><span class="op">+</span><span class="bu">str</span>(i))   <span class="co">##  TrainDF1</span></span>
<span id="cb1-491"><a href="#cb1-491" aria-hidden="true" tabindex="-1"></a>    temp2<span class="op">=</span><span class="bu">str</span>(<span class="st">"Train"</span><span class="op">+</span><span class="bu">str</span>(i)<span class="op">+</span><span class="st">"Labels"</span>)  <span class="co">#Train1Labels</span></span>
<span id="cb1-492"><a href="#cb1-492" aria-hidden="true" tabindex="-1"></a>    temp3<span class="op">=</span><span class="bu">str</span>(<span class="st">"TestDF"</span><span class="op">+</span><span class="bu">str</span>(i))  <span class="co">#TestDF1</span></span>
<span id="cb1-493"><a href="#cb1-493" aria-hidden="true" tabindex="-1"></a>    temp4<span class="op">=</span><span class="bu">str</span>(<span class="st">"Test"</span><span class="op">+</span><span class="bu">str</span>(i)<span class="op">+</span><span class="st">"Labels"</span>) <span class="co"># Test1Labels</span></span>
<span id="cb1-494"><a href="#cb1-494" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-495"><a href="#cb1-495" aria-hidden="true" tabindex="-1"></a>    <span class="co">## perform DT</span></span>
<span id="cb1-496"><a href="#cb1-496" aria-hidden="true" tabindex="-1"></a>    <span class="co">#MyDT.fit(TrainDF1, Train1Labels)</span></span>
<span id="cb1-497"><a href="#cb1-497" aria-hidden="true" tabindex="-1"></a>    MyDT.fit(<span class="bu">eval</span>(temp1), <span class="bu">eval</span>(temp2))</span>
<span id="cb1-498"><a href="#cb1-498" aria-hidden="true" tabindex="-1"></a>    <span class="co">## plot the tree</span></span>
<span id="cb1-499"><a href="#cb1-499" aria-hidden="true" tabindex="-1"></a>    tree.plot_tree(MyDT)</span>
<span id="cb1-500"><a href="#cb1-500" aria-hidden="true" tabindex="-1"></a>    plt.savefig(temp1)</span>
<span id="cb1-501"><a href="#cb1-501" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span><span class="bu">eval</span>(<span class="bu">str</span>(temp1<span class="op">+</span><span class="st">".columns"</span>))</span>
<span id="cb1-502"><a href="#cb1-502" aria-hidden="true" tabindex="-1"></a>    dot_data <span class="op">=</span> tree.export_graphviz(MyDT, out_file<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb1-503"><a href="#cb1-503" aria-hidden="true" tabindex="-1"></a>                    <span class="co">## The following creates TrainDF.columns for each</span></span>
<span id="cb1-504"><a href="#cb1-504" aria-hidden="true" tabindex="-1"></a>                    <span class="co">## which are the feature names.</span></span>
<span id="cb1-505"><a href="#cb1-505" aria-hidden="true" tabindex="-1"></a>                      feature_names<span class="op">=</span><span class="bu">eval</span>(<span class="bu">str</span>(temp1<span class="op">+</span><span class="st">".columns"</span>)),  </span>
<span id="cb1-506"><a href="#cb1-506" aria-hidden="true" tabindex="-1"></a>                      <span class="co">#class_names=MyDT.class_names,  </span></span>
<span id="cb1-507"><a href="#cb1-507" aria-hidden="true" tabindex="-1"></a>                      filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>,  </span>
<span id="cb1-508"><a href="#cb1-508" aria-hidden="true" tabindex="-1"></a>                      special_characters<span class="op">=</span><span class="va">True</span>)                                    </span>
<span id="cb1-509"><a href="#cb1-509" aria-hidden="true" tabindex="-1"></a>    graph <span class="op">=</span> graphviz.Source(dot_data) </span>
<span id="cb1-510"><a href="#cb1-510" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Create dynamic graph name</span></span>
<span id="cb1-511"><a href="#cb1-511" aria-hidden="true" tabindex="-1"></a>    tempname<span class="op">=</span><span class="bu">str</span>(<span class="st">"Graph"</span> <span class="op">+</span> <span class="bu">str</span>(i))</span>
<span id="cb1-512"><a href="#cb1-512" aria-hidden="true" tabindex="-1"></a>    graph.render(tempname) </span>
<span id="cb1-513"><a href="#cb1-513" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Show the predictions from the DT on the test set</span></span>
<span id="cb1-514"><a href="#cb1-514" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Actual for DataFrame: "</span>, i, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-515"><a href="#cb1-515" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="bu">eval</span>(temp2))</span>
<span id="cb1-516"><a href="#cb1-516" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Prediction</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-517"><a href="#cb1-517" aria-hidden="true" tabindex="-1"></a>    DT_pred<span class="op">=</span>MyDT.predict(<span class="bu">eval</span>(temp3))</span>
<span id="cb1-518"><a href="#cb1-518" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(DT_pred)</span>
<span id="cb1-519"><a href="#cb1-519" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Show the confusion matrix</span></span>
<span id="cb1-520"><a href="#cb1-520" aria-hidden="true" tabindex="-1"></a>    bn_matrix <span class="op">=</span> confusion_matrix(<span class="bu">eval</span>(temp4), DT_pred)</span>
<span id="cb1-521"><a href="#cb1-521" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-522"><a href="#cb1-522" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(bn_matrix)</span>
<span id="cb1-523"><a href="#cb1-523" aria-hidden="true" tabindex="-1"></a>    FeatureImp<span class="op">=</span>MyDT.feature_importances_   </span>
<span id="cb1-524"><a href="#cb1-524" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.argsort(FeatureImp)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-525"><a href="#cb1-525" aria-hidden="true" tabindex="-1"></a>    <span class="co">## print out the important features.....</span></span>
<span id="cb1-526"><a href="#cb1-526" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> f <span class="kw">in</span> <span class="bu">range</span>(TrainDF4.shape[<span class="dv">1</span>]):</span>
<span id="cb1-527"><a href="#cb1-527" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> FeatureImp[indices[f]] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-528"><a href="#cb1-528" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="sc">%d</span><span class="st">. feature </span><span class="sc">%d</span><span class="st"> (</span><span class="sc">%f</span><span class="st">)"</span> <span class="op">%</span> (f <span class="op">+</span> <span class="dv">1</span>, indices[f], FeatureImp[indices[f]]))</span>
<span id="cb1-529"><a href="#cb1-529" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span> (<span class="st">"feature name: "</span>, feature_names[indices[f]])</span>
<span id="cb1-530"><a href="#cb1-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-531"><a href="#cb1-531" aria-hidden="true" tabindex="-1"></a><span class="co">## FYI for small datasets you can zip features....</span></span>
<span id="cb1-532"><a href="#cb1-532" aria-hidden="true" tabindex="-1"></a><span class="co">## print(dict(zip(iris_pd.columns, clf.feature_importances_)))</span></span>
<span id="cb1-533"><a href="#cb1-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-534"><a href="#cb1-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-535"><a href="#cb1-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-536"><a href="#cb1-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-537"><a href="#cb1-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-538"><a href="#cb1-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-539"><a href="#cb1-539" aria-hidden="true" tabindex="-1"></a><span class="co">#####################################################</span></span>
<span id="cb1-540"><a href="#cb1-540" aria-hidden="true" tabindex="-1"></a><span class="co">##  Visualize Decision Trees plotting paired surfaces</span></span>
<span id="cb1-541"><a href="#cb1-541" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-542"><a href="#cb1-542" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################</span></span>
<span id="cb1-543"><a href="#cb1-543" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-544"><a href="#cb1-544" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-545"><a href="#cb1-545" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-546"><a href="#cb1-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-547"><a href="#cb1-547" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span>TrainDF1.columns.get_loc(<span class="st">"dog"</span>) </span>
<span id="cb1-548"><a href="#cb1-548" aria-hidden="true" tabindex="-1"></a>f2<span class="op">=</span>TrainDF1.columns.get_loc(<span class="st">"hike"</span>) </span>
<span id="cb1-549"><a href="#cb1-549" aria-hidden="true" tabindex="-1"></a>f3<span class="op">=</span>TrainDF1.columns.get_loc(<span class="st">"workout"</span>) </span>
<span id="cb1-550"><a href="#cb1-550" aria-hidden="true" tabindex="-1"></a>f4<span class="op">=</span>TrainDF1.columns.get_loc(<span class="st">"happi"</span>) </span>
<span id="cb1-551"><a href="#cb1-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-552"><a href="#cb1-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-553"><a href="#cb1-553" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span><span class="dv">2</span></span>
<span id="cb1-554"><a href="#cb1-554" aria-hidden="true" tabindex="-1"></a>plot_colors <span class="op">=</span> <span class="st">"ryb"</span></span>
<span id="cb1-555"><a href="#cb1-555" aria-hidden="true" tabindex="-1"></a>plot_step <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb1-556"><a href="#cb1-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-557"><a href="#cb1-557" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pairidx, pair <span class="kw">in</span> <span class="bu">enumerate</span>([[f1, f2], [f1, f3], [f1, f4],</span>
<span id="cb1-558"><a href="#cb1-558" aria-hidden="true" tabindex="-1"></a>                                [f2,f3], [f3, f4]]):</span>
<span id="cb1-559"><a href="#cb1-559" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(TrainDF1.iloc[:,pair])</span></span>
<span id="cb1-560"><a href="#cb1-560" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> TrainDF1.iloc[:, pair]</span>
<span id="cb1-561"><a href="#cb1-561" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Because we are plotting, using our GOD and HIKE labels will not work</span></span>
<span id="cb1-562"><a href="#cb1-562" aria-hidden="true" tabindex="-1"></a>    <span class="co">## we need to change them to 0 and 1</span></span>
<span id="cb1-563"><a href="#cb1-563" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> Train1Labels</span>
<span id="cb1-564"><a href="#cb1-564" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y)</span>
<span id="cb1-565"><a href="#cb1-565" aria-hidden="true" tabindex="-1"></a>    oldy<span class="op">=</span>y</span>
<span id="cb1-566"><a href="#cb1-566" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(type(y))</span></span>
<span id="cb1-567"><a href="#cb1-567" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y.replace(<span class="st">"DOG"</span>, <span class="dv">1</span>)</span>
<span id="cb1-568"><a href="#cb1-568" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y.replace(<span class="st">"HIKE"</span>, <span class="dv">0</span>)</span>
<span id="cb1-569"><a href="#cb1-569" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-570"><a href="#cb1-570" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y)</span>
<span id="cb1-571"><a href="#cb1-571" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train</span></span>
<span id="cb1-572"><a href="#cb1-572" aria-hidden="true" tabindex="-1"></a>    DT <span class="op">=</span> DecisionTreeClassifier().fit(X, y)</span>
<span id="cb1-573"><a href="#cb1-573" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the decision boundary</span></span>
<span id="cb1-574"><a href="#cb1-574" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, pairidx <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb1-575"><a href="#cb1-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-576"><a href="#cb1-576" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X.iloc[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X.iloc[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-577"><a href="#cb1-577" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(x_min)</span>
<span id="cb1-578"><a href="#cb1-578" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X.iloc[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X.iloc[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-579"><a href="#cb1-579" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-580"><a href="#cb1-580" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max,plot_step),</span>
<span id="cb1-581"><a href="#cb1-581" aria-hidden="true" tabindex="-1"></a>                         np.arange(y_min, y_max,plot_step))</span>
<span id="cb1-582"><a href="#cb1-582" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-583"><a href="#cb1-583" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(yy)</span></span>
<span id="cb1-584"><a href="#cb1-584" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-585"><a href="#cb1-585" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout(h_pad<span class="op">=</span><span class="fl">0.5</span>, w_pad<span class="op">=</span><span class="fl">0.5</span>, pad<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb1-586"><a href="#cb1-586" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-587"><a href="#cb1-587" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> DT.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb1-588"><a href="#cb1-588" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb1-589"><a href="#cb1-589" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(Z)</span>
<span id="cb1-590"><a href="#cb1-590" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-591"><a href="#cb1-591" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-592"><a href="#cb1-592" aria-hidden="true" tabindex="-1"></a>    cs <span class="op">=</span> plt.contourf(xx, yy, Z, cmap<span class="op">=</span>plt.cm.RdYlBu)</span>
<span id="cb1-593"><a href="#cb1-593" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb1-594"><a href="#cb1-594" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X.iloc[:, <span class="dv">0</span>], X.iloc[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span>oldy,edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb1-595"><a href="#cb1-595" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#c=color, s=15)</span></span>
<span id="cb1-596"><a href="#cb1-596" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#label=y[i],</span></span>
<span id="cb1-597"><a href="#cb1-597" aria-hidden="true" tabindex="-1"></a>                    cmap<span class="op">=</span>plt.cm.RdYlBu)</span>
<span id="cb1-598"><a href="#cb1-598" aria-hidden="true" tabindex="-1"></a><span class="co">###---------------------------end for loop ----------------------------------</span></span>
<span id="cb1-599"><a href="#cb1-599" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle("Decision surface of a decision tree using paired features")</span></span>
<span id="cb1-600"><a href="#cb1-600" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.legend(loc='lower right', borderpad=0, handletextpad=0)</span></span>
<span id="cb1-601"><a href="#cb1-601" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.axis("tight")</span></span>
<span id="cb1-602"><a href="#cb1-602" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-603"><a href="#cb1-603" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.figure()</span></span>
<span id="cb1-604"><a href="#cb1-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-605"><a href="#cb1-605" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-606"><a href="#cb1-606" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-607"><a href="#cb1-607" aria-hidden="true" tabindex="-1"></a><span class="co">##                 Random Forest for Text Data</span></span>
<span id="cb1-608"><a href="#cb1-608" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-609"><a href="#cb1-609" aria-hidden="true" tabindex="-1"></a><span class="co">#################################################################</span></span>
<span id="cb1-610"><a href="#cb1-610" aria-hidden="true" tabindex="-1"></a>RF <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb1-611"><a href="#cb1-611" aria-hidden="true" tabindex="-1"></a>RF.fit(TrainDF1, Train1Labels)</span>
<span id="cb1-612"><a href="#cb1-612" aria-hidden="true" tabindex="-1"></a>RF_pred<span class="op">=</span>RF.predict(TestDF1)</span>
<span id="cb1-613"><a href="#cb1-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-614"><a href="#cb1-614" aria-hidden="true" tabindex="-1"></a>bn_matrix_RF_text <span class="op">=</span> confusion_matrix(Test1Labels, RF_pred)</span>
<span id="cb1-615"><a href="#cb1-615" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-616"><a href="#cb1-616" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bn_matrix_RF_text)</span>
<span id="cb1-617"><a href="#cb1-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-618"><a href="#cb1-618" aria-hidden="true" tabindex="-1"></a><span class="co">################# VIS RF---------------------------------</span></span>
<span id="cb1-619"><a href="#cb1-619" aria-hidden="true" tabindex="-1"></a><span class="co">## FEATURE NAMES...................</span></span>
<span id="cb1-620"><a href="#cb1-620" aria-hidden="true" tabindex="-1"></a>FeaturesT<span class="op">=</span>TrainDF1.columns</span>
<span id="cb1-621"><a href="#cb1-621" aria-hidden="true" tabindex="-1"></a><span class="co">#Targets=StudentTestLabels_Num</span></span>
<span id="cb1-622"><a href="#cb1-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-623"><a href="#cb1-623" aria-hidden="true" tabindex="-1"></a>figT, axesT <span class="op">=</span> plt.subplots(nrows <span class="op">=</span> <span class="dv">1</span>,ncols <span class="op">=</span> <span class="dv">1</span>,figsize <span class="op">=</span> (<span class="dv">4</span>,<span class="dv">4</span>), dpi<span class="op">=</span><span class="dv">800</span>)</span>
<span id="cb1-624"><a href="#cb1-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-625"><a href="#cb1-625" aria-hidden="true" tabindex="-1"></a>tree.plot_tree(RF.estimators_[<span class="dv">0</span>],</span>
<span id="cb1-626"><a href="#cb1-626" aria-hidden="true" tabindex="-1"></a>               feature_names <span class="op">=</span> FeaturesT, </span>
<span id="cb1-627"><a href="#cb1-627" aria-hidden="true" tabindex="-1"></a>               <span class="co">#class_names=Targets,</span></span>
<span id="cb1-628"><a href="#cb1-628" aria-hidden="true" tabindex="-1"></a>               filled <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-629"><a href="#cb1-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-630"><a href="#cb1-630" aria-hidden="true" tabindex="-1"></a><span class="co">##save it</span></span>
<span id="cb1-631"><a href="#cb1-631" aria-hidden="true" tabindex="-1"></a>figT.savefig(<span class="st">'RF_Tree_Text'</span>)  <span class="co">## creates png</span></span>
<span id="cb1-632"><a href="#cb1-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-633"><a href="#cb1-633" aria-hidden="true" tabindex="-1"></a><span class="co">#####------------------&gt; View estimator Trees in RF</span></span>
<span id="cb1-634"><a href="#cb1-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-635"><a href="#cb1-635" aria-hidden="true" tabindex="-1"></a>figT2, axesT2 <span class="op">=</span> plt.subplots(nrows <span class="op">=</span> <span class="dv">1</span>,ncols <span class="op">=</span> <span class="dv">5</span>,figsize <span class="op">=</span> (<span class="dv">10</span>,<span class="dv">2</span>), dpi<span class="op">=</span><span class="dv">900</span>)</span>
<span id="cb1-636"><a href="#cb1-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-637"><a href="#cb1-637" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">5</span>):</span>
<span id="cb1-638"><a href="#cb1-638" aria-hidden="true" tabindex="-1"></a>    tree.plot_tree(RF.estimators_[index],</span>
<span id="cb1-639"><a href="#cb1-639" aria-hidden="true" tabindex="-1"></a>                   feature_names <span class="op">=</span> FeaturesT, </span>
<span id="cb1-640"><a href="#cb1-640" aria-hidden="true" tabindex="-1"></a>                   filled <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb1-641"><a href="#cb1-641" aria-hidden="true" tabindex="-1"></a>                   ax <span class="op">=</span> axesT2[index])</span>
<span id="cb1-642"><a href="#cb1-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-643"><a href="#cb1-643" aria-hidden="true" tabindex="-1"></a>    axesT2[index].set_title(<span class="st">'Estimator: '</span> <span class="op">+</span> <span class="bu">str</span>(index), fontsize <span class="op">=</span> <span class="dv">11</span>)</span>
<span id="cb1-644"><a href="#cb1-644" aria-hidden="true" tabindex="-1"></a><span class="co">## Save it</span></span>
<span id="cb1-645"><a href="#cb1-645" aria-hidden="true" tabindex="-1"></a>figT2.savefig(<span class="st">'FIVEtrees_RF.png'</span>)</span>
<span id="cb1-646"><a href="#cb1-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-647"><a href="#cb1-647" aria-hidden="true" tabindex="-1"></a><span class="co">#################--------------------------&gt;</span></span>
<span id="cb1-648"><a href="#cb1-648" aria-hidden="true" tabindex="-1"></a><span class="co">## Feature importance in RF</span></span>
<span id="cb1-649"><a href="#cb1-649" aria-hidden="true" tabindex="-1"></a><span class="co">##-----------------------------------------</span></span>
<span id="cb1-650"><a href="#cb1-650" aria-hidden="true" tabindex="-1"></a><span class="co">## Recall that FeaturesT are the columns names - the words in this case.</span></span>
<span id="cb1-651"><a href="#cb1-651" aria-hidden="true" tabindex="-1"></a><span class="co">######</span></span>
<span id="cb1-652"><a href="#cb1-652" aria-hidden="true" tabindex="-1"></a>FeatureImpRF<span class="op">=</span>RF.feature_importances_   </span>
<span id="cb1-653"><a href="#cb1-653" aria-hidden="true" tabindex="-1"></a>indicesRF <span class="op">=</span> np.argsort(FeatureImpRF)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-654"><a href="#cb1-654" aria-hidden="true" tabindex="-1"></a><span class="co">## print out the important features.....</span></span>
<span id="cb1-655"><a href="#cb1-655" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f2 <span class="kw">in</span> <span class="bu">range</span>(TrainDF1.shape[<span class="dv">1</span>]):   <span class="co">##TrainDF1.shape[1] is number of columns</span></span>
<span id="cb1-656"><a href="#cb1-656" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> FeatureImpRF[indicesRF[f2]] <span class="op">&gt;=</span> <span class="fl">0.01</span>:</span>
<span id="cb1-657"><a href="#cb1-657" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="sc">%d</span><span class="st">. feature </span><span class="sc">%d</span><span class="st"> (</span><span class="sc">%.2f</span><span class="st">)"</span> <span class="op">%</span> (f2 <span class="op">+</span> <span class="dv">1</span>, indicesRF[f2], FeatureImpRF[indicesRF[f2]]))</span>
<span id="cb1-658"><a href="#cb1-658" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> (<span class="st">"feature name: "</span>, FeaturesT[indicesRF[f2]])</span>
<span id="cb1-659"><a href="#cb1-659" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-660"><a href="#cb1-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-661"><a href="#cb1-661" aria-hidden="true" tabindex="-1"></a><span class="co">## PLOT THE TOP 10 FEATURES...........................</span></span>
<span id="cb1-662"><a href="#cb1-662" aria-hidden="true" tabindex="-1"></a>top_ten_arg <span class="op">=</span> indicesRF[:<span class="dv">10</span>]</span>
<span id="cb1-663"><a href="#cb1-663" aria-hidden="true" tabindex="-1"></a><span class="co">#print(top_ten_arg)</span></span>
<span id="cb1-664"><a href="#cb1-664" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importances Dog and Hike'</span>)</span>
<span id="cb1-665"><a href="#cb1-665" aria-hidden="true" tabindex="-1"></a>plt.barh(<span class="bu">range</span>(<span class="bu">len</span>(top_ten_arg)), FeatureImpRF[top_ten_arg], color<span class="op">=</span><span class="st">'b'</span>, align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb1-666"><a href="#cb1-666" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(top_ten_arg)), [FeaturesT[i] <span class="cf">for</span> i <span class="kw">in</span> top_ten_arg])</span>
<span id="cb1-667"><a href="#cb1-667" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Relative Importance'</span>)</span>
<span id="cb1-668"><a href="#cb1-668" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-669"><a href="#cb1-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-670"><a href="#cb1-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-671"><a href="#cb1-671" aria-hidden="true" tabindex="-1"></a><span class="co">#####################################################################</span></span>
<span id="cb1-672"><a href="#cb1-672" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-673"><a href="#cb1-673" aria-hidden="true" tabindex="-1"></a><span class="co">##             NN</span></span>
<span id="cb1-674"><a href="#cb1-674" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-675"><a href="#cb1-675" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################################</span></span>
<span id="cb1-676"><a href="#cb1-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-677"><a href="#cb1-677" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb1-678"><a href="#cb1-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-679"><a href="#cb1-679" aria-hidden="true" tabindex="-1"></a>MyNN <span class="op">=</span> MLPClassifier(solver<span class="op">=</span><span class="st">'lbfgs'</span>, </span>
<span id="cb1-680"><a href="#cb1-680" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#solver='adam',</span></span>
<span id="cb1-681"><a href="#cb1-681" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#solver='sgd',</span></span>
<span id="cb1-682"><a href="#cb1-682" aria-hidden="true" tabindex="-1"></a>                     alpha<span class="op">=</span><span class="dv">1</span>,  </span>
<span id="cb1-683"><a href="#cb1-683" aria-hidden="true" tabindex="-1"></a>                     </span>
<span id="cb1-684"><a href="#cb1-684" aria-hidden="true" tabindex="-1"></a>                   hidden_layer_sizes<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>), random_state<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-685"><a href="#cb1-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-686"><a href="#cb1-686" aria-hidden="true" tabindex="-1"></a>MyNN.fit(TrainDF1, Train1Labels)</span>
<span id="cb1-687"><a href="#cb1-687" aria-hidden="true" tabindex="-1"></a>NNPrediction <span class="op">=</span> MyNN.predict(TestDF1)</span>
<span id="cb1-688"><a href="#cb1-688" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"confusion matrix for NN</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-689"><a href="#cb1-689" aria-hidden="true" tabindex="-1"></a>NN_matrix <span class="op">=</span> confusion_matrix(Test1Labels, NNPrediction)</span>
<span id="cb1-690"><a href="#cb1-690" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(NN_matrix)</span>
<span id="cb1-691"><a href="#cb1-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-692"><a href="#cb1-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-693"><a href="#cb1-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-694"><a href="#cb1-694" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-695"><a href="#cb1-695" aria-hidden="true" tabindex="-1"></a><span class="co">###########  SVM ############################</span></span>
<span id="cb1-696"><a href="#cb1-696" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-697"><a href="#cb1-697" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.svm import LinearSVC</span></span>
<span id="cb1-698"><a href="#cb1-698" aria-hidden="true" tabindex="-1"></a>SVM_Model<span class="op">=</span>LinearSVC(C<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-699"><a href="#cb1-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-700"><a href="#cb1-700" aria-hidden="true" tabindex="-1"></a>SVM_Model.fit(TrainDF1, Train1Labels)</span>
<span id="cb1-701"><a href="#cb1-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-702"><a href="#cb1-702" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model.predict(TestDF1))</span></span>
<span id="cb1-703"><a href="#cb1-703" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-704"><a href="#cb1-704" aria-hidden="true" tabindex="-1"></a><span class="co">#print(Test1Labels)</span></span>
<span id="cb1-705"><a href="#cb1-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-706"><a href="#cb1-706" aria-hidden="true" tabindex="-1"></a>SVM_matrix <span class="op">=</span> confusion_matrix(Test1Labels, SVM_Model.predict(TestDF1))</span>
<span id="cb1-707"><a href="#cb1-707" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-708"><a href="#cb1-708" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix)</span>
<span id="cb1-709"><a href="#cb1-709" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-710"><a href="#cb1-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-711"><a href="#cb1-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-712"><a href="#cb1-712" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-713"><a href="#cb1-713" aria-hidden="true" tabindex="-1"></a><span class="co">###########  SVM ############################</span></span>
<span id="cb1-714"><a href="#cb1-714" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-715"><a href="#cb1-715" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.svm import LinearSVC</span></span>
<span id="cb1-716"><a href="#cb1-716" aria-hidden="true" tabindex="-1"></a><span class="co">### </span></span>
<span id="cb1-717"><a href="#cb1-717" aria-hidden="true" tabindex="-1"></a><span class="co">### SVMs do not run on qualitative data.</span></span>
<span id="cb1-718"><a href="#cb1-718" aria-hidden="true" tabindex="-1"></a><span class="co">### ALWAYS remove the Labels from the Test and Train data</span></span>
<span id="cb1-719"><a href="#cb1-719" aria-hidden="true" tabindex="-1"></a><span class="co">###</span></span>
<span id="cb1-720"><a href="#cb1-720" aria-hidden="true" tabindex="-1"></a><span class="co">### Here is what we have from above:</span></span>
<span id="cb1-721"><a href="#cb1-721" aria-hidden="true" tabindex="-1"></a><span class="co">## TrainDF_nolabels, TrainLabels</span></span>
<span id="cb1-722"><a href="#cb1-722" aria-hidden="true" tabindex="-1"></a><span class="co">### TestDF, TestLabels</span></span>
<span id="cb1-723"><a href="#cb1-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-724"><a href="#cb1-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-725"><a href="#cb1-725" aria-hidden="true" tabindex="-1"></a><span class="co">##############################</span></span>
<span id="cb1-726"><a href="#cb1-726" aria-hidden="true" tabindex="-1"></a><span class="co">## Rather than creating copies of everything</span></span>
<span id="cb1-727"><a href="#cb1-727" aria-hidden="true" tabindex="-1"></a><span class="co">## </span></span>
<span id="cb1-728"><a href="#cb1-728" aria-hidden="true" tabindex="-1"></a><span class="co">### !!!!!!!!!!!!!!!!!</span></span>
<span id="cb1-729"><a href="#cb1-729" aria-hidden="true" tabindex="-1"></a><span class="co">##  You can set the variables: TRAIN, TRAIN_Labels</span></span>
<span id="cb1-730"><a href="#cb1-730" aria-hidden="true" tabindex="-1"></a><span class="co">##                            </span><span class="al">TEST</span><span class="co"> and TEST_Labels</span></span>
<span id="cb1-731"><a href="#cb1-731" aria-hidden="true" tabindex="-1"></a><span class="co">## to whatever you wish</span></span>
<span id="cb1-732"><a href="#cb1-732" aria-hidden="true" tabindex="-1"></a><span class="co">######################################################</span></span>
<span id="cb1-733"><a href="#cb1-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-734"><a href="#cb1-734" aria-hidden="true" tabindex="-1"></a>TRAIN<span class="op">=</span> TrainDF1   <span class="co">## As noted above - this can also be TrainDF2, etc.</span></span>
<span id="cb1-735"><a href="#cb1-735" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TRAIN)</span>
<span id="cb1-736"><a href="#cb1-736" aria-hidden="true" tabindex="-1"></a>TRAIN_Labels<span class="op">=</span> Train1Labels</span>
<span id="cb1-737"><a href="#cb1-737" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(TRAIN_Labels)</span>
<span id="cb1-738"><a href="#cb1-738" aria-hidden="true" tabindex="-1"></a>TEST<span class="op">=</span> TestDF1</span>
<span id="cb1-739"><a href="#cb1-739" aria-hidden="true" tabindex="-1"></a>TEST_Labels<span class="op">=</span> Test1Labels</span>
<span id="cb1-740"><a href="#cb1-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-741"><a href="#cb1-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-742"><a href="#cb1-742" aria-hidden="true" tabindex="-1"></a>SVM_Model1<span class="op">=</span>LinearSVC(C<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-743"><a href="#cb1-743" aria-hidden="true" tabindex="-1"></a>SVM_Model1.fit(TRAIN, TRAIN_Labels)</span>
<span id="cb1-744"><a href="#cb1-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-745"><a href="#cb1-745" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model1.predict(</span><span class="al">TEST</span><span class="co">))</span></span>
<span id="cb1-746"><a href="#cb1-746" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-747"><a href="#cb1-747" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TEST_Labels)</span></span>
<span id="cb1-748"><a href="#cb1-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-749"><a href="#cb1-749" aria-hidden="true" tabindex="-1"></a>SVM_matrix <span class="op">=</span> confusion_matrix(TEST_Labels, SVM_Model1.predict(TEST))</span>
<span id="cb1-750"><a href="#cb1-750" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-751"><a href="#cb1-751" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix)</span>
<span id="cb1-752"><a href="#cb1-752" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-753"><a href="#cb1-753" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------other kernels</span></span>
<span id="cb1-754"><a href="#cb1-754" aria-hidden="true" tabindex="-1"></a><span class="co">## RBF------------------------------------------</span></span>
<span id="cb1-755"><a href="#cb1-755" aria-hidden="true" tabindex="-1"></a><span class="co">##------------------------------------------------------</span></span>
<span id="cb1-756"><a href="#cb1-756" aria-hidden="true" tabindex="-1"></a>SVM_Model2<span class="op">=</span>sklearn.svm.SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span><span class="st">'rbf'</span>, </span>
<span id="cb1-757"><a href="#cb1-757" aria-hidden="true" tabindex="-1"></a>                           verbose<span class="op">=</span><span class="va">True</span>, gamma<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb1-758"><a href="#cb1-758" aria-hidden="true" tabindex="-1"></a>SVM_Model2.fit(TRAIN, TRAIN_Labels)</span>
<span id="cb1-759"><a href="#cb1-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-760"><a href="#cb1-760" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model2.predict(</span><span class="al">TEST</span><span class="co">))</span></span>
<span id="cb1-761"><a href="#cb1-761" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-762"><a href="#cb1-762" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TEST_Labels)</span></span>
<span id="cb1-763"><a href="#cb1-763" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RBF  :</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-764"><a href="#cb1-764" aria-hidden="true" tabindex="-1"></a>SVM_matrix2 <span class="op">=</span> confusion_matrix(TEST_Labels, SVM_Model2.predict(TEST))</span>
<span id="cb1-765"><a href="#cb1-765" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-766"><a href="#cb1-766" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix2)</span>
<span id="cb1-767"><a href="#cb1-767" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-768"><a href="#cb1-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-769"><a href="#cb1-769" aria-hidden="true" tabindex="-1"></a><span class="co">##-----------------------------------------</span></span>
<span id="cb1-770"><a href="#cb1-770" aria-hidden="true" tabindex="-1"></a><span class="co">## POLY</span></span>
<span id="cb1-771"><a href="#cb1-771" aria-hidden="true" tabindex="-1"></a><span class="co">##_--------------------------------------------------</span></span>
<span id="cb1-772"><a href="#cb1-772" aria-hidden="true" tabindex="-1"></a>SVM_Model3<span class="op">=</span>sklearn.svm.SVC(C<span class="op">=</span><span class="dv">100</span>, kernel<span class="op">=</span><span class="st">'poly'</span>,degree<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb1-773"><a href="#cb1-773" aria-hidden="true" tabindex="-1"></a>                           gamma<span class="op">=</span><span class="st">"auto"</span>, verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-774"><a href="#cb1-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-775"><a href="#cb1-775" aria-hidden="true" tabindex="-1"></a><span class="co">#print(SVM_Model3)</span></span>
<span id="cb1-776"><a href="#cb1-776" aria-hidden="true" tabindex="-1"></a>SVM_Model3.fit(TRAIN, TRAIN_Labels)</span>
<span id="cb1-777"><a href="#cb1-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-778"><a href="#cb1-778" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model3.predict(</span><span class="al">TEST</span><span class="co">))</span></span>
<span id="cb1-779"><a href="#cb1-779" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-780"><a href="#cb1-780" aria-hidden="true" tabindex="-1"></a><span class="co">#print(TEST_Labels)</span></span>
<span id="cb1-781"><a href="#cb1-781" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"POLY Degree 2:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-782"><a href="#cb1-782" aria-hidden="true" tabindex="-1"></a>SVM_matrix3 <span class="op">=</span> confusion_matrix(TEST_Labels, SVM_Model3.predict(TEST))</span>
<span id="cb1-783"><a href="#cb1-783" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-784"><a href="#cb1-784" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix3)</span>
<span id="cb1-785"><a href="#cb1-785" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-786"><a href="#cb1-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-787"><a href="#cb1-787" aria-hidden="true" tabindex="-1"></a><span class="co">###################################################</span></span>
<span id="cb1-788"><a href="#cb1-788" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-789"><a href="#cb1-789" aria-hidden="true" tabindex="-1"></a><span class="co">##   Visualizing the top features</span></span>
<span id="cb1-790"><a href="#cb1-790" aria-hidden="true" tabindex="-1"></a><span class="co">##   Then Visualizing the margin with the top 2 in 2D</span></span>
<span id="cb1-791"><a href="#cb1-791" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-792"><a href="#cb1-792" aria-hidden="true" tabindex="-1"></a><span class="co">##########################################################</span></span>
<span id="cb1-793"><a href="#cb1-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-794"><a href="#cb1-794" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-795"><a href="#cb1-795" aria-hidden="true" tabindex="-1"></a><span class="co">## Credit: https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d</span></span>
<span id="cb1-796"><a href="#cb1-796" aria-hidden="true" tabindex="-1"></a><span class="co">## Define a function to visualize the TOP words (variables)</span></span>
<span id="cb1-797"><a href="#cb1-797" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_coefficients(MODEL<span class="op">=</span>SVM_Model, COLNAMES<span class="op">=</span>TrainDF1.columns, top_features<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb1-798"><a href="#cb1-798" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Model if SVM MUST be SVC, RE: SVM_Model=LinearSVC(C=10)</span></span>
<span id="cb1-799"><a href="#cb1-799" aria-hidden="true" tabindex="-1"></a>    coef <span class="op">=</span> MODEL.coef_.ravel()</span>
<span id="cb1-800"><a href="#cb1-800" aria-hidden="true" tabindex="-1"></a>    top_positive_coefficients <span class="op">=</span> np.argsort(coef,axis<span class="op">=</span><span class="dv">0</span>)[<span class="op">-</span>top_features:]</span>
<span id="cb1-801"><a href="#cb1-801" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(top_positive_coefficients)</span>
<span id="cb1-802"><a href="#cb1-802" aria-hidden="true" tabindex="-1"></a>    top_negative_coefficients <span class="op">=</span> np.argsort(coef,axis<span class="op">=</span><span class="dv">0</span>)[:top_features]</span>
<span id="cb1-803"><a href="#cb1-803" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(top_negative_coefficients)</span>
<span id="cb1-804"><a href="#cb1-804" aria-hidden="true" tabindex="-1"></a>    top_coefficients <span class="op">=</span> np.hstack([top_negative_coefficients, top_positive_coefficients])</span>
<span id="cb1-805"><a href="#cb1-805" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create plot</span></span>
<span id="cb1-806"><a href="#cb1-806" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb1-807"><a href="#cb1-807" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> [<span class="st">"red"</span> <span class="cf">if</span> c <span class="op">&lt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">"blue"</span> <span class="cf">for</span> c <span class="kw">in</span> coef[top_coefficients]]</span>
<span id="cb1-808"><a href="#cb1-808" aria-hidden="true" tabindex="-1"></a>    plt.bar(  x<span class="op">=</span>  np.arange(<span class="dv">2</span> <span class="op">*</span> top_features)  , height<span class="op">=</span>coef[top_coefficients], width<span class="op">=</span><span class="fl">.5</span>,  color<span class="op">=</span>colors)</span>
<span id="cb1-809"><a href="#cb1-809" aria-hidden="true" tabindex="-1"></a>    feature_names <span class="op">=</span> np.array(COLNAMES)</span>
<span id="cb1-810"><a href="#cb1-810" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="dv">0</span>, (<span class="dv">2</span><span class="op">*</span>top_features)), feature_names[top_coefficients], rotation<span class="op">=</span><span class="dv">60</span>, ha<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb1-811"><a href="#cb1-811" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb1-812"><a href="#cb1-812" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-813"><a href="#cb1-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-814"><a href="#cb1-814" aria-hidden="true" tabindex="-1"></a>plot_coefficients()</span>
<span id="cb1-815"><a href="#cb1-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-816"><a href="#cb1-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-817"><a href="#cb1-817" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-818"><a href="#cb1-818" aria-hidden="true" tabindex="-1"></a><span class="co">##  Using the top 2 features from above</span></span>
<span id="cb1-819"><a href="#cb1-819" aria-hidden="true" tabindex="-1"></a><span class="co">## Let's look at the margin of the SVM</span></span>
<span id="cb1-820"><a href="#cb1-820" aria-hidden="true" tabindex="-1"></a><span class="co">##################################################################</span></span>
<span id="cb1-821"><a href="#cb1-821" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-822"><a href="#cb1-822" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([TRAIN[<span class="st">"dog"</span>], TRAIN[<span class="st">"hike"</span>]])</span>
<span id="cb1-823"><a href="#cb1-823" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.transpose()</span>
<span id="cb1-824"><a href="#cb1-824" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X)</span>
<span id="cb1-825"><a href="#cb1-825" aria-hidden="true" tabindex="-1"></a><span class="co">#The classes of the training data</span></span>
<span id="cb1-826"><a href="#cb1-826" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> TRAIN_Labels</span>
<span id="cb1-827"><a href="#cb1-827" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y)</span>
<span id="cb1-828"><a href="#cb1-828" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelBinarizer</span>
<span id="cb1-829"><a href="#cb1-829" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-830"><a href="#cb1-830" aria-hidden="true" tabindex="-1"></a>lb <span class="op">=</span> preprocessing.LabelBinarizer()</span>
<span id="cb1-831"><a href="#cb1-831" aria-hidden="true" tabindex="-1"></a>y<span class="op">=</span>lb.fit_transform(y)</span>
<span id="cb1-832"><a href="#cb1-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-833"><a href="#cb1-833" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array(y)</span>
<span id="cb1-834"><a href="#cb1-834" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.ravel()  <span class="co">## to make it the right 1D array type</span></span>
<span id="cb1-835"><a href="#cb1-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-836"><a href="#cb1-836" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y)</span>
<span id="cb1-837"><a href="#cb1-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-838"><a href="#cb1-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-839"><a href="#cb1-839" aria-hidden="true" tabindex="-1"></a><span class="co">## Here - we need to make y into 0 or 1 so it will plot</span></span>
<span id="cb1-840"><a href="#cb1-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-841"><a href="#cb1-841" aria-hidden="true" tabindex="-1"></a><span class="co">#TRAIN</span></span>
<span id="cb1-842"><a href="#cb1-842" aria-hidden="true" tabindex="-1"></a><span class="co">#Define the model with SVC</span></span>
<span id="cb1-843"><a href="#cb1-843" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit SVM with training data</span></span>
<span id="cb1-844"><a href="#cb1-844" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span><span class="st">"linear"</span>)</span>
<span id="cb1-845"><a href="#cb1-845" aria-hidden="true" tabindex="-1"></a>clf.fit(X, y) </span>
<span id="cb1-846"><a href="#cb1-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-847"><a href="#cb1-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-848"><a href="#cb1-848" aria-hidden="true" tabindex="-1"></a>margin <span class="op">=</span> <span class="dv">2</span> <span class="op">/</span> np.sqrt(np.<span class="bu">sum</span>(clf.coef_ <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb1-849"><a href="#cb1-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-850"><a href="#cb1-850" aria-hidden="true" tabindex="-1"></a><span class="co"># get the separating hyperplane</span></span>
<span id="cb1-851"><a href="#cb1-851" aria-hidden="true" tabindex="-1"></a><span class="co">#The weights vector w</span></span>
<span id="cb1-852"><a href="#cb1-852" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> clf.coef_[<span class="dv">0</span>]</span>
<span id="cb1-853"><a href="#cb1-853" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The weight vector ", w)</span></span>
<span id="cb1-854"><a href="#cb1-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-855"><a href="#cb1-855" aria-hidden="true" tabindex="-1"></a><span class="co">#The slope of the SVM sep line</span></span>
<span id="cb1-856"><a href="#cb1-856" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="op">-</span>w[<span class="dv">0</span>] <span class="op">/</span> w[<span class="dv">1</span>]</span>
<span id="cb1-857"><a href="#cb1-857" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The slope of the SVM sep line is ", a)</span></span>
<span id="cb1-858"><a href="#cb1-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-859"><a href="#cb1-859" aria-hidden="true" tabindex="-1"></a><span class="co">#Create a variable xx that are values between 4 and 8</span></span>
<span id="cb1-860"><a href="#cb1-860" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb1-861"><a href="#cb1-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-862"><a href="#cb1-862" aria-hidden="true" tabindex="-1"></a><span class="co">#Equation of sep line in 2D</span></span>
<span id="cb1-863"><a href="#cb1-863" aria-hidden="true" tabindex="-1"></a><span class="co"># x1  = - b/w1  - (w0/w1 )(x0)</span></span>
<span id="cb1-864"><a href="#cb1-864" aria-hidden="true" tabindex="-1"></a><span class="co">## Note that clf_intercept_[0] is "b"</span></span>
<span id="cb1-865"><a href="#cb1-865" aria-hidden="true" tabindex="-1"></a><span class="co">## Note that a  = -w0/w1 and xx are a bunch of x values</span></span>
<span id="cb1-866"><a href="#cb1-866" aria-hidden="true" tabindex="-1"></a><span class="co">## This is the y values for the main sep line</span></span>
<span id="cb1-867"><a href="#cb1-867" aria-hidden="true" tabindex="-1"></a>yy <span class="op">=</span> a <span class="op">*</span> xx <span class="op">-</span> (clf.intercept_[<span class="dv">0</span>]) <span class="op">/</span> w[<span class="dv">1</span>]</span>
<span id="cb1-868"><a href="#cb1-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-869"><a href="#cb1-869" aria-hidden="true" tabindex="-1"></a><span class="co">##These plot the two parellel margin lines</span></span>
<span id="cb1-870"><a href="#cb1-870" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the parallel lines to the separating hyperplane </span></span>
<span id="cb1-871"><a href="#cb1-871" aria-hidden="true" tabindex="-1"></a><span class="co">#that pass through the support vectors and note the margin</span></span>
<span id="cb1-872"><a href="#cb1-872" aria-hidden="true" tabindex="-1"></a><span class="co">#margin = 2 / np.sqrt(np.sum(clf.coef_ ** 2))</span></span>
<span id="cb1-873"><a href="#cb1-873" aria-hidden="true" tabindex="-1"></a><span class="co">#translate the location of the center sep line by</span></span>
<span id="cb1-874"><a href="#cb1-874" aria-hidden="true" tabindex="-1"></a><span class="co"># adding or subtracting a fraaction of the margin </span></span>
<span id="cb1-875"><a href="#cb1-875" aria-hidden="true" tabindex="-1"></a>yy_down <span class="op">=</span> yy <span class="op">+</span> <span class="fl">.5</span><span class="op">*</span>margin</span>
<span id="cb1-876"><a href="#cb1-876" aria-hidden="true" tabindex="-1"></a>yy_up <span class="op">=</span> yy <span class="op">-</span> <span class="fl">.5</span><span class="op">*</span>margin</span>
<span id="cb1-877"><a href="#cb1-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-878"><a href="#cb1-878" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the line, the points, and the nearest vectors to the plane</span></span>
<span id="cb1-879"><a href="#cb1-879" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.figure(fignum, figsize=(4, 3))</span></span>
<span id="cb1-880"><a href="#cb1-880" aria-hidden="true" tabindex="-1"></a>plt.clf()</span>
<span id="cb1-881"><a href="#cb1-881" aria-hidden="true" tabindex="-1"></a>plt.plot(xx, yy, <span class="st">'r-'</span>)</span>
<span id="cb1-882"><a href="#cb1-882" aria-hidden="true" tabindex="-1"></a>plt.plot(xx, yy_down, <span class="st">'k--'</span>)</span>
<span id="cb1-883"><a href="#cb1-883" aria-hidden="true" tabindex="-1"></a>plt.plot(xx, yy_up, <span class="st">'k--'</span>)</span>
<span id="cb1-884"><a href="#cb1-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-885"><a href="#cb1-885" aria-hidden="true" tabindex="-1"></a>plt.scatter(clf.support_vectors_[:, <span class="dv">0</span>], clf.support_vectors_[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb1-886"><a href="#cb1-886" aria-hidden="true" tabindex="-1"></a>                facecolors<span class="op">=</span><span class="st">'none'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb1-887"><a href="#cb1-887" aria-hidden="true" tabindex="-1"></a><span class="co">#cmap is the color map</span></span>
<span id="cb1-888"><a href="#cb1-888" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, zorder<span class="op">=</span><span class="dv">5</span>, cmap<span class="op">=</span>plt.cm.Paired)</span>
<span id="cb1-889"><a href="#cb1-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-890"><a href="#cb1-890" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'tight'</span>)</span>
<span id="cb1-891"><a href="#cb1-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-892"><a href="#cb1-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-893"><a href="#cb1-893" aria-hidden="true" tabindex="-1"></a><span class="co">##@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-894"><a href="#cb1-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-895"><a href="#cb1-895" aria-hidden="true" tabindex="-1"></a><span class="co">##################################################################</span></span>
<span id="cb1-896"><a href="#cb1-896" aria-hidden="true" tabindex="-1"></a><span class="co">#############   PART 2 Using the Student Dataset #################</span></span>
<span id="cb1-897"><a href="#cb1-897" aria-hidden="true" tabindex="-1"></a><span class="co">##################################################################</span></span>
<span id="cb1-898"><a href="#cb1-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-899"><a href="#cb1-899" aria-hidden="true" tabindex="-1"></a><span class="co">##@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-900"><a href="#cb1-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-901"><a href="#cb1-901" aria-hidden="true" tabindex="-1"></a><span class="co">## The student dataset is not text data and so does not need to be </span></span>
<span id="cb1-902"><a href="#cb1-902" aria-hidden="true" tabindex="-1"></a><span class="co">## vectorized.</span></span>
<span id="cb1-903"><a href="#cb1-903" aria-hidden="true" tabindex="-1"></a><span class="co">## Also, the student dataset is clean. This will not normally</span></span>
<span id="cb1-904"><a href="#cb1-904" aria-hidden="true" tabindex="-1"></a><span class="co">## be the case.</span></span>
<span id="cb1-905"><a href="#cb1-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-906"><a href="#cb1-906" aria-hidden="true" tabindex="-1"></a><span class="co">#####################################################################</span></span>
<span id="cb1-907"><a href="#cb1-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-908"><a href="#cb1-908" aria-hidden="true" tabindex="-1"></a><span class="co">## Read the data into a dataframe</span></span>
<span id="cb1-909"><a href="#cb1-909" aria-hidden="true" tabindex="-1"></a><span class="co">## DATA: Just numeric and record labeled data</span></span>
<span id="cb1-910"><a href="#cb1-910" aria-hidden="true" tabindex="-1"></a><span class="co">## https://drive.google.com/file/d/1uXtDBIP-dTbFNXbZC0DcCKxIXjocW3xF/view?usp=sharing</span></span>
<span id="cb1-911"><a href="#cb1-911" aria-hidden="true" tabindex="-1"></a><span class="co">## ## There is also another dataset for which the labels are numbers and not words...</span></span>
<span id="cb1-912"><a href="#cb1-912" aria-hidden="true" tabindex="-1"></a><span class="co">## https://drive.google.com/file/d/1g0go050nV02Fibk_9RGpBRGnMwIGQZu5/view?usp=sharing</span></span>
<span id="cb1-913"><a href="#cb1-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-914"><a href="#cb1-914" aria-hidden="true" tabindex="-1"></a><span class="co">########################################################################################</span></span>
<span id="cb1-915"><a href="#cb1-915" aria-hidden="true" tabindex="-1"></a>filenameNum<span class="op">=</span><span class="st">"C:/Users/profa/Documents/Python Scripts/ANLY503/DATA/StudentSummerProgramData_Numeric_Labeled.csv"</span></span>
<span id="cb1-916"><a href="#cb1-916" aria-hidden="true" tabindex="-1"></a><span class="co">#filenameNum="C:/Users/profa/Documents/Python Scripts/ANLY503/DATA/StudentSummerProgramData_Numeric_NumLabeled.csv"</span></span>
<span id="cb1-917"><a href="#cb1-917" aria-hidden="true" tabindex="-1"></a>StudentDF_Num<span class="op">=</span>pd.read_csv(filenameNum)</span>
<span id="cb1-918"><a href="#cb1-918" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentDF_Num.head())</span>
<span id="cb1-919"><a href="#cb1-919" aria-hidden="true" tabindex="-1"></a><span class="co">################# Sklearn methods such as these do not run on mixed type data...</span></span>
<span id="cb1-920"><a href="#cb1-920" aria-hidden="true" tabindex="-1"></a><span class="co">#filenameMixed="C:/Users/profa/Documents/Python Scripts/ANLY503/DATA/StudentSummerProgramData_Mixed_Labeled.csv"</span></span>
<span id="cb1-921"><a href="#cb1-921" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentDF_Mix=pd.read_csv(filenameMixed)</span></span>
<span id="cb1-922"><a href="#cb1-922" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentDF_Mix.head())</span></span>
<span id="cb1-923"><a href="#cb1-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-924"><a href="#cb1-924" aria-hidden="true" tabindex="-1"></a><span class="co">### Because the data is already clean and ready - I can seperate it</span></span>
<span id="cb1-925"><a href="#cb1-925" aria-hidden="true" tabindex="-1"></a><span class="co">## into TRAINING and </span><span class="al">TESTING</span><span class="co"> sets</span></span>
<span id="cb1-926"><a href="#cb1-926" aria-hidden="true" tabindex="-1"></a><span class="co">####-----------------------------------------------</span></span>
<span id="cb1-927"><a href="#cb1-927" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-928"><a href="#cb1-928" aria-hidden="true" tabindex="-1"></a>StudentTrainDF_Num, StudentTestDF_Num <span class="op">=</span> train_test_split(StudentDF_Num, test_size<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb1-929"><a href="#cb1-929" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentTrainDF_Mix, StudentTestDF_Mix = train_test_split(StudentDF_Mix, test_size=0.3)</span></span>
<span id="cb1-930"><a href="#cb1-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-931"><a href="#cb1-931" aria-hidden="true" tabindex="-1"></a><span class="co">######## Seperate LABELS FROM DATA--------------------</span></span>
<span id="cb1-932"><a href="#cb1-932" aria-hidden="true" tabindex="-1"></a><span class="co">## Make sure you know the name of the label</span></span>
<span id="cb1-933"><a href="#cb1-933" aria-hidden="true" tabindex="-1"></a><span class="co">## For both datasets above  - in this case - it is "Decision"</span></span>
<span id="cb1-934"><a href="#cb1-934" aria-hidden="true" tabindex="-1"></a><span class="co">## </span><span class="al">TEST</span><span class="co"> - Num</span></span>
<span id="cb1-935"><a href="#cb1-935" aria-hidden="true" tabindex="-1"></a>StudentTestLabels_Num<span class="op">=</span>StudentTestDF_Num[<span class="st">"Decision"</span>]  <span class="co">## save labels</span></span>
<span id="cb1-936"><a href="#cb1-936" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentTestLabels_Num)</span>
<span id="cb1-937"><a href="#cb1-937" aria-hidden="true" tabindex="-1"></a>StudentTestData_Num <span class="op">=</span> StudentTestDF_Num.drop([<span class="st">"Decision"</span>], axis<span class="op">=</span><span class="dv">1</span>)  <span class="co">##drop labels</span></span>
<span id="cb1-938"><a href="#cb1-938" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentTestData_Num)</span>
<span id="cb1-939"><a href="#cb1-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-940"><a href="#cb1-940" aria-hidden="true" tabindex="-1"></a><span class="co">## TRAIN - Num</span></span>
<span id="cb1-941"><a href="#cb1-941" aria-hidden="true" tabindex="-1"></a>StudentTrainLabels_Num<span class="op">=</span>StudentTrainDF_Num[<span class="st">"Decision"</span>]  <span class="co">## save labels</span></span>
<span id="cb1-942"><a href="#cb1-942" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentTrainLabels_Num)</span>
<span id="cb1-943"><a href="#cb1-943" aria-hidden="true" tabindex="-1"></a>StudentTrainData_Num <span class="op">=</span> StudentTrainDF_Num.drop([<span class="st">"Decision"</span>], axis<span class="op">=</span><span class="dv">1</span>)  <span class="co">##drop labels</span></span>
<span id="cb1-944"><a href="#cb1-944" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentTrainData_Num)</span>
<span id="cb1-945"><a href="#cb1-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-946"><a href="#cb1-946" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="al">TEST</span><span class="co"> - Mixed</span></span>
<span id="cb1-947"><a href="#cb1-947" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentTestLabels_Mix=StudentTestDF_Mix["Decision"]  ## save labels</span></span>
<span id="cb1-948"><a href="#cb1-948" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Mix)</span></span>
<span id="cb1-949"><a href="#cb1-949" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentTestData_Mix = StudentTestDF_Mix.drop(["Decision"], axis=1)  ##drop labels</span></span>
<span id="cb1-950"><a href="#cb1-950" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestData_Mix)</span></span>
<span id="cb1-951"><a href="#cb1-951" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-952"><a href="#cb1-952" aria-hidden="true" tabindex="-1"></a><span class="co">### TRAIN - Mixed</span></span>
<span id="cb1-953"><a href="#cb1-953" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentTrainLabels_Mix=StudentTrainDF_Mix["Decision"]  ## save labels</span></span>
<span id="cb1-954"><a href="#cb1-954" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainLabels_Mix)</span></span>
<span id="cb1-955"><a href="#cb1-955" aria-hidden="true" tabindex="-1"></a><span class="co">#StudentTrainData_Mix = StudentTrainDF_Mix.drop(["Decision"], axis=1)  ##drop labels</span></span>
<span id="cb1-956"><a href="#cb1-956" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainData_Mix)</span></span>
<span id="cb1-957"><a href="#cb1-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-958"><a href="#cb1-958" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-959"><a href="#cb1-959" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestData_Num)</span></span>
<span id="cb1-960"><a href="#cb1-960" aria-hidden="true" tabindex="-1"></a><span class="co">### TRAIN - Num</span></span>
<span id="cb1-961"><a href="#cb1-961" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainLabels_Num)</span></span>
<span id="cb1-962"><a href="#cb1-962" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainData_Num)</span></span>
<span id="cb1-963"><a href="#cb1-963" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################</span></span>
<span id="cb1-964"><a href="#cb1-964" aria-hidden="true" tabindex="-1"></a><span class="co">## SCALE ALL DATA to between 0 and 1</span></span>
<span id="cb1-965"><a href="#cb1-965" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn import preprocessing</span></span>
<span id="cb1-966"><a href="#cb1-966" aria-hidden="true" tabindex="-1"></a><span class="co">###########################################################</span></span>
<span id="cb1-967"><a href="#cb1-967" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> StudentTrainData_Num.values <span class="co">#returns a numpy array</span></span>
<span id="cb1-968"><a href="#cb1-968" aria-hidden="true" tabindex="-1"></a>min_max_scaler <span class="op">=</span> preprocessing.MinMaxScaler()</span>
<span id="cb1-969"><a href="#cb1-969" aria-hidden="true" tabindex="-1"></a>x_scaled <span class="op">=</span> min_max_scaler.fit_transform(x)</span>
<span id="cb1-970"><a href="#cb1-970" aria-hidden="true" tabindex="-1"></a>StudentTrainData_Num_S <span class="op">=</span> pd.DataFrame(x_scaled)</span>
<span id="cb1-971"><a href="#cb1-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-972"><a href="#cb1-972" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> StudentTestData_Num.values <span class="co">#returns a numpy array</span></span>
<span id="cb1-973"><a href="#cb1-973" aria-hidden="true" tabindex="-1"></a>min_max_scaler2 <span class="op">=</span> preprocessing.MinMaxScaler()</span>
<span id="cb1-974"><a href="#cb1-974" aria-hidden="true" tabindex="-1"></a>x_scaled2 <span class="op">=</span> min_max_scaler2.fit_transform(x2)</span>
<span id="cb1-975"><a href="#cb1-975" aria-hidden="true" tabindex="-1"></a>StudentTestData_Num_S <span class="op">=</span> pd.DataFrame(x_scaled2)</span>
<span id="cb1-976"><a href="#cb1-976" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(StudentTestData_Num_S)</span>
<span id="cb1-977"><a href="#cb1-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-978"><a href="#cb1-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-979"><a href="#cb1-979" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################################</span></span>
<span id="cb1-980"><a href="#cb1-980" aria-hidden="true" tabindex="-1"></a><span class="co">########################### Naive Bayes ############################</span></span>
<span id="cb1-981"><a href="#cb1-981" aria-hidden="true" tabindex="-1"></a><span class="co">####################################################################</span></span>
<span id="cb1-982"><a href="#cb1-982" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.naive_bayes import MultinomialNB</span></span>
<span id="cb1-983"><a href="#cb1-983" aria-hidden="true" tabindex="-1"></a><span class="co">#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit</span></span>
<span id="cb1-984"><a href="#cb1-984" aria-hidden="true" tabindex="-1"></a><span class="co">#Create the modeler</span></span>
<span id="cb1-985"><a href="#cb1-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-986"><a href="#cb1-986" aria-hidden="true" tabindex="-1"></a><span class="co">############# In Python - unlike R - you cannot run a standard NB on </span></span>
<span id="cb1-987"><a href="#cb1-987" aria-hidden="true" tabindex="-1"></a><span class="co">## Mixed data. Therefore, we will only run it on our numeric dataset.</span></span>
<span id="cb1-988"><a href="#cb1-988" aria-hidden="true" tabindex="-1"></a><span class="co">##################</span></span>
<span id="cb1-989"><a href="#cb1-989" aria-hidden="true" tabindex="-1"></a>MyModelNB_Num<span class="op">=</span> MultinomialNB()</span>
<span id="cb1-990"><a href="#cb1-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-991"><a href="#cb1-991" aria-hidden="true" tabindex="-1"></a><span class="co">## When you look up this model, you learn that it wants the </span></span>
<span id="cb1-992"><a href="#cb1-992" aria-hidden="true" tabindex="-1"></a><span class="co">## DF seperate from the labels</span></span>
<span id="cb1-993"><a href="#cb1-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-994"><a href="#cb1-994" aria-hidden="true" tabindex="-1"></a>MyModelNB_Num.fit(StudentTrainData_Num, StudentTrainLabels_Num)</span>
<span id="cb1-995"><a href="#cb1-995" aria-hidden="true" tabindex="-1"></a>PredictionNB <span class="op">=</span> MyModelNB_Num.predict(StudentTestData_Num)</span>
<span id="cb1-996"><a href="#cb1-996" aria-hidden="true" tabindex="-1"></a><span class="co">#print("\nThe prediction from NB is:")</span></span>
<span id="cb1-997"><a href="#cb1-997" aria-hidden="true" tabindex="-1"></a><span class="co">#print(PredictionNB)</span></span>
<span id="cb1-998"><a href="#cb1-998" aria-hidden="true" tabindex="-1"></a><span class="co">#print("\nThe actual labels are:")</span></span>
<span id="cb1-999"><a href="#cb1-999" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1000"><a href="#cb1-1000" aria-hidden="true" tabindex="-1"></a><span class="co">## confusion matrix</span></span>
<span id="cb1-1001"><a href="#cb1-1001" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.metrics import confusion_matrix</span></span>
<span id="cb1-1002"><a href="#cb1-1002" aria-hidden="true" tabindex="-1"></a><span class="co">## The confusion matrix is square and is labels X labels</span></span>
<span id="cb1-1003"><a href="#cb1-1003" aria-hidden="true" tabindex="-1"></a><span class="co">## We ahve two labels, so ours will be 2X2</span></span>
<span id="cb1-1004"><a href="#cb1-1004" aria-hidden="true" tabindex="-1"></a><span class="co">#The matrix shows</span></span>
<span id="cb1-1005"><a href="#cb1-1005" aria-hidden="true" tabindex="-1"></a><span class="co">## rows are the true labels</span></span>
<span id="cb1-1006"><a href="#cb1-1006" aria-hidden="true" tabindex="-1"></a><span class="co">## columns are predicted</span></span>
<span id="cb1-1007"><a href="#cb1-1007" aria-hidden="true" tabindex="-1"></a><span class="co">## it is al[habetical</span></span>
<span id="cb1-1008"><a href="#cb1-1008" aria-hidden="true" tabindex="-1"></a><span class="co">## The numbers are how many </span></span>
<span id="cb1-1009"><a href="#cb1-1009" aria-hidden="true" tabindex="-1"></a>cnf_matrix <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, PredictionNB)</span>
<span id="cb1-1010"><a href="#cb1-1010" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1011"><a href="#cb1-1011" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix)</span>
<span id="cb1-1012"><a href="#cb1-1012" aria-hidden="true" tabindex="-1"></a><span class="co">### prediction probabilities</span></span>
<span id="cb1-1013"><a href="#cb1-1013" aria-hidden="true" tabindex="-1"></a><span class="co">## columns are the labels in alphabetical order</span></span>
<span id="cb1-1014"><a href="#cb1-1014" aria-hidden="true" tabindex="-1"></a><span class="co">## The decinal in the matrix are the prob of being</span></span>
<span id="cb1-1015"><a href="#cb1-1015" aria-hidden="true" tabindex="-1"></a><span class="co">## that label</span></span>
<span id="cb1-1016"><a href="#cb1-1016" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(MyModelNB_Num.predict_proba(StudentTestData_Num),<span class="dv">2</span>))</span>
<span id="cb1-1017"><a href="#cb1-1017" aria-hidden="true" tabindex="-1"></a>MyModelNB_Num.get_params(deep<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-1018"><a href="#cb1-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1019"><a href="#cb1-1019" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-1020"><a href="#cb1-1020" aria-hidden="true" tabindex="-1"></a><span class="co">#from mpl_toolkits.mplot3d import Axes3D </span></span>
<span id="cb1-1021"><a href="#cb1-1021" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-1022"><a href="#cb1-1022" aria-hidden="true" tabindex="-1"></a><span class="co">## remap labels to numbers to view</span></span>
<span id="cb1-1023"><a href="#cb1-1023" aria-hidden="true" tabindex="-1"></a>ymap<span class="op">=</span>StudentTrainLabels_Num</span>
<span id="cb1-1024"><a href="#cb1-1024" aria-hidden="true" tabindex="-1"></a>ymap<span class="op">=</span>ymap.replace(<span class="st">"Admit"</span>, <span class="dv">1</span>)</span>
<span id="cb1-1025"><a href="#cb1-1025" aria-hidden="true" tabindex="-1"></a>ymap<span class="op">=</span>ymap.replace(<span class="st">"Decline"</span>, <span class="dv">0</span>)</span>
<span id="cb1-1026"><a href="#cb1-1026" aria-hidden="true" tabindex="-1"></a>ymap<span class="op">=</span>ymap.replace(<span class="st">"Wait"</span>, <span class="dv">2</span>)</span>
<span id="cb1-1027"><a href="#cb1-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1028"><a href="#cb1-1028" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-1029"><a href="#cb1-1029" aria-hidden="true" tabindex="-1"></a>proj <span class="op">=</span> pca.fit_transform(StudentTrainData_Num)</span>
<span id="cb1-1030"><a href="#cb1-1030" aria-hidden="true" tabindex="-1"></a>plt.scatter(proj[:, <span class="dv">0</span>], proj[:, <span class="dv">1</span>], c<span class="op">=</span>ymap, cmap<span class="op">=</span><span class="st">"Paired"</span>)</span>
<span id="cb1-1031"><a href="#cb1-1031" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb1-1032"><a href="#cb1-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1033"><a href="#cb1-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1034"><a href="#cb1-1034" aria-hidden="true" tabindex="-1"></a><span class="co">#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-1035"><a href="#cb1-1035" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-1036"><a href="#cb1-1036" aria-hidden="true" tabindex="-1"></a><span class="co">#############    Decision Trees   #######################</span></span>
<span id="cb1-1037"><a href="#cb1-1037" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-1038"><a href="#cb1-1038" aria-hidden="true" tabindex="-1"></a><span class="co">#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-1039"><a href="#cb1-1039" aria-hidden="true" tabindex="-1"></a><span class="co">## In Python - the Decision Trees work ONLY on numeric data</span></span>
<span id="cb1-1040"><a href="#cb1-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1041"><a href="#cb1-1041" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="al">TEST</span></span>
<span id="cb1-1042"><a href="#cb1-1042" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1043"><a href="#cb1-1043" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestData_Num)</span></span>
<span id="cb1-1044"><a href="#cb1-1044" aria-hidden="true" tabindex="-1"></a><span class="co">### TRAIN - Num</span></span>
<span id="cb1-1045"><a href="#cb1-1045" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainLabels_Num)</span></span>
<span id="cb1-1046"><a href="#cb1-1046" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTrainData_Num)</span></span>
<span id="cb1-1047"><a href="#cb1-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1048"><a href="#cb1-1048" aria-hidden="true" tabindex="-1"></a><span class="co">#---------------------------------------------</span></span>
<span id="cb1-1049"><a href="#cb1-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1050"><a href="#cb1-1050" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-1051"><a href="#cb1-1051" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-1052"><a href="#cb1-1052" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-1053"><a href="#cb1-1053" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install python-graphviz</span></span>
<span id="cb1-1054"><a href="#cb1-1054" aria-hidden="true" tabindex="-1"></a><span class="co">## restart kernel (click the little red x next to the Console)</span></span>
<span id="cb1-1055"><a href="#cb1-1055" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz </span>
<span id="cb1-1056"><a href="#cb1-1056" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-1057"><a href="#cb1-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1058"><a href="#cb1-1058" aria-hidden="true" tabindex="-1"></a><span class="co">#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</span></span>
<span id="cb1-1059"><a href="#cb1-1059" aria-hidden="true" tabindex="-1"></a>MyDT_R<span class="op">=</span>DecisionTreeClassifier(criterion<span class="op">=</span><span class="st">'entropy'</span>, <span class="co">##"entropy" or "gini"</span></span>
<span id="cb1-1060"><a href="#cb1-1060" aria-hidden="true" tabindex="-1"></a>                            splitter<span class="op">=</span><span class="st">'best'</span>,  <span class="co">## or "random" or "best"</span></span>
<span id="cb1-1061"><a href="#cb1-1061" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-1062"><a href="#cb1-1062" aria-hidden="true" tabindex="-1"></a>                            min_samples_split<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb1-1063"><a href="#cb1-1063" aria-hidden="true" tabindex="-1"></a>                            min_samples_leaf<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb1-1064"><a href="#cb1-1064" aria-hidden="true" tabindex="-1"></a>                            min_weight_fraction_leaf<span class="op">=</span><span class="fl">0.0</span>, </span>
<span id="cb1-1065"><a href="#cb1-1065" aria-hidden="true" tabindex="-1"></a>                            max_features<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-1066"><a href="#cb1-1066" aria-hidden="true" tabindex="-1"></a>                            random_state<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-1067"><a href="#cb1-1067" aria-hidden="true" tabindex="-1"></a>                            max_leaf_nodes<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-1068"><a href="#cb1-1068" aria-hidden="true" tabindex="-1"></a>                            min_impurity_decrease<span class="op">=</span><span class="fl">0.0</span>, </span>
<span id="cb1-1069"><a href="#cb1-1069" aria-hidden="true" tabindex="-1"></a>                            min_impurity_split<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb1-1070"><a href="#cb1-1070" aria-hidden="true" tabindex="-1"></a>                            class_weight<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb1-1071"><a href="#cb1-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1072"><a href="#cb1-1072" aria-hidden="true" tabindex="-1"></a><span class="co">## perform DT</span></span>
<span id="cb1-1073"><a href="#cb1-1073" aria-hidden="true" tabindex="-1"></a>MyDT_R.fit(StudentTrainData_Num, StudentTrainLabels_Num)</span>
<span id="cb1-1074"><a href="#cb1-1074" aria-hidden="true" tabindex="-1"></a>    <span class="co">## plot the tree</span></span>
<span id="cb1-1075"><a href="#cb1-1075" aria-hidden="true" tabindex="-1"></a>tree.plot_tree(MyDT_R)</span>
<span id="cb1-1076"><a href="#cb1-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1077"><a href="#cb1-1077" aria-hidden="true" tabindex="-1"></a>feature_namesR<span class="op">=</span>StudentTrainData_Num.columns</span>
<span id="cb1-1078"><a href="#cb1-1078" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(feature_namesR)</span>
<span id="cb1-1079"><a href="#cb1-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1080"><a href="#cb1-1080" aria-hidden="true" tabindex="-1"></a><span class="co">##--------------------------------------------------------</span></span>
<span id="cb1-1081"><a href="#cb1-1081" aria-hidden="true" tabindex="-1"></a><span class="co">## VIS 1 saved as Tree_Record.pdf</span></span>
<span id="cb1-1082"><a href="#cb1-1082" aria-hidden="true" tabindex="-1"></a><span class="co">##-----------------------------------------------------------</span></span>
<span id="cb1-1083"><a href="#cb1-1083" aria-hidden="true" tabindex="-1"></a>TREE_data <span class="op">=</span> tree.export_graphviz(MyDT_R, out_file<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb1-1084"><a href="#cb1-1084" aria-hidden="true" tabindex="-1"></a>                  feature_names<span class="op">=</span>StudentTrainData_Num.columns,</span>
<span id="cb1-1085"><a href="#cb1-1085" aria-hidden="true" tabindex="-1"></a>                  filled<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb1-1086"><a href="#cb1-1086" aria-hidden="true" tabindex="-1"></a>                  rounded<span class="op">=</span><span class="va">True</span>,  </span>
<span id="cb1-1087"><a href="#cb1-1087" aria-hidden="true" tabindex="-1"></a>                  special_characters<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb1-1088"><a href="#cb1-1088" aria-hidden="true" tabindex="-1"></a>                                   </span>
<span id="cb1-1089"><a href="#cb1-1089" aria-hidden="true" tabindex="-1"></a>graph <span class="op">=</span> graphviz.Source(TREE_data) </span>
<span id="cb1-1090"><a href="#cb1-1090" aria-hidden="true" tabindex="-1"></a>graph.render(<span class="st">"Tree_Record"</span>) </span>
<span id="cb1-1091"><a href="#cb1-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1092"><a href="#cb1-1092" aria-hidden="true" tabindex="-1"></a><span class="co">##---</span></span>
<span id="cb1-1093"><a href="#cb1-1093" aria-hidden="true" tabindex="-1"></a><span class="co">## Show the predictions from the DT on the test set</span></span>
<span id="cb1-1094"><a href="#cb1-1094" aria-hidden="true" tabindex="-1"></a><span class="co">#print("\nActual\n")</span></span>
<span id="cb1-1095"><a href="#cb1-1095" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1096"><a href="#cb1-1096" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Prediction\n")</span></span>
<span id="cb1-1097"><a href="#cb1-1097" aria-hidden="true" tabindex="-1"></a>DT_pred_R<span class="op">=</span>MyDT_R.predict(StudentTestData_Num)</span>
<span id="cb1-1098"><a href="#cb1-1098" aria-hidden="true" tabindex="-1"></a><span class="co">#print(DT_pred_R)</span></span>
<span id="cb1-1099"><a href="#cb1-1099" aria-hidden="true" tabindex="-1"></a><span class="co">##_--</span></span>
<span id="cb1-1100"><a href="#cb1-1100" aria-hidden="true" tabindex="-1"></a><span class="co">## Show the confusion matrix</span></span>
<span id="cb1-1101"><a href="#cb1-1101" aria-hidden="true" tabindex="-1"></a>bn_matrix_R <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, DT_pred_R)</span>
<span id="cb1-1102"><a href="#cb1-1102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1103"><a href="#cb1-1103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bn_matrix_R)</span>
<span id="cb1-1104"><a href="#cb1-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1105"><a href="#cb1-1105" aria-hidden="true" tabindex="-1"></a><span class="co">##---</span></span>
<span id="cb1-1106"><a href="#cb1-1106" aria-hidden="true" tabindex="-1"></a><span class="co">## Feature Importance</span></span>
<span id="cb1-1107"><a href="#cb1-1107" aria-hidden="true" tabindex="-1"></a>FeatureImpR<span class="op">=</span>MyDT_R.feature_importances_   </span>
<span id="cb1-1108"><a href="#cb1-1108" aria-hidden="true" tabindex="-1"></a>indicesR <span class="op">=</span> np.argsort(FeatureImpR)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb1-1109"><a href="#cb1-1109" aria-hidden="true" tabindex="-1"></a>indicesR</span>
<span id="cb1-1110"><a href="#cb1-1110" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"feature name: "</span>, feature_namesR[indicesR])</span>
<span id="cb1-1111"><a href="#cb1-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1112"><a href="#cb1-1112" aria-hidden="true" tabindex="-1"></a><span class="co">## print out the important features.....</span></span>
<span id="cb1-1113"><a href="#cb1-1113" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> f <span class="kw">in</span> <span class="bu">range</span>(StudentTrainData_Num.shape[<span class="dv">1</span>]):</span>
<span id="cb1-1114"><a href="#cb1-1114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> FeatureImpR[indicesR[f]] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb1-1115"><a href="#cb1-1115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="sc">%d</span><span class="st">. feature </span><span class="sc">%d</span><span class="st"> (</span><span class="sc">%f</span><span class="st">)"</span> <span class="op">%</span> (f <span class="op">+</span> <span class="dv">1</span>, indicesR[f], FeatureImpR[indicesR[f]]))</span>
<span id="cb1-1116"><a href="#cb1-1116" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> (<span class="st">"feature name: "</span>, feature_namesR[indicesR[f]])</span>
<span id="cb1-1117"><a href="#cb1-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1118"><a href="#cb1-1118" aria-hidden="true" tabindex="-1"></a><span class="co">## FYI for small datasets you can zip features....</span></span>
<span id="cb1-1119"><a href="#cb1-1119" aria-hidden="true" tabindex="-1"></a><span class="co">## print(dict(zip(iris_pd.columns, clf.feature_importances_)))</span></span>
<span id="cb1-1120"><a href="#cb1-1120" aria-hidden="true" tabindex="-1"></a><span class="co">#######-----------------------------------------------------</span></span>
<span id="cb1-1121"><a href="#cb1-1121" aria-hidden="true" tabindex="-1"></a><span class="co">##  Visualize Decision Trees plotting paired surfaces</span></span>
<span id="cb1-1122"><a href="#cb1-1122" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-1123"><a href="#cb1-1123" aria-hidden="true" tabindex="-1"></a><span class="co">#####--------------------------------------------------------------</span></span>
<span id="cb1-1124"><a href="#cb1-1124" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-1125"><a href="#cb1-1125" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-1126"><a href="#cb1-1126" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-1127"><a href="#cb1-1127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1128"><a href="#cb1-1128" aria-hidden="true" tabindex="-1"></a>f1<span class="op">=</span>StudentTrainData_Num.columns.get_loc(<span class="st">"WritingScore"</span>) </span>
<span id="cb1-1129"><a href="#cb1-1129" aria-hidden="true" tabindex="-1"></a>f2<span class="op">=</span>StudentTrainData_Num.columns.get_loc(<span class="st">"TestScore"</span>) </span>
<span id="cb1-1130"><a href="#cb1-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1131"><a href="#cb1-1131" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span><span class="dv">2</span></span>
<span id="cb1-1132"><a href="#cb1-1132" aria-hidden="true" tabindex="-1"></a>plot_colors <span class="op">=</span> <span class="st">"ryb"</span></span>
<span id="cb1-1133"><a href="#cb1-1133" aria-hidden="true" tabindex="-1"></a>plot_step <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb1-1134"><a href="#cb1-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1135"><a href="#cb1-1135" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pairidx, pair <span class="kw">in</span> <span class="bu">enumerate</span>([[f1, f2], [<span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">0</span>, <span class="dv">3</span>],</span>
<span id="cb1-1136"><a href="#cb1-1136" aria-hidden="true" tabindex="-1"></a>                                [<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">3</span>]]):</span>
<span id="cb1-1137"><a href="#cb1-1137" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(TrainDF1.iloc[:,pair])</span></span>
<span id="cb1-1138"><a href="#cb1-1138" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> StudentTrainData_Num.iloc[:, pair]</span>
<span id="cb1-1139"><a href="#cb1-1139" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Because we are plotting, using our GOD and HIKE labels will not work</span></span>
<span id="cb1-1140"><a href="#cb1-1140" aria-hidden="true" tabindex="-1"></a>    <span class="co">## we need to change them to 0 and 1</span></span>
<span id="cb1-1141"><a href="#cb1-1141" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> StudentTrainLabels_Num</span>
<span id="cb1-1142"><a href="#cb1-1142" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y)</span>
<span id="cb1-1143"><a href="#cb1-1143" aria-hidden="true" tabindex="-1"></a>    oldy<span class="op">=</span>y</span>
<span id="cb1-1144"><a href="#cb1-1144" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(type(y))</span></span>
<span id="cb1-1145"><a href="#cb1-1145" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y.replace(<span class="st">"Admit"</span>, <span class="dv">1</span>)</span>
<span id="cb1-1146"><a href="#cb1-1146" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y.replace(<span class="st">"Decline"</span>, <span class="dv">0</span>)</span>
<span id="cb1-1147"><a href="#cb1-1147" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y.replace(<span class="st">"Wait"</span>, <span class="dv">2</span>)</span>
<span id="cb1-1148"><a href="#cb1-1148" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1149"><a href="#cb1-1149" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(y)</span>
<span id="cb1-1150"><a href="#cb1-1150" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train</span></span>
<span id="cb1-1151"><a href="#cb1-1151" aria-hidden="true" tabindex="-1"></a>    DTC <span class="op">=</span> DecisionTreeClassifier().fit(X, y)</span>
<span id="cb1-1152"><a href="#cb1-1152" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the decision boundary</span></span>
<span id="cb1-1153"><a href="#cb1-1153" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, pairidx <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb1-1154"><a href="#cb1-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1155"><a href="#cb1-1155" aria-hidden="true" tabindex="-1"></a>    x_min, x_max <span class="op">=</span> X.iloc[:, <span class="dv">0</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X.iloc[:, <span class="dv">0</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-1156"><a href="#cb1-1156" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(x_min)</span>
<span id="cb1-1157"><a href="#cb1-1157" aria-hidden="true" tabindex="-1"></a>    y_min, y_max <span class="op">=</span> X.iloc[:, <span class="dv">1</span>].<span class="bu">min</span>() <span class="op">-</span> <span class="dv">1</span>, X.iloc[:, <span class="dv">1</span>].<span class="bu">max</span>() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb1-1158"><a href="#cb1-1158" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb1-1159"><a href="#cb1-1159" aria-hidden="true" tabindex="-1"></a>    xx, yy <span class="op">=</span> np.meshgrid(np.arange(x_min, x_max,plot_step),</span>
<span id="cb1-1160"><a href="#cb1-1160" aria-hidden="true" tabindex="-1"></a>                         np.arange(y_min, y_max,plot_step))</span>
<span id="cb1-1161"><a href="#cb1-1161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1162"><a href="#cb1-1162" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(yy)</span></span>
<span id="cb1-1163"><a href="#cb1-1163" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1164"><a href="#cb1-1164" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout(h_pad<span class="op">=</span><span class="fl">0.5</span>, w_pad<span class="op">=</span><span class="fl">0.5</span>, pad<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb1-1165"><a href="#cb1-1165" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-1166"><a href="#cb1-1166" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> DTC.predict(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb1-1167"><a href="#cb1-1167" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb1-1168"><a href="#cb1-1168" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(Z)</span>
<span id="cb1-1169"><a href="#cb1-1169" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1170"><a href="#cb1-1170" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1171"><a href="#cb1-1171" aria-hidden="true" tabindex="-1"></a>    cs <span class="op">=</span> plt.contourf(xx, yy, Z, cmap<span class="op">=</span>plt.cm.RdYlBu)</span>
<span id="cb1-1172"><a href="#cb1-1172" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb1-1173"><a href="#cb1-1173" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X.iloc[:, <span class="dv">0</span>], X.iloc[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span>oldy,edgecolor<span class="op">=</span><span class="st">'black'</span>, </span>
<span id="cb1-1174"><a href="#cb1-1174" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#c=color, s=15)</span></span>
<span id="cb1-1175"><a href="#cb1-1175" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#label=y[i],</span></span>
<span id="cb1-1176"><a href="#cb1-1176" aria-hidden="true" tabindex="-1"></a>                    cmap<span class="op">=</span>plt.cm.RdYlBu)</span>
<span id="cb1-1177"><a href="#cb1-1177" aria-hidden="true" tabindex="-1"></a><span class="co">###---------------------------end for loop ----------------------------------</span></span>
<span id="cb1-1178"><a href="#cb1-1178" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.suptitle("Decision surface of a decision tree using paired features: Student Admissions")</span></span>
<span id="cb1-1179"><a href="#cb1-1179" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.legend(loc='lower right', borderpad=0, handletextpad=0)</span></span>
<span id="cb1-1180"><a href="#cb1-1180" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.axis("tight")</span></span>
<span id="cb1-1181"><a href="#cb1-1181" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb1-1182"><a href="#cb1-1182" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.figure()</span></span>
<span id="cb1-1183"><a href="#cb1-1183" aria-hidden="true" tabindex="-1"></a><span class="co">######################################################</span></span>
<span id="cb1-1184"><a href="#cb1-1184" aria-hidden="true" tabindex="-1"></a>    <span class="co">##  MORE DT Vis...................................</span></span>
<span id="cb1-1185"><a href="#cb1-1185" aria-hidden="true" tabindex="-1"></a><span class="co">###########################################################</span></span>
<span id="cb1-1186"><a href="#cb1-1186" aria-hidden="true" tabindex="-1"></a><span class="co"># dot_data2 = StringIO()</span></span>
<span id="cb1-1187"><a href="#cb1-1187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1188"><a href="#cb1-1188" aria-hidden="true" tabindex="-1"></a><span class="co"># export_graphviz(MyDT_R, out_file=dot_data2,  </span></span>
<span id="cb1-1189"><a href="#cb1-1189" aria-hidden="true" tabindex="-1"></a><span class="co">#                 filled=True, rounded=True,</span></span>
<span id="cb1-1190"><a href="#cb1-1190" aria-hidden="true" tabindex="-1"></a><span class="co">#                 special_characters=True,</span></span>
<span id="cb1-1191"><a href="#cb1-1191" aria-hidden="true" tabindex="-1"></a><span class="co">#                 feature_names = StudentTrainData_Num.columns)</span></span>
<span id="cb1-1192"><a href="#cb1-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1193"><a href="#cb1-1193" aria-hidden="true" tabindex="-1"></a><span class="co">#                 #class_names=['0','1'])</span></span>
<span id="cb1-1194"><a href="#cb1-1194" aria-hidden="true" tabindex="-1"></a><span class="co"># graph = pydotplus.graph_from_dot_data(dot_data2.getvalue())  </span></span>
<span id="cb1-1195"><a href="#cb1-1195" aria-hidden="true" tabindex="-1"></a><span class="co"># graph.write_png('StudentData.png')</span></span>
<span id="cb1-1196"><a href="#cb1-1196" aria-hidden="true" tabindex="-1"></a><span class="co"># Image(graph.create_png())</span></span>
<span id="cb1-1197"><a href="#cb1-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1198"><a href="#cb1-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1199"><a href="#cb1-1199" aria-hidden="true" tabindex="-1"></a><span class="co">#########################################################</span></span>
<span id="cb1-1200"><a href="#cb1-1200" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-1201"><a href="#cb1-1201" aria-hidden="true" tabindex="-1"></a><span class="co">##                 Random Forest</span></span>
<span id="cb1-1202"><a href="#cb1-1202" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb1-1203"><a href="#cb1-1203" aria-hidden="true" tabindex="-1"></a><span class="co">#################################################################</span></span>
<span id="cb1-1204"><a href="#cb1-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1205"><a href="#cb1-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1206"><a href="#cb1-1206" aria-hidden="true" tabindex="-1"></a>RF1 <span class="op">=</span> RandomForestClassifier()</span>
<span id="cb1-1207"><a href="#cb1-1207" aria-hidden="true" tabindex="-1"></a>RF1.fit(StudentTrainData_Num, StudentTrainLabels_Num)</span>
<span id="cb1-1208"><a href="#cb1-1208" aria-hidden="true" tabindex="-1"></a>RF1_pred<span class="op">=</span>RF1.predict(StudentTestData_Num)</span>
<span id="cb1-1209"><a href="#cb1-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1210"><a href="#cb1-1210" aria-hidden="true" tabindex="-1"></a>bn_matrix_RF <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, RF1_pred)</span>
<span id="cb1-1211"><a href="#cb1-1211" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1212"><a href="#cb1-1212" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bn_matrix_RF)</span>
<span id="cb1-1213"><a href="#cb1-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1214"><a href="#cb1-1214" aria-hidden="true" tabindex="-1"></a><span class="co">################# VIS RF---------------------------------</span></span>
<span id="cb1-1215"><a href="#cb1-1215" aria-hidden="true" tabindex="-1"></a>Features<span class="op">=</span>StudentTrainData_Num.columns</span>
<span id="cb1-1216"><a href="#cb1-1216" aria-hidden="true" tabindex="-1"></a><span class="co">#Targets=StudentTestLabels_Num</span></span>
<span id="cb1-1217"><a href="#cb1-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1218"><a href="#cb1-1218" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows <span class="op">=</span> <span class="dv">1</span>,ncols <span class="op">=</span> <span class="dv">1</span>,figsize <span class="op">=</span> (<span class="dv">4</span>,<span class="dv">4</span>), dpi<span class="op">=</span><span class="dv">800</span>)</span>
<span id="cb1-1219"><a href="#cb1-1219" aria-hidden="true" tabindex="-1"></a>tree.plot_tree(RF1.estimators_[<span class="dv">0</span>],</span>
<span id="cb1-1220"><a href="#cb1-1220" aria-hidden="true" tabindex="-1"></a>               feature_names <span class="op">=</span> Features, </span>
<span id="cb1-1221"><a href="#cb1-1221" aria-hidden="true" tabindex="-1"></a>               <span class="co">#class_names=Targets,</span></span>
<span id="cb1-1222"><a href="#cb1-1222" aria-hidden="true" tabindex="-1"></a>               filled <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-1223"><a href="#cb1-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1224"><a href="#cb1-1224" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">'RF_Tree'</span>)  <span class="co">## creates png</span></span>
<span id="cb1-1225"><a href="#cb1-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1226"><a href="#cb1-1226" aria-hidden="true" tabindex="-1"></a><span class="co">#####------------------&gt; View estimator Trees in RF</span></span>
<span id="cb1-1227"><a href="#cb1-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1228"><a href="#cb1-1228" aria-hidden="true" tabindex="-1"></a>fig2, axes2 <span class="op">=</span> plt.subplots(nrows <span class="op">=</span> <span class="dv">1</span>,ncols <span class="op">=</span> <span class="dv">3</span>,figsize <span class="op">=</span> (<span class="dv">10</span>,<span class="dv">2</span>), dpi<span class="op">=</span><span class="dv">900</span>)</span>
<span id="cb1-1229"><a href="#cb1-1229" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">3</span>):</span>
<span id="cb1-1230"><a href="#cb1-1230" aria-hidden="true" tabindex="-1"></a>    tree.plot_tree(RF1.estimators_[index],</span>
<span id="cb1-1231"><a href="#cb1-1231" aria-hidden="true" tabindex="-1"></a>                   feature_names <span class="op">=</span> Features, </span>
<span id="cb1-1232"><a href="#cb1-1232" aria-hidden="true" tabindex="-1"></a>                   filled <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb1-1233"><a href="#cb1-1233" aria-hidden="true" tabindex="-1"></a>                   ax <span class="op">=</span> axes2[index])</span>
<span id="cb1-1234"><a href="#cb1-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1235"><a href="#cb1-1235" aria-hidden="true" tabindex="-1"></a>    axes2[index].set_title(<span class="st">'Estimator: '</span> <span class="op">+</span> <span class="bu">str</span>(index), fontsize <span class="op">=</span> <span class="dv">11</span>)</span>
<span id="cb1-1236"><a href="#cb1-1236" aria-hidden="true" tabindex="-1"></a>fig2.savefig(<span class="st">'THREEtrees_RF.png'</span>)</span>
<span id="cb1-1237"><a href="#cb1-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1238"><a href="#cb1-1238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1239"><a href="#cb1-1239" aria-hidden="true" tabindex="-1"></a><span class="co">##@@@@@@@@@@@@@@@@@@@@@@@</span></span>
<span id="cb1-1240"><a href="#cb1-1240" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-1241"><a href="#cb1-1241" aria-hidden="true" tabindex="-1"></a><span class="co">###########  SVM ############################</span></span>
<span id="cb1-1242"><a href="#cb1-1242" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb1-1243"><a href="#cb1-1243" aria-hidden="true" tabindex="-1"></a><span class="co">#from sklearn.svm import LinearSVC</span></span>
<span id="cb1-1244"><a href="#cb1-1244" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="al">NOTE</span><span class="co"> - We CANNOT use SVM directly on the data. </span></span>
<span id="cb1-1245"><a href="#cb1-1245" aria-hidden="true" tabindex="-1"></a><span class="co">### SVMs do not run on qualitative data.</span></span>
<span id="cb1-1246"><a href="#cb1-1246" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-1247"><a href="#cb1-1247" aria-hidden="true" tabindex="-1"></a><span class="co">############  MUST NORMALIZE THE DATA!!  ################</span></span>
<span id="cb1-1248"><a href="#cb1-1248" aria-hidden="true" tabindex="-1"></a>    <span class="co">## This is done above. Notice the _S for scale after each DF</span></span>
<span id="cb1-1249"><a href="#cb1-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1250"><a href="#cb1-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1251"><a href="#cb1-1251" aria-hidden="true" tabindex="-1"></a><span class="co">##-----</span></span>
<span id="cb1-1252"><a href="#cb1-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1253"><a href="#cb1-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1254"><a href="#cb1-1254" aria-hidden="true" tabindex="-1"></a>SVM_Model1<span class="op">=</span>LinearSVC(C<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-1255"><a href="#cb1-1255" aria-hidden="true" tabindex="-1"></a>SVM_Model1.fit(StudentTrainData_Num_S, StudentTrainLabels_Num)</span>
<span id="cb1-1256"><a href="#cb1-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1257"><a href="#cb1-1257" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model1.predict(StudentTestData_Num_S))</span></span>
<span id="cb1-1258"><a href="#cb1-1258" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-1259"><a href="#cb1-1259" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1260"><a href="#cb1-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1261"><a href="#cb1-1261" aria-hidden="true" tabindex="-1"></a>SVM_matrix <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, SVM_Model1.predict(StudentTestData_Num_S))</span>
<span id="cb1-1262"><a href="#cb1-1262" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1263"><a href="#cb1-1263" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix)</span>
<span id="cb1-1264"><a href="#cb1-1264" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-1265"><a href="#cb1-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1266"><a href="#cb1-1266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1267"><a href="#cb1-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1268"><a href="#cb1-1268" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------other kernels</span></span>
<span id="cb1-1269"><a href="#cb1-1269" aria-hidden="true" tabindex="-1"></a><span class="co">## RBF</span></span>
<span id="cb1-1270"><a href="#cb1-1270" aria-hidden="true" tabindex="-1"></a>SVM_Model2<span class="op">=</span>sklearn.svm.SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span><span class="st">'rbf'</span>, degree<span class="op">=</span><span class="dv">3</span>, gamma<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb1-1271"><a href="#cb1-1271" aria-hidden="true" tabindex="-1"></a>SVM_Model2.fit(StudentTrainData_Num_S, StudentTrainLabels_Num)</span>
<span id="cb1-1272"><a href="#cb1-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1273"><a href="#cb1-1273" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model2.predict(StudentTestData_Num_S))</span></span>
<span id="cb1-1274"><a href="#cb1-1274" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-1275"><a href="#cb1-1275" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1276"><a href="#cb1-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1277"><a href="#cb1-1277" aria-hidden="true" tabindex="-1"></a>SVM_matrix2 <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, SVM_Model2.predict(StudentTestData_Num_S))</span>
<span id="cb1-1278"><a href="#cb1-1278" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1279"><a href="#cb1-1279" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix2)</span>
<span id="cb1-1280"><a href="#cb1-1280" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span>
<span id="cb1-1281"><a href="#cb1-1281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1282"><a href="#cb1-1282" aria-hidden="true" tabindex="-1"></a><span class="co">##------------------------------</span></span>
<span id="cb1-1283"><a href="#cb1-1283" aria-hidden="true" tabindex="-1"></a><span class="co">## POLY</span></span>
<span id="cb1-1284"><a href="#cb1-1284" aria-hidden="true" tabindex="-1"></a>SVM_Model3<span class="op">=</span>sklearn.svm.SVC(C<span class="op">=</span><span class="dv">100</span>, kernel<span class="op">=</span><span class="st">'poly'</span>, degree<span class="op">=</span><span class="dv">2</span>, gamma<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb1-1285"><a href="#cb1-1285" aria-hidden="true" tabindex="-1"></a>SVM_Model3.fit(StudentTrainData_Num_S, StudentTrainLabels_Num)</span>
<span id="cb1-1286"><a href="#cb1-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1287"><a href="#cb1-1287" aria-hidden="true" tabindex="-1"></a><span class="co">#print("SVM prediction:\n", SVM_Model3.predict(StudentTestData_Num_S))</span></span>
<span id="cb1-1288"><a href="#cb1-1288" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Actual:")</span></span>
<span id="cb1-1289"><a href="#cb1-1289" aria-hidden="true" tabindex="-1"></a><span class="co">#print(StudentTestLabels_Num)</span></span>
<span id="cb1-1290"><a href="#cb1-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-1291"><a href="#cb1-1291" aria-hidden="true" tabindex="-1"></a>SVM_matrix3 <span class="op">=</span> confusion_matrix(StudentTestLabels_Num, SVM_Model3.predict(StudentTestData_Num_S))</span>
<span id="cb1-1292"><a href="#cb1-1292" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The confusion matrix is:"</span>)</span>
<span id="cb1-1293"><a href="#cb1-1293" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(SVM_matrix3)</span>
<span id="cb1-1294"><a href="#cb1-1294" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>