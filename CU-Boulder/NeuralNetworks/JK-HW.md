---
layout: page
title: "Neural Networks: Jasmine's HW Submissions"
permalink: /CUB/NeuralNetworks/HW
---

# [CU Boulder](../../CUB.md): [Neural Networks](NeuralNets.md)
(Fall 2023) Neural Networks with Dr. Ami Gates at CU Boulder

# HW Submissions by Module

These are my homework submissions, so all my code. As much as possible done "from scratch" by myself. (But there are chances I got some help from Dr. Gates' above code examples.)

## Module 1

- [Assignment 1 (Jupyter Notebook)](HW/hw1/A1_JasmineKobayashi.html)
    - [Simple OOP of Logistic Regression (for this HW)](HW/hw1/hw1_log_reg_code.md)

## Module 2

- Assignment 2 
    - [Part 1: One Layer NN with One Output](HW/hw2/Part1/A2_Part1_JasmineKobayashi.html)
    - [Part 2: Multinomial NN with Softmax, CCE, and One-Hot Encoding](HW/hw2/Part2/A2_Part2_JasmineKobayashi.html)

## Module 3

- Assignment 3 
    - Part 1: ANNs in Keras
    - Part 2: Use TF/Keras to Create a CNN
    - (Part 3: Illustrate the processes for cross-correlation... (**Non coding portion**))
    - Part 4: Use TF/Keras to Create both an RNN and an LSTM and Compare Results
    - Part 5: Type out the back propagation derivatives for $\frac{\partial L}{\partial U}$
