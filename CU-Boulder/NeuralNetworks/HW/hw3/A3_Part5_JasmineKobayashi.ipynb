{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 3 Assignment - Part 5: Type out the back propagation derivatives for dL/dU\n",
    "---\n",
    "\n",
    "Type out the back propagation derivatives for $\\frac{\\partial L}{\\partial U}$ (also called $\\frac{\\partial L}{\\partial W_{xh}}$) and draw the architecture for an RNN over 4 time steps. Show all of your work. You can find an example of this on the RNN slides (PowerPoints) in Canvas in Module 3.\n",
    "\n",
    "This image shows you which weight matrix here is \"U\".\n",
    "\n",
    "![RNN image](RNN_V_W_U.jpg)\n",
    "\n",
    "The example on the slides shows $\\frac{\\partial L}{\\partial W}$. Your goals is to show $\\frac{\\partial L}{\\partial U}$.\n",
    "\n",
    "You are not required to calculate the values of the derivatives but just to show the derivatives. You can see this on slide 31 of the Module 3 *RNN_LSTM_Gates.pptx* slides.\n",
    "\n",
    "The goal of this exercise is to take deeper look at the derivatives and to practice. I recommend that you start with $\\frac{\\partial L}{\\partial W}$ (which is already given) and then do $\\frac{\\partial L}{\\partial U}$.\n",
    "\n",
    "Do NOT find the solution online and copy it into your HW :).\n",
    "\n",
    "Instead, understand the process and create the solution. In fact, I recommend trying to do it by hand on paper with no internet or help first. \n",
    "\n",
    "Then, compare with examples/web to see if you are right. If you are wrong (which is often an even better learning experience) determine why and correct it. The idea at the end is less about being \"right\" (as the solution is online) but rather to understand what you did. You will need this for the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
