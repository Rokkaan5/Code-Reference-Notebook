{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Module 3 Assignment - Part 2: Use TF/Keras to Create a CNN\"\n",
    "author: Jasmine Kobayashi\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "execute:\n",
    "  output: true\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 3 Assignment - Part 2: Use TF/Keras to Create a CNN\n",
    "---\n",
    "\n",
    "Use the Fashion MNIST **OR** Digits MNIST dataset here. This time, create a CNN in TF/Keras. Just like in Part 1, you will have Python code and you will create a Word Doc that fully illustrates your model, outcomes, data, accuracies, vis, etc.\n",
    "\n",
    "**Code Hint:** \n",
    "<https://gatesboltonanalytics.com/?page_id=898>\n",
    "\n",
    "# Requirements:\n",
    "\n",
    "- Use the `Sequential` Model\n",
    "- Have at least (more is fine) two `Conv2D` layers with all the needed parameters, shapes, number of filters, and activation.\n",
    "- Have at least two `MaxPooling` layers\n",
    "- You will need at least one `Flatten` Layer and one `Dense` Layer.\n",
    "- Use the appropriate loss function, optimizer, and metrics.\n",
    "- Illustrate your raw data, at least one image of what your training data looks like as a matrix and as an image. (The matrix may be large - so you can make it small or use a portion of it). Illustrate data sizes so that I know that you know the sizes of your training data, your testing data, etc.\n",
    "- Include the first two and last two epoch runs.\n",
    "- Include a visualization for the Loss over all epochs.\n",
    "- Include a confusion matrix.\n",
    "\n",
    "The goals here are to learn to use Keras to build a CNN Model to learn and then predict image data. It is also important to understand shapes and sizes of images, filters, etc. As you do this, make sure that you understand what you are coding and that you illustrate it (on the Word Doc) for the reader to see what you did and confirm that you know what you did :).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 23:33:35.476160: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 23:33:35.809139: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "(Using Digits MNIST again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = Data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  67, 232,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  62,  81,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 120, 180,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 126, 163,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   2, 153, 210,  40,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 220, 163,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  27, 254, 162,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 222, 163,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 183, 254, 125,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  46, 245, 163,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 198, 254,  56,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 120, 254, 163,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  23, 231, 254,  29,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 159, 254, 120,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 163, 254, 216,  16,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 159, 254,  67,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  14,  86, 178, 248, 254,  91,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 159, 254,  85,   0,   0,   0,  47,  49, 116, 144,\n",
       "        150, 241, 243, 234, 179, 241, 252,  40,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 150, 253, 237, 207, 207, 207, 253, 254, 250, 240,\n",
       "        198, 143,  91,  28,   5, 233, 250,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 119, 177, 177, 177, 177, 177,  98,  56,   0,\n",
       "          0,   0,   0,   0, 102, 254, 220,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254, 137,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254,  57,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254,  57,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 255,  94,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254,  96,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 254, 153,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 169, 255, 153,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  96, 254, 153,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdb1d027810>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZgUlEQVR4nO3df2zU953n8ddgYGLQMCuX2DNTHK+Vg2uFEd0CBXz8MGywmFVQiBMtSXQ9I7UoaQwn5ETZUnaFryvhLBUs0rqhapqloEJBJxGCBBviHNgUEboOIhsvTZGzmOAsnrr4Eo8xZBzgc3/4mN3BBvI1M3577OdD+krxzPfDvPPtV33yzcx87XPOOQEAYGCM9QAAgNGLCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNjrQe4061bt3T58mUFAgH5fD7rcQAAHjnn1N3drUgkojFj7n2tM+widPnyZRUWFlqPAQB4QG1tbZoyZco99xl2EQoEApKkBfoLjdU442kAAF7d0Jc6qSPJ/z+/l4xF6LXXXtNPfvITtbe3a/r06dq+fbsWLlx433W3/xPcWI3TWB8RAoCs8//vSPpV3lLJyAcT9u/fr/Xr12vjxo06e/asFi5cqGg0qkuXLmXi5QAAWSojEdq2bZu+973v6fvf/76++c1vavv27SosLNSOHTsy8XIAgCyV9gj19vbqzJkzKi8vT3m8vLxcp06d6rd/IpFQPB5P2QAAo0PaI3TlyhXdvHlTBQUFKY8XFBQoFov127+2tlbBYDC58ck4ABg9MvZl1TvfkHLODfgm1YYNG9TV1ZXc2traMjUSAGCYSfun4yZPnqycnJx+Vz0dHR39ro4kye/3y+/3p3sMAEAWSPuV0Pjx4zVr1izV19enPF5fX6/S0tJ0vxwAIItl5HtC1dXV+u53v6vZs2dr/vz5+vnPf65Lly7phRdeyMTLAQCyVEYitGrVKnV2durHP/6x2tvbVVJSoiNHjqioqCgTLwcAyFI+55yzHuI/i8fjCgaDKtMT3DEBALLQDfelGvSWurq6NGnSpHvuy69yAACYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMyMtR4AALzoeXqu5zV/t2XHoF7rb//yf3he497/10G91mjFlRAAwAwRAgCYSXuEampq5PP5UrZQKJTulwEAjAAZeU9o+vTpevfdd5M/5+TkZOJlAABZLiMRGjt2LFc/AID7ysh7Qi0tLYpEIiouLtYzzzyjCxcu3HXfRCKheDyesgEARoe0R2ju3LnavXu3jh49qtdff12xWEylpaXq7OwccP/a2loFg8HkVlhYmO6RAADDVNojFI1G9dRTT2nGjBl67LHHdPjwYUnSrl27Btx/w4YN6urqSm5tbW3pHgkAMExl/MuqEydO1IwZM9TS0jLg836/X36/P9NjAACGoYx/TyiRSOijjz5SOBzO9EsBALJM2iP08ssvq7GxUa2trfrtb3+rp59+WvF4XJWVlel+KQBAlkv7f4779NNP9eyzz+rKlSt6+OGHNW/ePJ0+fVpFRUXpfikAQJZLe4T27duX7j9yRLj+xHe8r/ma9y/55v3je57XANmkY7b3/4DztxdXZGASpAP3jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzGT8l9qhz+VF3ns/4dHPvb/QP3pfApgZ4/0mve6R657X/Hn+7z2vkaT/4ysd1Dp8dVwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAx30R4i/+vx/+15zd99VJ6BSYDhI+fRIs9rfr/Y+63iv/XP/93zGkmKNDUPah2+Oq6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MB0iIzz3bAeARh2xv7i2pC8zvV/mzQkrwPvuBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA9NBuLXgW57XLHzoZPoHAbLcn07sHJLXKXz35pC8DrzjSggAYIYIAQDMeI7QiRMntGLFCkUiEfl8Ph08eDDleeecampqFIlElJubq7KyMp07dy5d8wIARhDPEerp6dHMmTNVV1c34PNbtmzRtm3bVFdXp6amJoVCIS1btkzd3d0PPCwAYGTx/MGEaDSqaDQ64HPOOW3fvl0bN25URUWFJGnXrl0qKCjQ3r179fzzzz/YtACAESWt7wm1trYqFoupvLw8+Zjf79fixYt16tSpAdckEgnF4/GUDQAwOqQ1QrFYTJJUUFCQ8nhBQUHyuTvV1tYqGAwmt8LCwnSOBAAYxjLy6Tifz5fys3Ou32O3bdiwQV1dXcmtra0tEyMBAIahtH5ZNRQKSeq7IgqHw8nHOzo6+l0d3eb3++X3+9M5BgAgS6T1Sqi4uFihUEj19fXJx3p7e9XY2KjS0tJ0vhQAYATwfCV09epVffzxx8mfW1tb9cEHHygvL0+PPPKI1q9fr82bN2vq1KmaOnWqNm/erAkTJui5555L6+AAgOznOULvv/++lixZkvy5urpaklRZWalf/vKXeuWVV3T9+nW9+OKL+uyzzzR37ly98847CgQC6ZsaADAieI5QWVmZnHN3fd7n86mmpkY1NTUPMtew9snjuZ7X5OdMyMAkwPAx9k8f8bzm6bxDGZikv9zWzwa1jtueZh73jgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZtP5m1dFi7H/pHpLX+eL3fzIkrwOkQ9v2iZ7X/Df/Lc9r3ohP8bxGn8e9r8GQ4EoIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUyHsfz3vd/cESNXzuSveV7zh6emDeq18v7yU89rGqe9MYhXesjzih0/Xel5Tf4fTnleg6HBlRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYbmA5j1/O8/x1hYgbmSKdbC//M8xqX4/O8pu0xv+c1ktQb+dLzmjHjb3pe887Cf/C8Zpz3w6DYzcEdh7+58KTnNf/3lvcb7k4Y4/3YFfy22/Ma53kFhgpXQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGW5gOgiJL8Z5XnNrELdQ3Pmjv/e85tDab3leM5T+6mu/8LxmjLzfufO66/W8RpIu3/R+Q826P5Z5XvPYu+s9r/mTs+M9rwm/8wfPayTJ98mnntf88aNcz2sKcrzfMNY1NXteg+GLKyEAgBkiBAAw4zlCJ06c0IoVKxSJROTz+XTw4MGU51evXi2fz5eyzZs3L13zAgBGEM8R6unp0cyZM1VXV3fXfZYvX6729vbkduTIkQcaEgAwMnn+YEI0GlU0Gr3nPn6/X6FQaNBDAQBGh4y8J9TQ0KD8/HxNmzZNa9asUUdHx133TSQSisfjKRsAYHRIe4Si0aj27NmjY8eOaevWrWpqatLSpUuVSCQG3L+2tlbBYDC5FRYWpnskAMAwlfbvCa1atSr5zyUlJZo9e7aKiop0+PBhVVRU9Nt/w4YNqq6uTv4cj8cJEQCMEhn/smo4HFZRUZFaWloGfN7v98vv92d6DADAMJTx7wl1dnaqra1N4XA40y8FAMgynq+Erl69qo8//jj5c2trqz744APl5eUpLy9PNTU1euqppxQOh3Xx4kX96Ec/0uTJk/Xkk0+mdXAAQPbzHKH3339fS5YsSf58+/2cyspK7dixQ83Nzdq9e7c+//xzhcNhLVmyRPv371cgEEjf1ACAEcHnnPN+Z80MisfjCgaDKtMTGuvzfqPQ4aq1dr7nNYVz/j0Dk2SfP/7TFM9rvnbO+40xJWn8202DWjfS/PtflXpe8y//8+5fYL+bfVcf9rxm93/lg0vD3Q33pRr0lrq6ujRp0qR77su94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAm479ZFX2KN7xnPULWCuuS9QijzoRFfxyS1/nr4095XjNN/5yBSWCFKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAw3MAVgpugtZz0CjHElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwM9Z6AAAjQ47P+99pP5s2zvOa0D95XoJhjCshAIAZIgQAMOMpQrW1tZozZ44CgYDy8/O1cuVKnT9/PmUf55xqamoUiUSUm5ursrIynTt3Lq1DAwBGBk8RamxsVFVVlU6fPq36+nrduHFD5eXl6unpSe6zZcsWbdu2TXV1dWpqalIoFNKyZcvU3d2d9uEBANnN0wcT3n777ZSfd+7cqfz8fJ05c0aLFi2Sc07bt2/Xxo0bVVFRIUnatWuXCgoKtHfvXj3//PPpmxwAkPUe6D2hrq4uSVJeXp4kqbW1VbFYTOXl5cl9/H6/Fi9erFOnTg34ZyQSCcXj8ZQNADA6DDpCzjlVV1drwYIFKikpkSTFYjFJUkFBQcq+BQUFyefuVFtbq2AwmNwKCwsHOxIAIMsMOkJr167Vhx9+qF//+tf9nvP5fCk/O+f6PXbbhg0b1NXVldza2toGOxIAIMsM6suq69at06FDh3TixAlNmTIl+XgoFJLUd0UUDoeTj3d0dPS7OrrN7/fL7/cPZgwAQJbzdCXknNPatWt14MABHTt2TMXFxSnPFxcXKxQKqb6+PvlYb2+vGhsbVVpamp6JAQAjhqcroaqqKu3du1dvvfWWAoFA8n2eYDCo3Nxc+Xw+rV+/Xps3b9bUqVM1depUbd68WRMmTNBzzz2XkX8BAED28hShHTt2SJLKyspSHt+5c6dWr14tSXrllVd0/fp1vfjii/rss880d+5cvfPOOwoEAmkZGAAwcniKkHPuvvv4fD7V1NSopqZmsDMByEI33S3vi7hx2KjHKQAAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzg/rNqgCQDtfmXLMeAca4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADUwBpkePj77TwjrMGAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUwB9JN492HPa25+61YGJsFIx5UQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGDG55xz1kP8Z/F4XMFgUGV6QmN946zHAQB4dMN9qQa9pa6uLk2aNOme+3IlBAAwQ4QAAGY8Rai2tlZz5sxRIBBQfn6+Vq5cqfPnz6fss3r1avl8vpRt3rx5aR0aADAyeIpQY2OjqqqqdPr0adXX1+vGjRsqLy9XT09Pyn7Lly9Xe3t7cjty5EhahwYAjAyefrPq22+/nfLzzp07lZ+frzNnzmjRokXJx/1+v0KhUHomBACMWA/0nlBXV5ckKS8vL+XxhoYG5efna9q0aVqzZo06Ojru+mckEgnF4/GUDQAwOgw6Qs45VVdXa8GCBSopKUk+Ho1GtWfPHh07dkxbt25VU1OTli5dqkQiMeCfU1tbq2AwmNwKCwsHOxIAIMsM+ntCVVVVOnz4sE6ePKkpU6bcdb/29nYVFRVp3759qqio6Pd8IpFICVQ8HldhYSHfEwKALOXle0Ke3hO6bd26dTp06JBOnDhxzwBJUjgcVlFRkVpaWgZ83u/3y+/3D2YMAECW8xQh55zWrVunN998Uw0NDSouLr7vms7OTrW1tSkcDg96SADAyOTpPaGqqir96le/0t69exUIBBSLxRSLxXT9+nVJ0tWrV/Xyyy/rvffe08WLF9XQ0KAVK1Zo8uTJevLJJzPyLwAAyF6eroR27NghSSorK0t5fOfOnVq9erVycnLU3Nys3bt36/PPP1c4HNaSJUu0f/9+BQKBtA0NABgZPP/nuHvJzc3V0aNHH2ggAMDowb3jAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmxloPcCfnnCTphr6UnPEwAADPbuhLSf/x/+f3Muwi1N3dLUk6qSPGkwAAHkR3d7eCweA99/G5r5KqIXTr1i1dvnxZgUBAPp8v5bl4PK7CwkK1tbVp0qRJRhPa4zj04Tj04Tj04Tj0GQ7HwTmn7u5uRSIRjRlz73d9ht2V0JgxYzRlypR77jNp0qRRfZLdxnHow3How3How3HoY30c7ncFdBsfTAAAmCFCAAAzWRUhv9+vTZs2ye/3W49iiuPQh+PQh+PQh+PQJ9uOw7D7YAIAYPTIqishAMDIQoQAAGaIEADADBECAJjJqgi99tprKi4u1kMPPaRZs2bpN7/5jfVIQ6qmpkY+ny9lC4VC1mNl3IkTJ7RixQpFIhH5fD4dPHgw5XnnnGpqahSJRJSbm6uysjKdO3fOZtgMut9xWL16db/zY968eTbDZkhtba3mzJmjQCCg/Px8rVy5UufPn0/ZZzScD1/lOGTL+ZA1Edq/f7/Wr1+vjRs36uzZs1q4cKGi0aguXbpkPdqQmj59utrb25Nbc3Oz9UgZ19PTo5kzZ6qurm7A57ds2aJt27aprq5OTU1NCoVCWrZsWfI+hCPF/Y6DJC1fvjzl/DhyZGTdg7GxsVFVVVU6ffq06uvrdePGDZWXl6unpye5z2g4H77KcZCy5HxwWeI73/mOe+GFF1Ie+8Y3vuF++MMfGk009DZt2uRmzpxpPYYpSe7NN99M/nzr1i0XCoXcq6++mnzsiy++cMFg0P3sZz8zmHBo3HkcnHOusrLSPfHEEybzWOno6HCSXGNjo3Nu9J4Pdx4H57LnfMiKK6He3l6dOXNG5eXlKY+Xl5fr1KlTRlPZaGlpUSQSUXFxsZ555hlduHDBeiRTra2tisViKeeG3+/X4sWLR925IUkNDQ3Kz8/XtGnTtGbNGnV0dFiPlFFdXV2SpLy8PEmj93y48zjclg3nQ1ZE6MqVK7p586YKCgpSHi8oKFAsFjOaaujNnTtXu3fv1tGjR/X6668rFouptLRUnZ2d1qOZuf2//2g/NyQpGo1qz549OnbsmLZu3aqmpiYtXbpUiUTCerSMcM6purpaCxYsUElJiaTReT4MdByk7Dkfht1dtO/lzl/t4Jzr99hIFo1Gk/88Y8YMzZ8/X48++qh27dql6upqw8nsjfZzQ5JWrVqV/OeSkhLNnj1bRUVFOnz4sCoqKgwny4y1a9fqww8/1MmTJ/s9N5rOh7sdh2w5H7LiSmjy5MnKycnp9zeZjo6Ofn/jGU0mTpyoGTNmqKWlxXoUM7c/Hci50V84HFZRUdGIPD/WrVunQ4cO6fjx4ym/+mW0nQ93Ow4DGa7nQ1ZEaPz48Zo1a5bq6+tTHq+vr1dpaanRVPYSiYQ++ugjhcNh61HMFBcXKxQKpZwbvb29amxsHNXnhiR1dnaqra1tRJ0fzjmtXbtWBw4c0LFjx1RcXJzy/Gg5H+53HAYybM8Hww9FeLJv3z43btw498Ybb7jf/e53bv369W7ixInu4sWL1qMNmZdeesk1NDS4CxcuuNOnT7vHH3/cBQKBEX8Muru73dmzZ93Zs2edJLdt2zZ39uxZ98knnzjnnHv11VddMBh0Bw4ccM3Nze7ZZ5914XDYxeNx48nT617Hobu727300kvu1KlTrrW11R0/ftzNnz/fff3rXx9Rx+EHP/iBCwaDrqGhwbW3tye3a9euJfcZDefD/Y5DNp0PWRMh55z76U9/6oqKitz48ePdt7/97ZSPI44Gq1atcuFw2I0bN85FIhFXUVHhzp07Zz1Wxh0/ftxJ6rdVVlY65/o+lrtp0yYXCoWc3+93ixYtcs3NzbZDZ8C9jsO1a9dceXm5e/jhh924cePcI4884iorK92lS5esx06rgf79JbmdO3cm9xkN58P9jkM2nQ/8KgcAgJmseE8IADAyESEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABm/h+kZZY8IvAKlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"y_train shape:\",y_train.shape)\n",
    "print(\"X_test shape:\",X_test.shape)\n",
    "print(\"y_test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(See Part1 for more extensive EDA and detailed info about Min-Max normalization formula simplification.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalize data\n",
    "assert X_train.min() == 0   # the following min-max normlization is only effective if the minimum value in the data is zero\n",
    "\n",
    "# min-max scale from 0 to 1 (as long as original min value was zero)\n",
    "X_train, X_test = X_train/X_train.max(), X_test/X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "**Reminder of model requirements:**\n",
    "\n",
    "- Use the `Sequential` Model\n",
    "- Have at least two `Conv2D` layers with all the needed parameters, shapes, number of filters, and activation.\n",
    "- Have at least two `MaxPooling` layers\n",
    "- You will need at least `Flatten` Layer and one `Dense` Layer.\n",
    "- Use the appropriate loss function, optimizer, and metrics.\n",
    "- Include the first two and last two epoch runs.\n",
    "- Include a visualization for the Loss over all epochs\n",
    "- Include a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 26, 26, 28)        280       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 13, 13, 28)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 12, 36)        4068      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 36)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1296)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                12970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,318\n",
      "Trainable params: 17,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(28,3,activation='relu',input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2))\n",
    "])\n",
    "\n",
    "model.add(layers.Conv2D(36,2,activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=[\"accuracy\"],\n",
    "                 optimizer='adam'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 02:55:29.828926: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.829457: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.829525: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall_4}}]]\n",
      "2023-11-28 02:55:29.855494: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.855870: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.883785: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.884124: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.918908: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.919459: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.947347: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.947994: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.973203: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-28 02:55:29.973569: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_4' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n      app.start()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_111445/3510862319.py\", line 1, in <module>\n      hist = model.fit(X_train,y_train, epochs=30, validation_data=(X_test,y_test))\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_4'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_4}}]] [Op:__inference_train_function_36722]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/jasminekobayashi/gh_repos/Code-Reference-Notebook/CU-Boulder/NeuralNetworks/HW/hw3/A3_Part2_JasmineKobayashi.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jasminekobayashi/gh_repos/Code-Reference-Notebook/CU-Boulder/NeuralNetworks/HW/hw3/A3_Part2_JasmineKobayashi.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test,y_test))\n",
      "File \u001b[0;32m~/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_4' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n      app.start()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n      result = self._run_cell(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n      result = runner(coro)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_111445/3510862319.py\", line 1, in <module>\n      hist = model.fit(X_train,y_train, epochs=30, validation_data=(X_test,y_test))\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/jasminekobayashi/anaconda3/envs/code-ref-notebook/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_4'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_4}}]] [Op:__inference_train_function_36722]"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train, epochs=30, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-ref-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
