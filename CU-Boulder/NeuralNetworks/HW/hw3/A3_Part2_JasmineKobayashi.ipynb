{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Module 3 Assignment - Part 2: Use TF/Keras to Create a CNN\"\n",
    "author: Jasmine Kobayashi\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "execute:\n",
    "  output: true\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 3 Assignment - Part 2: Use TF/Keras to Create a CNN\n",
    "---\n",
    "\n",
    "Use the Fashion MNIST Digits dataset again here. This time, create a CNN in TF/Keras. Just like in Part 1, you will have Python code and you will create a Word Doc that fully illustrates your model, outcomes, data, accuracies, vis, etc.\n",
    "\n",
    "## Data:\n",
    "<https://keras.io/api/datasets/mnist/>\n",
    "\n",
    "**Hint: Data Access**\n",
    "```\n",
    "Data = tf.keras.datasets.mnist\n",
    "```\n",
    "\n",
    "**Code Hint:** \n",
    "<https://gatesboltonanalytics.com/?page_id=898>\n",
    "\n",
    "# Requirements:\n",
    "\n",
    "- Use the `Sequential` Model\n",
    "- Have at least (more is fine) two `Conv2D` layers with all the needed parameters, shapes, number of filters, and activation.\n",
    "- Have at least two `MaxPooling` layers\n",
    "- You will need at least one `Flatten` Layer and one `Dense` Layer.\n",
    "- Use the appropriate loss function, optimizer, and metrics.\n",
    "- Illustrate your raw data, at least one image of what your training data looks like as a matrix and as an image. (The matrix may be large - so you can make it small or use a portion of it). Illustrate data sizes so that I know that you know the sizes of your training data, your testing data, etc.\n",
    "- Include the first two and last two epoch runs.\n",
    "- Include a visualization for the Loss over all epochs.\n",
    "- Include a confusion matrix.\n",
    "\n",
    "The goals here are to learn to use Keras to build a CNN Model to learn and then predict image data. It is also important to understand shapes and sizes of images, filters, etc. As you do this, make sure that you understand what you are coding and that you illustrate it (on the Word Doc) for the reader to see what you did and confirm that you know what you did :).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 22:45:07.274762: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-26 22:45:07.320694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = Data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalize data\n",
    "assert X_train.min() == 0   # the following min-max normlization is only effective if the minimum value in the data is zero\n",
    "\n",
    "# min-max scale from 0 to 1 (as long as original min value was zero)\n",
    "X_train, X_test = X_train/X_train.max(), X_test/X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-ref-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
