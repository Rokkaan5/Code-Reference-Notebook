<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jasmine Kobayashi">

<title>Module 2 Assignment - Part 1: One Layer NN with One Output</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="A2_Part1_JasmineKobayashi_files/libs/clipboard/clipboard.min.js"></script>
<script src="A2_Part1_JasmineKobayashi_files/libs/quarto-html/quarto.js"></script>
<script src="A2_Part1_JasmineKobayashi_files/libs/quarto-html/popper.min.js"></script>
<script src="A2_Part1_JasmineKobayashi_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="A2_Part1_JasmineKobayashi_files/libs/quarto-html/anchor.min.js"></script>
<link href="A2_Part1_JasmineKobayashi_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="A2_Part1_JasmineKobayashi_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="A2_Part1_JasmineKobayashi_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="A2_Part1_JasmineKobayashi_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="A2_Part1_JasmineKobayashi_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#fill-out-this-network-by-hand-and-create-all-the-needed-matrices-etc.-show-all-multiplications-and-shapes." id="toc-fill-out-this-network-by-hand-and-create-all-the-needed-matrices-etc.-show-all-multiplications-and-shapes." class="nav-link active" data-scroll-target="#fill-out-this-network-by-hand-and-create-all-the-needed-matrices-etc.-show-all-multiplications-and-shapes.">1) Fill out this network by hand and create all the needed matrices, etc. Show all multiplications and shapes.</a>
  <ul class="collapse">
  <li><a href="#jks-answer" id="toc-jks-answer" class="nav-link" data-scroll-target="#jks-answer">JK’s answer:</a>
  <ul class="collapse">
  <li><a href="#input-matrix-x" id="toc-input-matrix-x" class="nav-link" data-scroll-target="#input-matrix-x">Input Matrix <span class="math inline">\(X\)</span></a></li>
  <li><a href="#targets-y" id="toc-targets-y" class="nav-link" data-scroll-target="#targets-y">Targets <span class="math inline">\(y\)</span></a></li>
  <li><a href="#weight-matrix-w1" id="toc-weight-matrix-w1" class="nav-link" data-scroll-target="#weight-matrix-w1">Weight matrix <span class="math inline">\(W1\)</span></a></li>
  <li><a href="#bias-b" id="toc-bias-b" class="nav-link" data-scroll-target="#bias-b">Bias <span class="math inline">\(B\)</span></a></li>
  <li><a href="#z_1" id="toc-z_1" class="nav-link" data-scroll-target="#z_1"><span class="math inline">\(Z_1\)</span></a></li>
  <li><a href="#h_1" id="toc-h_1" class="nav-link" data-scroll-target="#h_1"><span class="math inline">\(H_1\)</span></a></li>
  <li><a href="#w2" id="toc-w2" class="nav-link" data-scroll-target="#w2"><span class="math inline">\(W2\)</span></a></li>
  <li><a href="#c" id="toc-c" class="nav-link" data-scroll-target="#c"><span class="math inline">\(C\)</span></a></li>
  <li><a href="#z_2" id="toc-z_2" class="nav-link" data-scroll-target="#z_2"><span class="math inline">\(Z_2\)</span></a></li>
  <li><a href="#mathbfhaty" id="toc-mathbfhaty" class="nav-link" data-scroll-target="#mathbfhaty"><span class="math inline">\(\mathbf{\hat{y}}\)</span></a></li>
  <li><a href="#mathbfhaty---mathbfy" id="toc-mathbfhaty---mathbfy" class="nav-link" data-scroll-target="#mathbfhaty---mathbfy"><span class="math inline">\(\mathbf{\hat{y}} - \mathbf{y}\)</span></a></li>
  <li><a href="#loss-l" id="toc-loss-l" class="nav-link" data-scroll-target="#loss-l">Loss <span class="math inline">\(L\)</span></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#use-python-to-code-the-feed-forward-portion-of-this-nn." id="toc-use-python-to-code-the-feed-forward-portion-of-this-nn." class="nav-link" data-scroll-target="#use-python-to-code-the-feed-forward-portion-of-this-nn.">2) Use Python to code the <strong>Feed-Forward</strong> portion of this NN.</a></li>
  <li><a href="#compare-by-hand-and-code" id="toc-compare-by-hand-and-code" class="nav-link" data-scroll-target="#compare-by-hand-and-code">3) Compare <em>by-hand</em> and code</a>
  <ul class="collapse">
  <li><a href="#jks-answer-1" id="toc-jks-answer-1" class="nav-link" data-scroll-target="#jks-answer-1">JK’s answer</a>
  <ul class="collapse">
  <li><a href="#x-matrix" id="toc-x-matrix" class="nav-link" data-scroll-target="#x-matrix">X Matrix</a></li>
  <li><a href="#targets-mathbfy" id="toc-targets-mathbfy" class="nav-link" data-scroll-target="#targets-mathbfy">Targets <span class="math inline">\(\mathbf{y}\)</span></a></li>
  <li><a href="#w1-matrix" id="toc-w1-matrix" class="nav-link" data-scroll-target="#w1-matrix"><span class="math inline">\(W^{(1)}\)</span> Matrix</a></li>
  <li><a href="#bias-vector-mathbfb" id="toc-bias-vector-mathbfb" class="nav-link" data-scroll-target="#bias-vector-mathbfb">Bias vector <span class="math inline">\(\mathbf{B}\)</span></a></li>
  <li><a href="#z_1-matrix" id="toc-z_1-matrix" class="nav-link" data-scroll-target="#z_1-matrix"><span class="math inline">\(Z_1\)</span> Matrix</a></li>
  <li><a href="#h_1-matrix" id="toc-h_1-matrix" class="nav-link" data-scroll-target="#h_1-matrix"><span class="math inline">\(H_1\)</span> Matrix</a></li>
  <li><a href="#w2-matrix" id="toc-w2-matrix" class="nav-link" data-scroll-target="#w2-matrix"><span class="math inline">\(W^{(2)}\)</span> Matrix</a></li>
  <li><a href="#mathbfc-bias-vector" id="toc-mathbfc-bias-vector" class="nav-link" data-scroll-target="#mathbfc-bias-vector"><span class="math inline">\(\mathbf{C}\)</span> bias vector</a></li>
  <li><a href="#z_2-matrix" id="toc-z_2-matrix" class="nav-link" data-scroll-target="#z_2-matrix"><span class="math inline">\(Z_2\)</span> Matrix</a></li>
  <li><a href="#mse-loss" id="toc-mse-loss" class="nav-link" data-scroll-target="#mse-loss">MSE Loss</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#writing-out-the-derivatives-by-hand." id="toc-writing-out-the-derivatives-by-hand." class="nav-link" data-scroll-target="#writing-out-the-derivatives-by-hand.">4) Writing out the derivatives by hand.</a>
  <ul class="collapse">
  <li><a href="#jks-answer-2" id="toc-jks-answer-2" class="nav-link" data-scroll-target="#jks-answer-2">JK’s answer:</a>
  <ul class="collapse">
  <li><a href="#fracpartial-lpartial-c" id="toc-fracpartial-lpartial-c" class="nav-link" data-scroll-target="#fracpartial-lpartial-c"><span class="math inline">\(\frac{\partial L}{\partial C}\)</span></a></li>
  <li><a href="#fracpartial-lpartial-w2" id="toc-fracpartial-lpartial-w2" class="nav-link" data-scroll-target="#fracpartial-lpartial-w2"><span class="math inline">\(\frac{\partial L}{\partial W^{(2)}}\)</span></a></li>
  <li><a href="#fracpartial-lpartial-b" id="toc-fracpartial-lpartial-b" class="nav-link" data-scroll-target="#fracpartial-lpartial-b"><span class="math inline">\(\frac{\partial L}{\partial B}\)</span></a></li>
  <li><a href="#fracpartial-lpartial-w1" id="toc-fracpartial-lpartial-w1" class="nav-link" data-scroll-target="#fracpartial-lpartial-w1"><span class="math inline">\(\frac{\partial L}{\partial W^{(1)}}\)</span></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#adding-back-propagation-to-your-code-so-that-mathbfw_1-mathbfb-and-c-are-updated." id="toc-adding-back-propagation-to-your-code-so-that-mathbfw_1-mathbfb-and-c-are-updated." class="nav-link" data-scroll-target="#adding-back-propagation-to-your-code-so-that-mathbfw_1-mathbfb-and-c-are-updated.">5) Adding Back Propagation to your code so that <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{B}\)</span>, and <span class="math inline">\(C\)</span> are updated.</a></li>
  <li><a href="#test-model" id="toc-test-model" class="nav-link" data-scroll-target="#test-model">6) Test model</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Module 2 Assignment - Part 1: One Layer NN with One Output</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jasmine Kobayashi </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>Module 2 Assignment - Part 1: One Layer NN with One Output</p>
<hr>
<p><strong>Instructions:</strong></p>
<p>This assignment has a two large parts with many sub-parts. Each part will enable you to practice with a neural networks and to practice for Exam 2.</p>
<p>This Assignment will TAKE TIME so use all of the time you have to work on it. Please avoid waiting until the last few days as this will not be enough time. You need weeks - not days :)</p>
<p>Be sure to show all work and (when requested) to code using Python (and no NN/TF/Keras packages). Do not worry, we will use packages in coming modules but first it is best to learn about what is going on inside the model.</p>
<p>You may use examples and code that I have shared as a reference. Using my code will not be considered cheating although I strongly recommend that you write as much (if not all) of your own code so that you learn the concepts more robustly.</p>
<p>This is not a team assignment. Please work and code alone. You may discuss concepts, but you cannot share code or work with others. Papers that look too similar with split the grade (first offense) and can suffer less pleasant outcomes for further offenses. Keep it simple and smart - do your own work.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="network.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">NN_architecture</figcaption>
</figure>
</div>
<section id="fill-out-this-network-by-hand-and-create-all-the-needed-matrices-etc.-show-all-multiplications-and-shapes." class="level1">
<h1>1) Fill out this network by hand and create all the needed matrices, etc. Show all multiplications and shapes.</h1>
<p>In other words, illustrate the <span class="math inline">\(X\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(W1\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(Z_1\)</span>, <span class="math inline">\(H_1\)</span>, <span class="math inline">\(W2\)</span>, <span class="math inline">\(Z_2\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(\hat{y}\)</span>, <span class="math inline">\(\hat{y}-y\)</span>, and <span class="math inline">\(L\)</span>. Assume that <span class="math inline">\(H_1\)</span> uses the Sigmoid Function.</p>
<p>As you do this - ask yourself:</p>
<ul>
<li>How many columns does <span class="math inline">\(X\)</span> have?</li>
<li>How many hidden layers are there in this architecture?</li>
<li>How many hidden units are there in the hidden layer?</li>
<li>How many outputs are there?</li>
</ul>
<section id="jks-answer" class="level2">
<h2 class="anchored" data-anchor-id="jks-answer">JK’s answer:</h2>
<section id="input-matrix-x" class="level3">
<h3 class="anchored" data-anchor-id="input-matrix-x">Input Matrix <span class="math inline">\(X\)</span></h3>
<p><span class="math display">\[\begin{equation}
X =

\begin{bmatrix}
x_{11} &amp; x_{12} &amp; x_{13} \\
\vdots  &amp; \vdots  &amp; \vdots  \\
x_{n1} &amp; x_{n2} &amp; x_{n3} \\
\end{bmatrix}
\nonumber
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(n\)</span> is any integer.</p>
<p>In any case, the point being: this architecture implies <span class="math inline">\(X\)</span> has 3 columns (but gives no restriction/information about the number of rows of <span class="math inline">\(X\)</span>.)</p>
</section>
<section id="targets-y" class="level3">
<h3 class="anchored" data-anchor-id="targets-y">Targets <span class="math inline">\(y\)</span></h3>
<p><span class="math display">\[\begin{align*}
\mathbf{y} =
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}
\end{align*}\]</span></p>
</section>
<section id="weight-matrix-w1" class="level3">
<h3 class="anchored" data-anchor-id="weight-matrix-w1">Weight matrix <span class="math inline">\(W1\)</span></h3>
<p>The weight matrix connecting inputs <span class="math inline">\(X\)</span> with the first hidden layer (or in this case, the only hidden layer).</p>
<p>I will use both notations <span class="math inline">\(W1 = W^{(1)}\)</span>, to be clear and be able to distinct weights <span class="math inline">\(w\)</span> in <span class="math inline">\(W1\)</span> and <span class="math inline">\(W2\)</span></p>
<p><span class="math display">\[\begin{align*}
W1 = W^{(1)} =
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}
\end{align*}\]</span></p>
<p>When creating the matrix to match the subscript notation so that the first number in the subscript of <span class="math inline">\(w\)</span> is associated with the connected <span class="math inline">\(x\)</span> value and the second number is associated with the hidden unit <span class="math inline">\(h\)</span> (i.e.&nbsp;<span class="math inline">\(w_{12}\)</span> is the weight connecting <span class="math inline">\(x_1\)</span> to <span class="math inline">\(h_2\)</span>), then the <span class="math inline">\(W^{(1)}\)</span> matrix is an <span class="math inline">\(m \times p\)</span> matrix, where <span class="math inline">\(m\)</span> is the number of columns of <span class="math inline">\(X\)</span> and <span class="math inline">\(p\)</span> is the number of units in the first hidden layer (which is also the number of rows of <span class="math inline">\(H_1\)</span>).</p>
</section>
<section id="bias-b" class="level3">
<h3 class="anchored" data-anchor-id="bias-b">Bias <span class="math inline">\(B\)</span></h3>
<p>The “bias”. Column vector with length that matches the number of rows in <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\mathbf{B} = [b_1,\cdots, b_n]^\top\]</span></p>
</section>
<section id="z_1" class="level3">
<h3 class="anchored" data-anchor-id="z_1"><span class="math inline">\(Z_1\)</span></h3>
<p><span class="math display">\[\begin{align*}
Z_1 &amp; =  X\cdot W_1 + B

\\
&amp; =
\begin{bmatrix}
x_{11} &amp; x_{12} &amp; x_{13} \\
\vdots  &amp; \vdots  &amp; \vdots  \\
x_{n1} &amp; x_{n2} &amp; x_{n3} \\
\end{bmatrix}

\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}

+
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}

\\

&amp; =
\begin{bmatrix}
z_{11} &amp; z_{12} &amp; z_{13} &amp; z_{14} \\
z_{21} &amp; z_{22} &amp; z_{23} &amp; z_{24} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
z_{n1} &amp; z_{n2} &amp; z_{n3} &amp; z_{n4}
\end{bmatrix}
\end{align*}\]</span></p>
<p>Where we have:</p>
<p><span class="math display">\[\begin{align*}
&amp; z_{11} = x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + b_1 &amp; &amp; \\
&amp; z_{12} = x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + b_1 &amp; &amp;\\
\end{align*}\]</span></p>
<p><span class="math display">\[\vdots\]</span></p>
<p><span class="math display">\[\begin{align*}
z_{n4} = x_{n1}w_{14} + x_{n2}w_{24} + x_{n3}w_{34} + b_n
\end{align*}\]</span></p>
<p>In other words, I guess any <span class="math inline">\(Z\)</span> element can be summarized as,</p>
<p><span class="math display">\[z_{i,k} = \sum_j^3 x_{i,j}w_{j,k} + b_i\]</span></p>
</section>
<section id="h_1" class="level3">
<h3 class="anchored" data-anchor-id="h_1"><span class="math inline">\(H_1\)</span></h3>
<p>We’re assuming the first hidden layer uses the Simoid activation function. Thus <span class="math inline">\(S(z)\)</span> is the Sigmoid of <span class="math inline">\(z\)</span>.</p>
<p>(Very) Generically we have, <span class="math display">\[h = S(z) = \frac{1}{1+e^{-z}}\]</span></p>
<p>Thus the matrix is as follows:</p>
<p><span class="math display">\[\begin{align*}
H_1 &amp; =
\begin{bmatrix}
S(z_{11}) &amp; S(z_{12}) &amp; S(z_{13}) &amp; S(z_{14}) \\
\vdots    &amp;   \vdots  &amp;   \vdots  &amp;   \vdots  \\
S(z_{n1}) &amp; S(z_{n2}) &amp; S(z_{n3}) &amp; S(z_{n4}) \\
\end{bmatrix}

\\

&amp; =
\begin{bmatrix}
h_{11} &amp; h_{12} &amp; h_{13} &amp; h_{14} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
h_{n1} &amp; h_{n2} &amp; h_{n3} &amp; h_{n4} \\
\end{bmatrix}
\end{align*}\]</span></p>
<p>The number of columns in <span class="math inline">\(H_1\)</span> is the number of hidden units in the hidden layer.</p>
</section>
<section id="w2" class="level3">
<h3 class="anchored" data-anchor-id="w2"><span class="math inline">\(W2\)</span></h3>
<p>The weight matrix connecting the hidden layer and the last node.</p>
<p>Again, I will use both notations <span class="math inline">\(W1 = W^{(1)}\)</span> and <span class="math inline">\(W2 = W^{(2)}\)</span>, to be able to distinguish weights from each weight matrix.</p>
<p><span class="math display">\[\begin{align*}
W2 = W^{(2)} =
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}
\end{align*}\]</span></p>
<p>The number of rows in <span class="math inline">\(W^{(2)}\)</span> is defined by the number of hidden units in the previous layer it’s connected to, and the number of columns is defined by the number of outputs. (In this case, for this part of the assignment, that’s only one.)</p>
</section>
<section id="c" class="level3">
<h3 class="anchored" data-anchor-id="c"><span class="math inline">\(C\)</span></h3>
<p>I believe this is the “bias” associated to calculate <span class="math inline">\(Z_2\)</span>. So much like <span class="math inline">\(B\)</span> it’s going to be a column vector with length that matches the number of rows in <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\begin{equation*}
C =
\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}
\end{equation*}\]</span></p>
</section>
<section id="z_2" class="level3">
<h3 class="anchored" data-anchor-id="z_2"><span class="math inline">\(Z_2\)</span></h3>
<p><span class="math display">\[\begin{align*}
Z^{(2)} &amp;= H_1 W^{(2)} + C \\
&amp;=
\begin{bmatrix}
h_{11} &amp; h_{12} &amp; h_{13} &amp; h_{14} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
h_{n1} &amp; h_{n2} &amp; h_{n3} &amp; h_{n4} \\
\end{bmatrix}
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}

+

\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
h_{11}w_1^{(2)} + h_{12}w_2^{(2)} + h_{13}w_3^{(2)} + h_{14}w_4^{(2)} + c_1\\
\vdots \\
h_{n1}w_1^{(2)} + h_{n2}w_2^{(2)} + h_{n3}w_3^{(2)} + h_{n4}w_4^{(2)} + c_n
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
z_1^{(2)} \\
\vdots \\
z_n^{(2)}
\end{bmatrix}
\end{align*}\]</span></p>
<p>Or in other words, each <span class="math inline">\(Z^{(2)}\)</span> element can be summarized as,</p>
<p><span class="math display">\[\begin{align*}
z_i^{(2)} = \sum_k^4 h_{i,k}w_k^{(2)} + c_i
\end{align*}\]</span></p>
</section>
<section id="mathbfhaty" class="level3">
<h3 class="anchored" data-anchor-id="mathbfhaty"><span class="math inline">\(\mathbf{\hat{y}}\)</span></h3>
<p>In terms of notation,</p>
<p><span class="math display">\[\begin{align*}
\mathbf{\hat{y}} =
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}
\end{align*}\]</span></p>
<p>(Should have the same shape as <span class="math inline">\(\mathbf{y}\)</span>)</p>
<p>I’m guessing I have to do sigmoid again to get probability for binary labels?</p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
\mathbf{\hat{y}} =
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}
=
\begin{bmatrix}
S(z_1^{(2)}) \\
\vdots \\
S(z_n^{(2)})
\end{bmatrix}
\end{align*}\]</span></p>
</section>
<section id="mathbfhaty---mathbfy" class="level3">
<h3 class="anchored" data-anchor-id="mathbfhaty---mathbfy"><span class="math inline">\(\mathbf{\hat{y}} - \mathbf{y}\)</span></h3>
<p><span class="math display">\[\begin{align*}
\mathbf{\hat{y}} - \mathbf{y} =
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}

-

\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}

=

\begin{bmatrix}
\hat{y}_1 - y_1 \\
\vdots \\
\hat{y}_n - y_n \\
\end{bmatrix}

\end{align*}\]</span></p>
</section>
<section id="loss-l" class="level3">
<h3 class="anchored" data-anchor-id="loss-l">Loss <span class="math inline">\(L\)</span></h3>
<p>There’s really no limit of what Loss function <span class="math inline">\(L\)</span> to use. (A NN architecture doesn’t define this, the NN model builder does :)) It could be LCE or a simple one.</p>
<p>For the purpose of this assignment I’ll use a simple MSE (that’s supposedly pretty commonly used as well), since it uses <span class="math inline">\(\mathbf{\hat{y}} - \mathbf{y}\)</span>.</p>
<p><span class="math display">\[\begin{align*}
Loss = L &amp;= \frac{1}{2} (\mathbf{y} - \mathbf{\hat{y}})^2 \\
&amp;= \frac{1}{2}
\begin{bmatrix}
\hat{y}_1 - y_1 \\
\vdots \\
\hat{y}_n - y_n
\end{bmatrix}^2
\\
&amp;=\frac{1}{2}
\begin{bmatrix}
\hat{y}_1 - y_1 \\
\vdots \\
\hat{y}_n - y_n
\end{bmatrix}
\begin{bmatrix}
\hat{y}_1 - y_1, &amp; \cdots, &amp; \hat{y}_1 - y_1
\end{bmatrix}
\\
&amp;= \frac{1}{2} \sum_i^n (\hat{y}_i - y_i)^2
\end{align*}\]</span></p>
</section>
</section>
</section>
<section id="use-python-to-code-the-feed-forward-portion-of-this-nn." class="level1">
<h1>2) Use Python to code the <strong>Feed-Forward</strong> portion of this NN.</h1>
<p>Print out <span class="math inline">\(X\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(W1\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(Z_1\)</span>, <span class="math inline">\(H_1\)</span>, <span class="math inline">\(W_2\)</span>, <span class="math inline">\(Z_2\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(\hat{y}\)</span>, <span class="math inline">\(\hat{y}-y\)</span>, and <span class="math inline">\(L\)</span>.</p>
<p><strong>Assumptions and Notes</strong>:</p>
<ol type="a">
<li><p>Create your own small labeled dataset. Have the right number of columns and have a column called “LABEL” which is 0 or 1.</p></li>
<li><p>Read in the data and create <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span></p></li>
<li><p>YOU create the dataset so that everyone will have a unique dataset. Have between 5 and 7 rows (no more), assure that your labels “make sense” for the data, and have a balance of labels (so nearish 50% <span class="math inline">\(0\)</span> and 50% <span class="math inline">\(1\)</span>). You want your NN to “work” so again make sure your labeled data has a predictable pattern. <em>INVENT</em> the data yourself - type it into a <code>.csv</code> file - save the file as <strong>A2_Data_YourName.csv</strong>. You will submit this dataset with your Assignment submission.</p></li>
<li><p>Create <span class="math inline">\(H_1\)</span> using Sigmoid. You will need to <strong>code</strong> a function for the Sigmoid (and its derivative) into your code. Do this using <code>def</code>.</p></li>
<li><p>Use <span class="math inline">\(L = \frac{1}{n} \displaystyle \sum^n (\hat{y} - y)^2\)</span> as the Loss Function when <span class="math inline">\(n\)</span> is the number of rows in your dataset. Do not “hard code”. The TAs or I should be able to use your code to read ANY dataset that has 3 columns of data, one label column called “LABEL” (of 0 or 1), and any number of rows.</p></li>
</ol>
<p><strong><em>JK answer:</em></strong></p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#%% libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder,MinMaxScaler</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix  </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HW2_FeedForward():</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                 data_filename <span class="op">=</span> <span class="st">"A2_Data_JasmineKobayashi.csv"</span>, </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                 scale_data <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                 verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read Data</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> pd.read_csv(data_filename)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create X and y, assuming data has column "LABEL" as column with labels</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">## X matrix</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> scale_data:</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            mm_scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            X <span class="op">=</span> mm_scaler.fit_transform(<span class="va">self</span>.df.drop(columns<span class="op">=</span><span class="st">"LABEL"</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            X <span class="op">=</span> np.array(<span class="va">self</span>.df.drop(columns<span class="op">=</span>[<span class="st">'LABEL'</span>],axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">## y</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> np.array(<span class="va">self</span>.df[[<span class="st">'LABEL'</span>]])</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of X:"</span>, <span class="va">self</span>.X.shape)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"X matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.X)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of y:"</span>, <span class="va">self</span>.y.shape)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"y vector: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.y)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> MSE_loss(<span class="va">self</span>,y_hat,y):</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># L = mean((y_hat - y)^2)</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.mean((y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> lin_eq(<span class="va">self</span>,X,W,B):</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> W.shape[<span class="dv">0</span>], <span class="st">"Linear eq: z = X @ W + B. Shape of X: </span><span class="sc">{}</span><span class="st">; Shape of W: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(X.shape,W.shape)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> B.shape[<span class="dv">0</span>] <span class="op">==</span> X.shape[<span class="dv">0</span>], <span class="st">"Linear eq: z = X @ W + B. Length of B should match X rows; Length B = </span><span class="sc">{}</span><span class="st">; Shape of X = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(B.shape[<span class="dv">0</span>],X.shape)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X <span class="op">@</span> W <span class="op">+</span> B</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Sigmoid(<span class="va">self</span>,z,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>                derivative <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> derivative:</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.Sigmoid(z) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.Sigmoid(z)) <span class="co"># dS/dz = S(z)(1-S(z))</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sigmoid</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> math.e<span class="op">**</span>(<span class="op">-</span>z)) <span class="co"># S(z) = 1/(1 + e^(-z))</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> FeedForward(<span class="va">self</span>,</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>                    hidden_units<span class="op">=</span> <span class="dv">4</span>,</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>                    randomize_parameters <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>                    activation <span class="op">=</span> <span class="st">"sigmoid"</span>,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of W1</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        w1_ncol <span class="op">=</span> hidden_units        <span class="co"># Number of W1 cols should be number of hidden units in H1</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>        w1_nrow <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">1</span>]     <span class="co"># Number of W1 rows should be number of X columns (dim of X)</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of B (column vector)</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        b_length <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">0</span>]    <span class="co"># length of X rows</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of W2:</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        w2_ncol <span class="op">=</span> <span class="dv">1</span>                   <span class="co"># Number of W2 cols should be number of outputs (in this case, only one output)</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        w2_nrow <span class="op">=</span> hidden_units        <span class="co"># Number of W2 rows should be number of hidden units in H1</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of C (column vector)</span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        c_length <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">0</span>]    <span class="co"># length of X rows</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> randomize_parameters: </span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># </span><span class="al">TODO</span><span class="co">: Finish potential code of randomized parameters</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># # bounds of randomized weights</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># bound = 1/np.sqrt(w1_nrow)   # I found online that supposedly this is a standard range for randomized weights</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># rand_w = [np.random.uniform(-bound,bound) for i in range(w1_ncol)]</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># self.W1 = np.array([rand_w]*w1_nrow)</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># self.W2 = np.array([]*w2_nrow)</span></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print('All parameters were randomized')</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:   <span class="co"># These are the parameters defined by the question 2 in Assignment2</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W1 <span class="op">=</span> np.array([[<span class="dv">1</span>]<span class="op">*</span>w1_ncol]<span class="op">*</span>w1_nrow) <span class="co"># otherwise, all weights of W1 = 1</span></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.B <span class="op">=</span> np.array([[<span class="dv">0</span>]]<span class="op">*</span>b_length)         <span class="co"># otherwise, all bias (B) = 0</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W2 <span class="op">=</span> np.array([[<span class="dv">2</span>]<span class="op">*</span>w2_ncol]<span class="op">*</span>w2_nrow) <span class="co"># otherwise, all weights of W2 = 2</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.C <span class="op">=</span> np.array([[<span class="dv">0</span>]]<span class="op">*</span>c_length)</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Parameters built for simple calculation (not randomized)"</span>)</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of X cols (should be # of W1 rows):", self.X.shape[1])</span></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of hidden units (should be # of W1 cols):", hidden_units)</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W1 has shape:"</span>, <span class="va">self</span>.W1.shape)</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W1 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W1)</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of B:"</span>, <span class="va">self</span>.B.shape)</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"B (bias vector for Z1): </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.B)</span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of W2:"</span>,<span class="va">self</span>.W2.shape)</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W2 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W2)</span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of C :"</span>, <span class="va">self</span>.C.shape)</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"C (bias vector for Z2): </span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.C)</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create H1</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z1 = X @ W1 + B</span></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Z1 <span class="op">=</span> <span class="va">self</span>.lin_eq(<span class="va">self</span>.X,<span class="va">self</span>.W1,<span class="va">self</span>.B)</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of Z1:"</span>,<span class="va">self</span>.Z1.shape)</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Z1 matrix: </span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.Z1)</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.H1 <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z1)</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Add flexibility with other activation functions</span></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose: </span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Activation function:"</span>,activation)</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"H1 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.H1)</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z2 and y-hat</span></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z2 = H1 @ W2 + C</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Z2 <span class="op">=</span> <span class="va">self</span>.lin_eq(<span class="va">self</span>.H1,<span class="va">self</span>.W2,<span class="va">self</span>.C)</span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_hat <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z2)</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of Z2:"</span>, <span class="va">self</span>.Z2.shape)</span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Z2 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.Z2)</span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"y_hat:</span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.y_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>NN <span class="op">=</span> HW2_FeedForward()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>NN.FeedForward()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE Loss:"</span>,NN.MSE_loss(y_hat<span class="op">=</span>NN.y_hat,y<span class="op">=</span>NN.y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of X: (6, 3)
X matrix: 
 [[0.86363636 0.         0.        ]
 [0.09090909 0.84615385 0.75862069]
 [0.         1.         1.        ]
 [1.         0.30769231 0.13793103]
 [0.90909091 0.07692308 0.27586207]
 [0.04545455 0.92307692 0.93103448]]
Shape of y: (6, 1)
y vector: 
 [[0]
 [1]
 [1]
 [0]
 [0]
 [1]]
Parameters built for simple calculation (not randomized)
W1 has shape: (3, 4)
W1 matrix: 
 [[1 1 1 1]
 [1 1 1 1]
 [1 1 1 1]]
Shape of B: (6, 1)
B (bias vector for Z1): 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]
Shape of W2: (4, 1)
W2 matrix: 
 [[2]
 [2]
 [2]
 [2]]
Shape of C : (6, 1)
C (bias vector for Z2): 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]
Shape of Z1: (6, 4)
Z1 matrix: 
 [[0.86363636 0.86363636 0.86363636 0.86363636]
 [1.69568363 1.69568363 1.69568363 1.69568363]
 [2.         2.         2.         2.        ]
 [1.44562334 1.44562334 1.44562334 1.44562334]
 [1.26187605 1.26187605 1.26187605 1.26187605]
 [1.89956595 1.89956595 1.89956595 1.89956595]]
Activation function: sigmoid
H1 matrix: 
 [[0.70341983 0.70341983 0.70341983 0.70341983]
 [0.84497015 0.84497015 0.84497015 0.84497015]
 [0.88079708 0.88079708 0.88079708 0.88079708]
 [0.80932395 0.80932395 0.80932395 0.80932395]
 [0.77934889 0.77934889 0.77934889 0.77934889]
 [0.86984239 0.86984239 0.86984239 0.86984239]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[5.62735868]
 [6.7597612 ]
 [7.04637662]
 [6.47459158]
 [6.23479113]
 [6.95873914]]
y_hat:
 [[0.99641483]
 [0.99884184]
 [0.9991302 ]
 [0.99846025]
 [0.9980438 ]
 [0.99905061]]
MSE Loss: 0.49764329995811907</code></pre>
</div>
</div>
</section>
<section id="compare-by-hand-and-code" class="level1">
<h1>3) Compare <em>by-hand</em> and code</h1>
<p>Here, will compare your by-hand work in (1) with your code in (2).</p>
<p>To do this, use your dataset values (just the first row) and your label (for the first row) to FF <em>by hand on paper</em> through the network. Show numeric and clear results for <span class="math inline">\(X\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(W_1\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(Z_1\)</span>, <span class="math inline">\(H_1\)</span>, <span class="math inline">\(W_2\)</span>, <span class="math inline">\(Z_2\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(\hat{y}\)</span>, <span class="math inline">\(\hat{y}-y\)</span>, and <span class="math inline">\(L\)</span>.</p>
<p>Then, using your code and the same <span class="math inline">\(X\)</span> (first row) and <span class="math inline">\(y\)</span> (first label), print out <span class="math inline">\(X\)</span>, <span class="math inline">\(y\)</span>, <span class="math inline">\(W_1\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(Z_1\)</span>, <span class="math inline">\(H_1\)</span>, <span class="math inline">\(W_2\)</span>, <span class="math inline">\(Z_2\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(\hat{y}\)</span>, <span class="math inline">\(\hat{y}-y\)</span>, and <span class="math inline">\(L\)</span>.</p>
<p>Both the “by hand on paper” and the “by code” results should be the same.</p>
<p>If they are not, find and fix your bugs until they are the same.</p>
<p><strong>Notes</strong>: <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{W_2}\)</span>, <span class="math inline">\(\mathbf{B}\)</span> (which is <span class="math inline">\(b_1\)</span>, <span class="math inline">\(b_2\)</span>, <span class="math inline">\(b_3\)</span>, <span class="math inline">\(b_4\)</span>), and <span class="math inline">\(C\)</span> (which is <span class="math inline">\(c_1\)</span>) would normally be randomly initialized. However, to make your code and “by hand” comparison easier, let all the values in <span class="math inline">\(W_1\)</span> be <span class="math inline">\(1\)</span>, let all the values in <span class="math inline">\(W_2\)</span> be 2, let all the <span class="math inline">\(\mathbf{B}\)</span> values be <span class="math inline">\(0\)</span>, and let <span class="math inline">\(c\)</span> be <span class="math inline">\(-1\)</span>. You will code this in and will use this by hand so that your code and by-hand results will be the same.</p>
<p>Print out all key matrices and results.</p>
<p>Illustrate and compare your “by-hand” results with your code print outs to show that they are the same.</p>
<section id="jks-answer-1" class="level2">
<h2 class="anchored" data-anchor-id="jks-answer-1">JK’s answer</h2>
<section id="x-matrix" class="level3">
<h3 class="anchored" data-anchor-id="x-matrix">X Matrix</h3>
<p><span class="math display">\[\begin{align*}
X &amp;=

\begin{bmatrix}
x_{11} &amp; x_{12} &amp; x_{13} \\
x_{21} &amp; x_{22} &amp; x_{23} \\
\vdots  &amp; \vdots  &amp; \vdots  \\
x_{n1} &amp; x_{n2} &amp; x_{n3} \\
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
22 &amp; 10 &amp; 24 \\
5  &amp; 12 &amp; 52 \\
3  &amp; 15 &amp; 59 \\
25 &amp; 11 &amp; 23 \\
23 &amp; 14 &amp; 21 \\
4  &amp; 13 &amp; 57
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>NN <span class="op">=</span> HW2_FeedForward(scale_data<span class="op">=</span><span class="va">False</span>,verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"non-scaled X:</span><span class="ch">\n</span><span class="st">"</span>,NN.X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>non-scaled X:
 [[22  1 30]
 [ 5 12 52]
 [ 3 14 59]
 [25  5 34]
 [23  2 38]
 [ 4 13 57]]</code></pre>
</div>
</div>
<p>To avoid errors with Sigmoid, so going to Min-Max scale the data. I’m not going to calculate individually I”m going to leave it to the Sklearn package min-max normalizer and trust it works.</p>
<p>But this is the formula I would use if I did calculate by hand:</p>
<p><span class="math display">\[x' = \frac{x - min}{max - min}\]</span></p>
<p>Where <span class="math inline">\(x'\)</span> is the scaled value, <span class="math inline">\(x\)</span> is the value to scale. (<span class="math inline">\(min\)</span> &amp; <span class="math inline">\(max\)</span> are the minimum value and maximum value of the list of values to scale to.)</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>NN <span class="op">=</span> HW2_FeedForward(scale_data<span class="op">=</span><span class="va">True</span>,verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Min-Max Scaled X:</span><span class="ch">\n</span><span class="st">"</span>,NN.X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Min-Max Scaled X:
 [[0.86363636 0.         0.        ]
 [0.09090909 0.84615385 0.75862069]
 [0.         1.         1.        ]
 [1.         0.30769231 0.13793103]
 [0.90909091 0.07692308 0.27586207]
 [0.04545455 0.92307692 0.93103448]]</code></pre>
</div>
</div>
</section>
<section id="targets-mathbfy" class="level3">
<h3 class="anchored" data-anchor-id="targets-mathbfy">Targets <span class="math inline">\(\mathbf{y}\)</span></h3>
<p><span class="math display">\[\begin{align*}
\mathbf{y} &amp;=
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
0 \\
1 \\
1 \\
0 \\
0 \\
1
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y target vector:</span><span class="ch">\n</span><span class="st">"</span>,NN.y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y target vector:
 [[0]
 [1]
 [1]
 [0]
 [0]
 [1]]</code></pre>
</div>
</div>
</section>
<section id="w1-matrix" class="level3">
<h3 class="anchored" data-anchor-id="w1-matrix"><span class="math inline">\(W^{(1)}\)</span> Matrix</h3>
<p>For this assignment we’re using all weights in <span class="math inline">\(W^{(1)}\)</span> are equal to <span class="math inline">\(1\)</span></p>
<p><span class="math display">\[\begin{align*}
W^{(1)} &amp;=
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>NN.FeedForward(verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"W1 matrix: </span><span class="ch">\n</span><span class="st">"</span>,NN.W1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameters built for simple calculation (not randomized)
W1 matrix: 
 [[1 1 1 1]
 [1 1 1 1]
 [1 1 1 1]]</code></pre>
</div>
</div>
</section>
<section id="bias-vector-mathbfb" class="level3">
<h3 class="anchored" data-anchor-id="bias-vector-mathbfb">Bias vector <span class="math inline">\(\mathbf{B}\)</span></h3>
<p>For this assignment we using all bias = 0</p>
<p><span class="math display">\[\begin{align*}
\mathbf{B} =
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Bias vector B: </span><span class="ch">\n</span><span class="st">"</span>,NN.B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Bias vector B: 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]</code></pre>
</div>
</div>
</section>
<section id="z_1-matrix" class="level3">
<h3 class="anchored" data-anchor-id="z_1-matrix"><span class="math inline">\(Z_1\)</span> Matrix</h3>
<p><span class="math display">\[\begin{align*}
Z_1 &amp;= X \cdot W^{(1)} + B \\
&amp;=
\begin{bmatrix}
x_{11} &amp; x_{12} &amp; x_{13} \\
x_{21} &amp; x_{22} &amp; x_{23} \\
\vdots  &amp; \vdots  &amp; \vdots  \\
x_{n1} &amp; x_{n2} &amp; x_{n3} \\
\end{bmatrix}
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}
+
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
0.863 &amp; 0.0 &amp; 0.0789 \\
0.091 &amp; 0.4 &amp; 0.816  \\
0.0   &amp; 0.8 &amp; 1.0    \\
1.0   &amp; 0.2 &amp; 0.0526 \\
0.909 &amp; 1.0 &amp; 0.0    \\
0.045 &amp; 0.6 &amp; 0.947
\end{bmatrix}
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}
+
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
0.942 &amp; 0.942 &amp; 0.942 &amp; 0.942 \\
1.306 &amp; 1.306 &amp; 1.306 &amp; 1.306 \\
1.8   &amp; 1.8   &amp; 1.8   &amp; 1.8   \\
1.253 &amp; 1.253 &amp; 1.253 &amp; 1.253 \\
1.91  &amp; 1.91  &amp; 1.91  &amp; 1.91  \\
1.597 &amp; 1.597 &amp; 1.597 &amp; 1.597
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>NN.Z1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[0.86363636, 0.86363636, 0.86363636, 0.86363636],
       [1.69568363, 1.69568363, 1.69568363, 1.69568363],
       [2.        , 2.        , 2.        , 2.        ],
       [1.44562334, 1.44562334, 1.44562334, 1.44562334],
       [1.26187605, 1.26187605, 1.26187605, 1.26187605],
       [1.89956595, 1.89956595, 1.89956595, 1.89956595]])</code></pre>
</div>
</div>
</section>
<section id="h_1-matrix" class="level3">
<h3 class="anchored" data-anchor-id="h_1-matrix"><span class="math inline">\(H_1\)</span> Matrix</h3>
<p>Using the Sigmoid as the activation function which is defined as follows,</p>
<p><span class="math display">\[\begin{align*}
S(z) &amp;= \frac{e^z}{1+e^z} \\[6pt]
&amp;= \frac{1}{1+e^{-z}}
\end{align*}\]</span></p>
<p>And <span class="math inline">\(h=S(z)\)</span></p>
<p><span class="math display">\[\begin{align*}
H_1 &amp; =
\begin{bmatrix}
S(z_{11}) &amp; S(z_{12}) &amp; S(z_{13}) &amp; S(z_{14}) \\
\vdots    &amp;   \vdots  &amp;   \vdots  &amp;   \vdots  \\
S(z_{n1}) &amp; S(z_{n2}) &amp; S(z_{n3}) &amp; S(z_{n4}) \\
\end{bmatrix}

\\

&amp; =
\begin{bmatrix}
0.7195 &amp; 0.7195 &amp; 0.7195 &amp; 0.7195 \\
0.787  &amp; 0.787  &amp; 0.787  &amp; 0.787  \\
0.858  &amp; 0.858  &amp; 0.858  &amp; 0.858  \\
0.778  &amp; 0.778  &amp; 0.778  &amp; 0.778  \\
0.871  &amp; 0.871  &amp; 0.871  &amp; 0.871  \\
0.832  &amp; 0.832  &amp; 0.832  &amp; 0.832  
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"H1 matrix: </span><span class="ch">\n</span><span class="st">"</span>,NN.H1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>H1 matrix: 
 [[0.70341983 0.70341983 0.70341983 0.70341983]
 [0.84497015 0.84497015 0.84497015 0.84497015]
 [0.88079708 0.88079708 0.88079708 0.88079708]
 [0.80932395 0.80932395 0.80932395 0.80932395]
 [0.77934889 0.77934889 0.77934889 0.77934889]
 [0.86984239 0.86984239 0.86984239 0.86984239]]</code></pre>
</div>
</div>
</section>
<section id="w2-matrix" class="level3">
<h3 class="anchored" data-anchor-id="w2-matrix"><span class="math inline">\(W^{(2)}\)</span> Matrix</h3>
<p>For this assignment we’re using all weights in <span class="math inline">\(W^{(2)}\)</span> are equal to <span class="math inline">\(2\)</span></p>
<p><span class="math display">\[\begin{align*}
W^{(2)} =
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}
=
\begin{bmatrix}
2 \\
2 \\
2 \\
2
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"W2 matrix: </span><span class="ch">\n</span><span class="st">"</span>,NN.W2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>W2 matrix: 
 [[2]
 [2]
 [2]
 [2]]</code></pre>
</div>
</div>
</section>
<section id="mathbfc-bias-vector" class="level3">
<h3 class="anchored" data-anchor-id="mathbfc-bias-vector"><span class="math inline">\(\mathbf{C}\)</span> bias vector</h3>
<p>For this assignment we using all bias = 0</p>
<p><span class="math display">\[\begin{equation*}
C =
\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0
\end{bmatrix}
\end{equation*}\]</span></p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"C bias vector: </span><span class="ch">\n</span><span class="st">"</span>,NN.C)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>C bias vector: 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]</code></pre>
</div>
</div>
</section>
<section id="z_2-matrix" class="level3">
<h3 class="anchored" data-anchor-id="z_2-matrix"><span class="math inline">\(Z_2\)</span> Matrix</h3>
<p><span class="math display">\[\begin{align*}
Z_2 &amp;= H_1 W^{(2)} + C \\
&amp;=
\begin{bmatrix}
h_{11} &amp; h_{12} &amp; h_{13} &amp; h_{14} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
h_{n1} &amp; h_{n2} &amp; h_{n3} &amp; h_{n4} \\
\end{bmatrix}
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}

+

\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}

=
\begin{bmatrix}
z_1^{(2)} \\
\vdots \\
z_n^{(2)}
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
0.7195 &amp; 0.7195 &amp; 0.7195 &amp; 0.7195 \\
0.787  &amp; 0.787  &amp; 0.787  &amp; 0.787  \\
0.858  &amp; 0.858  &amp; 0.858  &amp; 0.858  \\
0.778  &amp; 0.778  &amp; 0.778  &amp; 0.778  \\
0.871  &amp; 0.871  &amp; 0.871  &amp; 0.871  \\
0.832  &amp; 0.832  &amp; 0.832  &amp; 0.832  
\end{bmatrix}
\begin{bmatrix}
2 \\
2 \\
2 \\
2
\end{bmatrix}
+
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
0 \\
0
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
5.756 \\
6.296 \\
6.864 \\
6.224 \\
6.968 \\
6.656
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Z2 matrix: </span><span class="ch">\n</span><span class="st">"</span>,NN.Z2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Z2 matrix: 
 [[5.62735868]
 [6.7597612 ]
 [7.04637662]
 [6.47459158]
 [6.23479113]
 [6.95873914]]</code></pre>
</div>
</div>
<section id="mathbfhaty-prediction-vector" class="level4">
<h4 class="anchored" data-anchor-id="mathbfhaty-prediction-vector"><span class="math inline">\(\mathbf{\hat{y}}\)</span> prediction vector</h4>
<p>I’m guessing I have to do sigmoid again to get probability for binary labels.</p>
<p>So something like,</p>
<p><span class="math display">\[\begin{align*}
\mathbf{\hat{y}} &amp;=
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}
=
\begin{bmatrix}
S(z_1^{(2)}) \\
\vdots \\
S(z_n^{(2)})
\end{bmatrix}
\\
&amp; =
\begin{bmatrix}
0.997 \\
0.998 \\
0.999 \\
0.998 \\
0.999 \\
0.999
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y-hat prediction vector:</span><span class="ch">\n</span><span class="st">"</span>,NN.y_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y-hat prediction vector:
 [[0.99641483]
 [0.99884184]
 [0.9991302 ]
 [0.99846025]
 [0.9980438 ]
 [0.99905061]]</code></pre>
</div>
</div>
</section>
</section>
<section id="mse-loss" class="level3">
<h3 class="anchored" data-anchor-id="mse-loss">MSE Loss</h3>
<p>We’re using MSE</p>
<p><span class="math display">\[\begin{align*}
L = \frac{1}{n} \displaystyle \sum_i^n (\hat{y}_i - y_i)^2
\end{align*}\]</span></p>
<p>Gonna start with <span class="math inline">\(\hat{y} - y\)</span></p>
<p><span class="math display">\[\begin{align*}
\mathbf{\hat{y}} - \mathbf{y} &amp;=
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}

-

\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}

=

\begin{bmatrix}
\hat{y}_1 - y_1 \\
\vdots \\
\hat{y}_n - y_n \\
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
0.997 \\
0.998 \\
0.999 \\
0.998 \\
0.999 \\
0.999
\end{bmatrix}
-
\begin{bmatrix}
0 \\
1 \\
1 \\
0 \\
0 \\
1
\end{bmatrix}
=
\begin{bmatrix}
0.997  \\
-0.002 \\
-0.001 \\
0.998  \\
0.999  \\
-0.001
\end{bmatrix}
\end{align*}\]</span></p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"(y_hat) - y:</span><span class="ch">\n</span><span class="st">"</span>, NN.y_hat<span class="op">-</span>NN.y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(y_hat) - y:
 [[ 9.96414833e-01]
 [-1.15816313e-03]
 [-8.69800396e-04]
 [ 9.98460246e-01]
 [ 9.98043796e-01]
 [-9.49391810e-04]]</code></pre>
</div>
</div>
<p><span class="math display">\[\begin{align*}
\Rightarrow
L  \frac{1}{n} \displaystyle \sum_i^n (\hat{y}_i - y_i)^2
\approx 0.498
\end{align*}\]</span></p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MSE Loss:"</span>,NN.MSE_loss(y_hat<span class="op">=</span>NN.y_hat,y<span class="op">=</span>NN.y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE Loss: 0.49764329995811907</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="writing-out-the-derivatives-by-hand." class="level1">
<h1>4) Writing out the derivatives by hand.</h1>
<p>For this part and in order to help you to code the back propagation, write out the derivatives for updating <span class="math inline">\(\mathbf{W1}\)</span>, <span class="math inline">\(\mathbf{W2}\)</span>, <span class="math inline">\(\mathbf{B}\)</span>, and <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p>Please write them clearly :)</p>
<p>You can do this “matrix style” - so for example, <span class="math inline">\(\frac{\partial L}{\partial \mathbf{W1}}\)</span>, or you can write them out individually, such as <span class="math inline">\(\frac{\partial L}{dw_{11}}\)</span>, <span class="math inline">\(\frac{\partial L}{\partial w_{12}}\)</span>, etc…</p>
<p>Either way, show all your work and illustrate how the matrices (such as <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{W_2}\)</span>, etc. etc.) will all fit together to create the final derivative.</p>
<p><strong>Hints:</strong> There are many examples on the PowerPoints. We reviewed this in class. You can also see examples of this in my code examples which are all here: <a href="https://gatesboltonanalytics.com/?page_id=680">Gates Bolton Analytics - Neural Networks Page</a></p>
<section id="jks-answer-2" class="level2">
<h2 class="anchored" data-anchor-id="jks-answer-2">JK’s answer:</h2>
<p>Parameters we want to update via back propagation (and gradient descent):</p>
<span class="math display">\[\begin{aligned}
\begin{array}{ccc}
\hline
\text{Parameter} &amp; \text{Matrix/Vector form} &amp; \text{Shape} \\
\hline
\\

W^{(1)} &amp;
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}
&amp;
[3 \times 4]\\

\\
\hline
\\

\mathbf{B} &amp;
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}
&amp;
[n \times 1]\\

\\
\hline
\\

W^{(2)} &amp;
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}
&amp;
[4 \times 1]\\

\\
\hline
\\

\mathbf{C} &amp;
\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}
&amp;
[n \times 1]

\end{array}
\end{aligned}\]</span>
<p>And I believe for gradient descent to work properly, I think the (final matrix/vector form of the) partial derivatives of each parameter needs to match the shape of the original parameter.</p>
<p>Other relevant formulas:</p>
<span class="math display">\[\begin{aligned}
\begin{array}{c|c|c|c}
\hline
\text{Variable (matrix/vector form)}&amp; \text{Shape} &amp; \text{Vector/Matrix Formula} &amp; \text{Element-wise formula} \\
\hline \\

L &amp; \text{(scalar)} &amp; \frac{1}{2}([\mathbf{\hat{y}} - \mathbf{y}]\cdot[\mathbf{\hat{y}} - \mathbf{y}]) &amp; L = \frac{1}{2} \displaystyle\sum_i^n (\hat{y}_i - y_i)^2 \\
\\
\hline \\

\mathbf{\hat{y}} =
\begin{bmatrix}
\hat{y}_1 \\
\vdots \\
\hat{y}_n \\
\end{bmatrix}
=
\begin{bmatrix}
S(z_1^{(2)}) \\
\vdots \\
S(z_n^{(2)})
\end{bmatrix}
&amp;
[n \times 1]
&amp;
\mathbf{\hat{y}} = S(Z^{(2)})
&amp; \hat{y}_i = S(z_i^{(2)}) \\
\\
\hline
\\

Z^{(2)} = \begin{bmatrix}
z_1^{(2)} \\
\vdots \\
z_n^{(2)}
\end{bmatrix}
&amp;
[n \times 4]
&amp;
Z^{(2)} = H_1 W^{(2)} + C
&amp; z_i^{(2)} = \displaystyle \sum_k^4 h_{i,k}w_k^{(2)} + c_i \\

\\
\hline
\\

H_1 =
\begin{bmatrix}
h_{11} &amp; h_{12} &amp; h_{13} &amp; h_{14} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
h_{n1} &amp; h_{n2} &amp; h_{n3} &amp; h_{n4} \\
\end{bmatrix}
&amp;
[n \times 4]
&amp;
H_1 = S(Z^{(1)})
&amp;
h_{i,k} = S(z_{i,k}^{(1)}) \\

\\
\hline
\\

Z^{(1)} =
\begin{bmatrix}
z_{11} &amp; z_{12} &amp; z_{13} &amp; z_{14} \\
z_{21} &amp; z_{22} &amp; z_{23} &amp; z_{24} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
z_{n1} &amp; z_{n2} &amp; z_{n3} &amp; z_{n4}
\end{bmatrix}
&amp;
[n \times 4]
&amp;
Z^{(1)} =  X\cdot W_1 + B
&amp;
z_{i,k} = \displaystyle \sum_j^3 x_{i,j}w_{j,k} + b_i \\

\end{array}
\end{aligned}\]</span>
<p>Reminder (to self) the following are specific to the architecture of this assignment:</p>
<ul>
<li><span class="math inline">\(4\)</span> comes from the number of units in the hidden layer</li>
<li><span class="math inline">\(3\)</span> comes from the number of inputs/columns in <span class="math inline">\(X\)</span></li>
<li>(<span class="math inline">\(n\)</span> in this is supposed to be 6 for the dataset I created)</li>
</ul>
<p><strong>Other potentially useful multiplication notation to match with python.</strong></p>
<p>I will try my best to match the multiplication notation as done in Professor Gates’ lecture slides.</p>
<p>Thus, I will use an “o-dot” (<span class="math inline">\(\odot\)</span>) to represent matrix multiplcation, (equivalent to <code>@</code> in Python) i.e.:</p>
<p><span class="math display">\[\begin{align*}
A \odot B =
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}\\
\end{bmatrix}
\odot
\begin{bmatrix}
b_{11} &amp; b_{12} \\
b_{21} &amp; b_{22} \\
\end{bmatrix}
=
\begin{bmatrix}
a_{11}b_{11} + a_{12}b_{21} &amp; a_{11}b_{12} + a_{12}b_{22} \\
a_{21}b_{11} + a_{22}b_{21} &amp; a_{21}b_{12} + a_{22}b_{22}
\end{bmatrix}
\end{align*}\]</span></p>
<p>And I will use an asterisk (<span class="math inline">\(\ast\)</span>) for element-wise (“regular”) multiplication, (equivalent to <code>*</code> in Python) i.e.:</p>
<p><span class="math display">\[\begin{align*}
A \ast B =
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}\\
\end{bmatrix}
\ast
\begin{bmatrix}
b_{11} &amp; b_{12} \\
b_{21} &amp; b_{22} \\
\end{bmatrix}
=
\begin{bmatrix}
a_{11}b_{11} &amp; a_{12}b_{12} \\
a_{21}b_{21} &amp; a_{22}b_{22}
\end{bmatrix}
\end{align*}\]</span></p>
<section id="fracpartial-lpartial-c" class="level3">
<h3 class="anchored" data-anchor-id="fracpartial-lpartial-c"><span class="math inline">\(\frac{\partial L}{\partial C}\)</span></h3>
<p><span class="math display">\[\begin{equation*}
C =
\begin{bmatrix}
c_1 \\
\vdots \\
c_n
\end{bmatrix}
\end{equation*}\]</span></p>
<p>Let’s start with finding <span class="math inline">\(\frac{\partial L}{\partial c_i}\)</span></p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial c_i} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial c_i}
\end{align*}\]</span></p>
<p>Breaking down each partial derivative one at a time:</p>
<p><span class="math display">\[\begin{align*}
L &amp;= \frac{1}{2} \displaystyle\sum_i^n (\hat{y}_i - y_i)^2 \\
\Rightarrow
\frac{\partial L}{\partial \hat{y}_i} &amp;= \frac{1}{2} (2) (\hat{y}_i - y_i) \\
&amp;= \hat{y}_i - y_i
\end{align*}\]</span></p>
<p>Then we have <span class="math inline">\(\frac{\partial \hat{y}_i}{\partial z_i^{(2)}}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\hat{y}_i = S(z_i^{(2)})
\end{align*}\]</span></p>
<p>And reminder: <span class="math inline">\(\frac{d}{dz} S(z) = S(z)(1-S(z))\)</span></p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
\frac{\partial \hat{y}_i}{\partial z^{(2)}_i} &amp;= S(z^{(2)}_i)(1-S(z^{(2)}_i)) \\
&amp;= \hat{y}_i(1- \hat{y}_i)
\end{align*}\]</span></p>
<p>Then finally we have <span class="math inline">\(\frac{\partial z^{(2)}_i}{\partial c_i}\)</span></p>
<p><span class="math display">\[\begin{align*}
z_i^{(2)} &amp;= \displaystyle \sum_k^4 h_{i,k}w_k^{(2)} + c_i \\
\Rightarrow
\frac{\partial z^{(2)}_i}{\partial c_i} &amp;= 0 + (1)
\end{align*}\]</span></p>
<p>So altogether we have,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial c_i} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial c_i} \\

&amp;=
\underbrace{(\hat{y}_i - y_i)}_{\textstyle \frac{\partial L}{ \partial \hat{y}_i}}
\underbrace{S(z^{(2)}_i)(1-S(z^{(2)}_i))}_{\textstyle \frac{\partial \hat{y}_i}{\partial z^{(2)}_i}}
\underbrace{(1)}_{\textstyle \frac{\partial z^{(2)}_i}{\partial c_i}} \\

&amp;= [\hat{y}_i - y_i][\hat{y}_i(1- \hat{y}_i)][1]
\end{align*}\]</span></p>
<p>So I think I can summarize this derivative with the following vector notation:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial C} &amp;=
\begin{bmatrix}
(\hat{y}_1 - y_1)(\hat{y}_1 - (\hat{y}_1)^2) (1)\\
\vdots \\
(\hat{y}_n - y_n)(\hat{y}_n - (\hat{y}_n)^2) (1)
\end{bmatrix}
\end{align*}\]</span></p>
<p>I can probably <em>technically</em> stop here, but I want to see if I can make things “simpler” notation to start thinking about how I can translate these into Python.</p>
<p>I want to start by breaking these into their own matrices. For instance, maybe we can call the matrix/vector for <span class="math inline">\(\frac{\partial L}{\partial \hat{y}_i}\)</span>, <span class="math inline">\(E\)</span> (can be anything though).</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial \hat{y}_i} &amp;= \mathbf{\hat{y}} - \mathbf{y} =
\begin{bmatrix}
\hat{y}_1 - y_1\\
\vdots \\
\hat{y}_n - y_n
\end{bmatrix} \\
&amp;= E
\end{align*}\]</span></p>
<p>And then maybe call the matrix/vector for <span class="math inline">\(\frac{\partial \hat{y}_i}{\partial z^{(2)}_i}\)</span>, <span class="math inline">\(\Phi\)</span>.</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial \hat{y}_i}{\partial z^{(2)}_i} &amp;= S(z^{(2)}_i)(1-S(z^{(2)}_i)) \\
&amp;= \hat{y}_i(1- \hat{y}_i) \\
&amp;= \hat{y}_i - (\hat{y}_i)^2 \\
&amp;= \mathbf{\hat{y}} - (\mathbf{\hat{y}} \ast \mathbf{\hat{y}}) \\
&amp;= \Phi
\end{align*}\]</span></p>
<p>And this is not really vital, but just for the sake of clarity and commiting to everything written before, I’ll will use <span class="math inline">\(\vec{1}_n\)</span> as notation of a vector entirely made of ones, where <span class="math inline">\(n\)</span> is the number of elements in the vector.</p>
<p>i.e:</p>
<p><span class="math display">\[\begin{align*}
\vec{1}_3 =  
\begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}
\end{align*}\]</span></p>
<p>Thus I think I can finalize the matrix/vector notation as follows for this partial derivative:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial C} &amp;=
\begin{bmatrix}
(\hat{y}_1 - y_1)(\hat{y}_1 - (\hat{y}_1)^2) (1)\\
\vdots \\
(\hat{y}_n - y_n)(\hat{y}_n - (\hat{y}_n)^2) (1)
\end{bmatrix}\\
&amp;=
\begin{bmatrix}
\hat{y}_1 - y_1\\
\vdots \\
\hat{y}_n - y_n
\end{bmatrix}
\ast
\begin{bmatrix}
\hat{y}_1 - (\hat{y}_1)^2 \\
\vdots \\
\hat{y}_n - (\hat{y}_n)^2
\end{bmatrix}
\ast
\begin{bmatrix}
1 \\
\vdots \\
1
\end{bmatrix}\\

&amp;= E \ast \Phi \ast \vec{1}_n
\end{align*}\]</span></p>
<p>Because the vector of ones (<span class="math inline">\(\vec{1}_n\)</span>), we can also see that technically <span class="math inline">\(\frac{\partial L}{\partial C} = \frac{\partial L}{\partial Z^{(2)}}\)</span></p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial C}

&amp;= E \ast \Phi \\
&amp;= \frac{\partial L}{\partial \mathbf{\hat{y}}} \cdot \frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}
\end{align*}\]</span></p>
<p>This will come in handy with the rest of the derivatives as we’ll soon see.</p>
</section>
<section id="fracpartial-lpartial-w2" class="level3">
<h3 class="anchored" data-anchor-id="fracpartial-lpartial-w2"><span class="math inline">\(\frac{\partial L}{\partial W^{(2)}}\)</span></h3>
<p><span class="math display">\[\begin{align*}
W^{(2)} =
\begin{bmatrix}
w_1^{(2)} \\[6pt]
w_2^{(2)} \\[6pt]
w_3^{(2)} \\[6pt]
w_4^{(2)} \\[6pt]
\end{bmatrix}
\end{align*}\]</span></p>
<p>Let’s start small again,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_k^{(2)}} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial w_k^{(2)}}
\end{align*}\]</span></p>
<p>First pattern emerges! We’ve seen <span class="math inline">\(\textstyle \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i}\)</span> before when deriving <span class="math inline">\(\frac{\partial L}{\partial C}\)</span>.</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} &amp;= \frac{\partial L}{\partial \mathbf{\hat{y}}} \cdot \frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}} \\
&amp;= E \ast \Phi
\end{align*}\]</span></p>
<p>Yay! So that essentially means all I have to worry about is <span class="math inline">\(\frac{\partial z^{(2)}_i}{\partial w_k^{(2)}}\)</span>.</p>
<p>So we had,</p>
<p><span class="math display">\[\begin{align*}
z_i^{(2)}
&amp;= \sum_k^4 h_{i,k}w_k^{(2)} + c_i\\
\Rightarrow
\frac{\partial z^{(2)}_i}{\partial w_k^{(2)}} &amp;= h_{i,k}(1) + 0 \\
&amp;= h_{i,k}
\end{align*}\]</span></p>
<p>Where in this case, (<span class="math inline">\(i=1,\dots,n\)</span>) and (<span class="math inline">\(k=1,\dots,4\)</span>).</p>
<p>Thus,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial z^{(2)}_i}{\partial w_k^{(2)}} &amp;= h_{i,k} \\
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
\frac{\partial Z^{(2)}}{\partial W^{(2)}} &amp;=

\begin{bmatrix}
\frac{\partial z^{(2)}_1}{\partial w_1^{(2)}} &amp; \frac{\partial z^{(2)}_1}{\partial w_2^{(2)}} &amp; \frac{\partial z^{(2)}_1}{\partial w_3^{(2)}} &amp; \frac{\partial z^{(2)}_1}{\partial w_4^{(2)}} \\[6pt]
\frac{\partial z^{(2)}_2}{\partial w_1^{(2)}} &amp; \frac{\partial z^{(2)}_2}{\partial w_2^{(2)}} &amp; \frac{\partial z^{(2)}_2}{\partial w_3^{(2)}} &amp; \frac{\partial z^{(2)}_2}{\partial w_4^{(2)}} \\[6pt]
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\frac{\partial z^{(2)}_n}{\partial w_1^{(2)}} &amp; \frac{\partial z^{(2)}_n}{\partial w_2^{(2)}} &amp; \frac{\partial z^{(2)}_n}{\partial w_3^{(2)}} &amp; \frac{\partial z^{(2)}_n}{\partial w_4^{(2)}} \\[6pt]
\end{bmatrix}\\

&amp;=
\begin{bmatrix}
h_{11} &amp; h_{12} &amp; h_{13} &amp; h_{14} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
h_{n1} &amp; h_{n2} &amp; h_{n3} &amp; h_{n4} \\
\end{bmatrix} \\
&amp;=H_1 \\
\end{align*}\]</span></p>
<p>So finally we have,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_k^{(2)}}
&amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial w_k^{(2)}}\\
&amp;= [\hat{y}_i - y_i][\hat{y}_i(1- \hat{y}_i)](h_{i,k})\\

\Rightarrow
\frac{\partial L}{\partial W^{(2)}} &amp;= \underbrace{\frac{\partial L}{\partial \mathbf{\hat{y}}}}_E \cdot \underbrace{\frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}}_{\textstyle \Phi} \cdot \underbrace{\frac{\partial Z^{(2)}}{\partial W^{(2)}}}_{H_1} \\
\end{align*}\]</span></p>
<p><span class="math inline">\(E \ast \Phi\)</span> has shape (<span class="math inline">\(n \times 1\)</span>), and <span class="math inline">\(H_1\)</span> has shape (<span class="math inline">\(n \times 4\)</span>). We want the final matrix of the partial derivative (<span class="math inline">\(\frac{\partial L}{\partial W^{(2)}}\)</span>) to match the shape of <span class="math inline">\(W^{(2)}\)</span>, (<span class="math inline">\(4 \times 1\)</span>) (or the transpose (<span class="math inline">\(1 \times 4\)</span>)).</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial W^{(2)}} &amp;= \underbrace{\frac{\partial L}{\partial \mathbf{\hat{y}}}}_E \cdot \underbrace{\frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}}_{\textstyle \Phi} \cdot \underbrace{\frac{\partial Z^{(2)}}{\partial W^{(2)}}}_{H_1} \\
&amp;= [E \ast \Phi] \odot H_1
\end{align*}\]</span></p>
</section>
<section id="fracpartial-lpartial-b" class="level3">
<h3 class="anchored" data-anchor-id="fracpartial-lpartial-b"><span class="math inline">\(\frac{\partial L}{\partial B}\)</span></h3>
<p><span class="math display">\[\begin{equation*}
\mathbf{B} =
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}
\end{equation*}\]</span></p>
<p>Starting small again,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial b_i} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial h_{ik}} \cdot \frac{\partial h_{ik}}{\partial z_{ik}^{(1)}} \cdot \frac{\partial z_{ik}^{(1)}}{\partial b_i}
\end{align*}\]</span></p>
<p>Again, since we’re already familiar with <span class="math inline">\(\frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i}\)</span>, we will focus on the last few partial derivatives.</p>
<p>Starting with <span class="math inline">\(\frac{\partial z^{(2)}_i}{\partial h_{ik}}\)</span>.</p>
<p><span class="math display">\[\begin{align*}
z_{i}^{(2)} &amp;= \displaystyle \sum_k^4 h_{ik}w_k^{(2)} + c_i \\
\Rightarrow
\frac{\partial z^{(2)}_i}{\partial h_{ik}} &amp;= \sum_k^4 (1)w_k^{(2)} + 0 \\
&amp;= \sum_k^4 w_k^{(2)}
\end{align*}\]</span></p>
<p>(I don’t think I can put this in itself into a matrix, but I can start to see this can utilize a dot product (matrix multiplication))</p>
<p>Then <span class="math inline">\(\frac{\partial h_{ik}}{\partial z_{ik}}\)</span>,</p>
<p><span class="math display">\[\begin{align*}
h_{ik} &amp;= S(z_{ik}^{(1)}) \\
\Rightarrow
\frac{\partial h_{ik}}{\partial z_{ik}^{(1)}} &amp;= S(z_{ik}^{(1)})(1 - S(z_{ik}^{(1)})) \\
&amp;= h_{ik}(1 - h_{ik}) \\
&amp;= h_{ik} - (h_{ik})^2 \\
\end{align*}\]</span> We can put this in matrix form again, and perhaps call it <span class="math inline">\(\Omega\)</span>.</p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
\frac{\partial H_1}{\partial Z^{(1)}} &amp;= H_1 - [H_1 \ast H_1] \\
&amp;= \Omega
\end{align*}\]</span></p>
<p>Then finally, <span class="math inline">\(\frac{\partial z_{ik}^{(1)}}{\partial b_i}\)</span>,</p>
<p><span class="math display">\[\begin{align*}
z_{i,k}^{(1)} &amp;= \sum_j^3 x_{i,j}w_{j,k} + b_i \\
\Rightarrow
\frac{\partial z_{ik}^{(1)}}{\partial b_i} &amp;= 0 + (1)
\end{align*}\]</span></p>
<p>I can summarize this as a vector of ones again.</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial Z^{(1)}}{\partial B} &amp;=
\begin{bmatrix}
1 \\
\vdots \\
1
\end{bmatrix} \\
&amp;= \vec{1}_n
\end{align*}\]</span></p>
<p>Altogether, we get something like this:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial b_i} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial h_{ik}} \cdot \frac{\partial h_{ik}}{\partial z_{ik}^{(1)}} \cdot \frac{\partial z_{ik}^{(1)}}{\partial b_i} \\
&amp;= [\hat{y}_i - y_i][\hat{y}_i(1- \hat{y}_i)](\displaystyle \sum_k^4 w_k^{(2)}) [h_{ik} - (h_{ik})^2][1]
\end{align*}\]</span></p>
<p>As mentioned before, <span class="math inline">\(E \ast \Phi\)</span> has shape (<span class="math inline">\(n \times 1\)</span>), <span class="math inline">\(\Omega\)</span> has the same shape as <span class="math inline">\(H_1\)</span>, (<span class="math inline">\(n \times 4\)</span>). And we can use a dot product (matrix multiplication) with <span class="math inline">\(W^{(2)}\)</span> to get <span class="math inline">\(\sum w_k{(2)}\)</span>, and <span class="math inline">\(W^{(2)}\)</span> has shape (<span class="math inline">\(4 \times 1\)</span>). We want the final matrix of the partial derivative (<span class="math inline">\(\frac{\partial L}{\partial B}\)</span>) to match the shape of <span class="math inline">\(\mathbf{B}\)</span>, (<span class="math inline">\(n \times 1\)</span>) (or the transpose (<span class="math inline">\(1 \times n\)</span>)).</p>
<p>Thus we can build the matrix/vector formula as such:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial B} &amp;= \underbrace{\frac{\partial L}{\partial \mathbf{\hat{y}}} \cdot \frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}}_{E \ast \Phi} \cdot \underbrace{\frac{\partial Z^{(2)}}{\partial H_1}}_{W^{(2)}} \cdot \underbrace{\frac{\partial H_1}{\partial Z^{(1)}}}_{\Omega} \cdot \underbrace{\frac{\partial Z^{(1)}}{\partial B}}_{\vec{1}_n} \\
\Rightarrow
&amp;= [E \ast \Phi] \ast [\Omega \odot W^{(2)}] \ast \vec{1}_n \\
&amp;= [E \ast \Phi] \ast [\Omega \odot W^{(2)}]
\end{align*}\]</span></p>
</section>
<section id="fracpartial-lpartial-w1" class="level3">
<h3 class="anchored" data-anchor-id="fracpartial-lpartial-w1"><span class="math inline">\(\frac{\partial L}{\partial W^{(1)}}\)</span></h3>
<p>(FINALLY)</p>
<p><span class="math display">\[\begin{align*}
W^{(1)} =
\begin{bmatrix}
w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} \\
w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} \\
w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34}
\end{bmatrix}
\end{align*}\]</span></p>
<p>Let’s start element-wise again,</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_{j,k}^{(1)}} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial h_{ik}} \cdot \frac{\partial h_{ik}}{\partial z_{ik}^{(1)}} \cdot \frac{\partial z_{ik}^{(1)}}{\partial w_{jk}^{(1)}}
\end{align*}\]</span></p>
<p>Much like last time, we only need the last derivative (<span class="math inline">\(\frac{\partial z_{ik}^{(1)}}{\partial w_{jk}^{(1)}}\)</span>).</p>
<p><span class="math display">\[\begin{align*}
z_{i,k}^{(1)} &amp;= \sum_j^3 x_{i,j}w_{j,k} + b_i \\
\Rightarrow
\frac{\partial z_{ik}^{(1)}}{\partial w_{jk}^{(1)}} &amp;= \sum_j^3 x_{i,j}(1) + 0\\
&amp;= x_{i,j} \\
\end{align*}\]</span></p>
<p>It appears that regardless of the value of <span class="math inline">\(k\)</span> the partial derivative is an <span class="math inline">\(x\)</span> value associated the row of <span class="math inline">\(z\)</span> (the <span class="math inline">\(i\)</span> value), and the column of <span class="math inline">\(w^{(1)}\)</span> (value of <span class="math inline">\(j\)</span>).</p>
<p><span class="math display">\[\begin{align*}
\Rightarrow \frac{\partial z_{i1}^{(1)}}{\partial w_{j1}^{(1)}} &amp;= \frac{\partial z_{i2}^{(1)}}{\partial w_{j2}^{(1)}} = \frac{\partial z_{i3}^{(1)}}{\partial w_{j3}^{(1)}} = \frac{\partial z_{i4}^{(1)}}{\partial w_{j4}^{(1)}} = x_{i,j} \\
\end{align*}\]</span></p>
<p>Thus I think I can summarize as the following matrix (which turns out to be X)</p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
\frac{\partial Z^{(1)}}{\partial W^{(1)}} &amp;=
\begin{bmatrix}
\frac{\partial z_{1k}^{(1)}}{\partial w_{1k}^{(1)}} &amp; \frac{\partial z_{1k}^{(1)}}{\partial w_{2k}^{(1)}} &amp;
\frac{\partial z_{1k}^{(1)}}{\partial w_{3k}^{(1)}} \\[8pt]
\frac{\partial z_{2k}^{(1)}}{\partial w_{1k}^{(1)}} &amp; \frac{\partial z_{2k}^{(1)}}{\partial w_{2k}^{(1)}} &amp;
\frac{\partial z_{2k}^{(1)}}{\partial w_{3k}^{(1)}} \\[8pt]
\vdots &amp; \vdots &amp; \vdots \\[6pt]
\frac{\partial z_{nk}^{(1)}}{\partial w_{1k}^{(1)}} &amp; \frac{\partial z_{nk}^{(1)}}{\partial w_{2k}^{(1)}} &amp;
\frac{\partial z_{nk}^{(1)}}{\partial w_{3k}^{(1)}} \\[8pt]
\end{bmatrix}\\
&amp; =
\begin{bmatrix}
x_{11} &amp; x_{12} &amp; x_{13} \\
\vdots  &amp; \vdots  &amp; \vdots  \\
x_{n1} &amp; x_{n2} &amp; x_{n3} \\
\end{bmatrix} \\
&amp;= X
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_{j,k}^{(1)}} &amp;= \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial z^{(2)}_i} \cdot \frac{\partial z^{(2)}_i}{\partial h_{ik}} \cdot \frac{\partial h_{ik}}{\partial z_{ik}^{(1)}} \cdot \frac{\partial z_{ik}^{(1)}}{\partial w_{jk}^{(1)}} \\
&amp;= [\hat{y}_i - y_i][\hat{y}_i(1- \hat{y}_i)](\displaystyle \sum_k^4 w_k^{(2)}) [h_{ik} - (h_{ik})^2][x_{ij}] \\
\Rightarrow
\frac{\partial L}{\partial W^{(1)}} &amp;= \underbrace{\frac{\partial L}{\partial \mathbf{\hat{y}}} \cdot \frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}}_{E \ast \Phi} \cdot \underbrace{\frac{\partial Z^{(2)}}{\partial H_1}}_{W^{(2)}} \cdot \underbrace{\frac{\partial H_1}{\partial Z^{(1)}}}_{\Omega} \cdot \underbrace{\frac{\partial Z^{(1)}}{\partial W^{(1)}}}_{X} \\
\end{align*}\]</span></p>
<p>The following is just to check the shapes work out as hoped:</p>
<p><span class="math display">\[\begin{align*}
\Rightarrow
&amp;= \underbrace{X^\top}_{(3 \times n)} \odot [(\underbrace{[E \ast \Phi]}_{(n \times 1)} \odot \underbrace{W^{(2)\top}}_{(1 \times 4)}) \ast \underbrace{\Omega}_{(n \times 4)}] \\
&amp;= \underbrace{X^\top}_{(3 \times n)} \odot [(\underbrace{[E \ast \Phi] \odot W^{(2)\top}}_{(n \times 4)}) \ast \underbrace{\Omega}_{(n \times 4)}] \\
&amp;= \underbrace{X^\top}_{(3 \times n)} \odot \underbrace{[([E \ast \Phi] \odot W^{(2)\top}) \ast \Omega]}_{(n \times 4)} \\
\end{align*}\]</span></p>
<p>The final shape is (<span class="math inline">\(3 \times 4\)</span>) matrix as hoped, thus:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial W^{(1)}}
&amp;= \frac{\partial L}{\partial \mathbf{\hat{y}}}
\cdot
\frac{\partial \mathbf{\hat{y}}}{\partial Z^{(2)}}
\cdot
\frac{\partial Z^{(2)}}{\partial H_1}
\cdot
\frac{\partial H_1}{\partial Z^{(1)}}
\cdot
\frac{\partial Z^{(1)}}{\partial W^{(1)}} \\
&amp;=
X^\top \odot [([E \ast \Phi] \odot W^{(2)\top}) \ast \Omega]
\end{align*}\]</span></p>
</section>
</section>
</section>
<section id="adding-back-propagation-to-your-code-so-that-mathbfw_1-mathbfb-and-c-are-updated." class="level1">
<h1>5) Adding Back Propagation to your code so that <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{B}\)</span>, and <span class="math inline">\(C\)</span> are updated.</h1>
<p>For this step, you will add back propagation to your code. Specifically, you already have code <strong>(2)</strong> above. In your code (so far) you have read in your dataset, have created <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>, and have function (or class if you OO programming) for Feed Forward.</p>
<p>In this next step, you will add a function for Back Propagation that will update your parameters. Recall that the parameters for this NN architecture are <span class="math inline">\(\mathbf{W_1}\)</span>, <span class="math inline">\(\mathbf{W_2}\)</span>, <span class="math inline">\(\mathbf{B}\)</span>, and <span class="math inline">\(C\)</span>. Each must be updated (using a learning rate) and the derivatives you calculated in <strong>(4)</strong>.</p>
<p>Once you create code for the Back Propagation, add further code for epochs so that your code will “update” (FF and BP and calculate the Loss each time) for as many iterations (epochs) as you wish.</p>
<p>Be sure to have a visualization of the change in the average Loss over epochs.</p>
<p>Be sure to have a final visualization that is a confusion matrix that shows the label predictions.</p>
<p>Be sure to <strong>print out</strong> some of your matrices so that a viewer can see what you are doing. While there are many ways to do this, you can consider printing <span class="math inline">\(\mathbf{W_1}\)</span>, the updates for <span class="math inline">\(\mathbf{W_1}\)</span>, the new <span class="math inline">\(\mathbf{W_1}\)</span> (which will be the derivative updates times the learning rate added to <span class="math inline">\(\mathbf{W_1}\)</span>). In other words, <strong>make your code verbose (shows/tells what its doing)</strong> so you can print out the last epoch steps. (An example on Canvas)</p>
<p><strong>NOTE:</strong> At this point, you should have code that will read in any dataset with 3 columns of numeric data and one column called “LABEL” (of <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>) and will perform NN modeling and a prediction result on the dataset.</p>
<p><strong>JK’s answer:</strong></p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#%% libraries</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder,MinMaxScaler,StandardScaler</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix  </span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OneLayer_OneOutput():</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>                 data_filename <span class="op">=</span> <span class="st">"A2_Data_JasmineKobayashi.csv"</span>, </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>                 data_normalizer <span class="op">=</span> StandardScaler(),</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>                 hidden_units<span class="op">=</span> <span class="dv">4</span>,</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>                 randomize_initial_parameters <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>                 verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read Data</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.df <span class="op">=</span> pd.read_csv(data_filename)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create X and y, assuming data has column "LABEL" as column with labels</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">## X matrix</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> data_normalizer <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.data_scaler <span class="op">=</span> data_normalizer</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>            X <span class="op">=</span> <span class="va">self</span>.data_scaler.fit_transform(<span class="va">self</span>.df.drop(columns<span class="op">=</span><span class="st">"LABEL"</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"X was normalized using </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(data_normalizer))</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.data_scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>            X <span class="op">=</span> np.array(<span class="va">self</span>.df.drop(columns<span class="op">=</span>[<span class="st">'LABEL'</span>],axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"X was not normalized"</span>)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>        <span class="co">## y</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> np.array(<span class="va">self</span>.df[[<span class="st">'LABEL'</span>]])</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of X:"</span>, <span class="va">self</span>.X.shape)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"X matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.X)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of y:"</span>, <span class="va">self</span>.y.shape)</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"y vector: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.y)</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of W1</span></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>        w1_ncol <span class="op">=</span> hidden_units        <span class="co"># Number of W1 cols should be number of hidden units in H1</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>        w1_nrow <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">1</span>]     <span class="co"># Number of W1 rows should be number of X columns (dim of X)</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of B (column vector)</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>        b_length <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">0</span>]    <span class="co"># length of X rows</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of W2:</span></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>        w2_ncol <span class="op">=</span> <span class="dv">1</span>                   <span class="co"># Number of W2 cols should be number of outputs (in this case, only one output)</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>        w2_nrow <span class="op">=</span> hidden_units        <span class="co"># Number of W2 rows should be number of hidden units in H1</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Shape of C (column vector)</span></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>        c_length <span class="op">=</span> <span class="va">self</span>.X.shape[<span class="dv">0</span>]    <span class="co"># length of X rows</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> randomize_initial_parameters: </span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># </span><span class="al">TODO</span><span class="co">: Finish potential code of randomized parameters</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># # bounds of randomized weights</span></span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># bound = 1/np.sqrt(w1_nrow)   # I found online that supposedly this is a standard range for randomized weights</span></span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># rand_w = [np.random.uniform(-bound,bound) for i in range(w1_ncol)]</span></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># self.W1 = np.array([rand_w]*w1_nrow)</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># self.W2 = np.array([]*w2_nrow)</span></span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print('All parameters were randomized')</span></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:   <span class="co"># These are the parameters defined by the question 2 in Assignment2</span></span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W1 <span class="op">=</span> np.array([[<span class="dv">1</span>]<span class="op">*</span>w1_ncol]<span class="op">*</span>w1_nrow) <span class="co"># otherwise, all weights of W1 = 1</span></span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.B <span class="op">=</span> np.array([[<span class="dv">0</span>]]<span class="op">*</span>b_length)         <span class="co"># otherwise, all bias (B) = 0</span></span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W2 <span class="op">=</span> np.array([[<span class="dv">2</span>]<span class="op">*</span>w2_ncol]<span class="op">*</span>w2_nrow) <span class="co"># otherwise, all weights of W2 = 2</span></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.C <span class="op">=</span> np.array([[<span class="dv">0</span>]]<span class="op">*</span>c_length)</span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Parameters built for simple calculation (not randomized)"</span>)</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of X cols (should be # of W1 rows):", self.X.shape[1])</span></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of hidden units (should be # of W1 cols):", hidden_units)</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W1 has shape:"</span>, <span class="va">self</span>.W1.shape)</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W1 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W1)</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of B:"</span>, <span class="va">self</span>.B.shape)</span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"B (bias vector for Z1): </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.B)</span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of W2:"</span>,<span class="va">self</span>.W2.shape)</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"W2 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W2)</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of C :"</span>, <span class="va">self</span>.C.shape)</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"C (bias vector for Z2): </span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.C)</span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> MSE_loss(<span class="va">self</span>,y_hat,y):</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># L = mean((y_hat - y)^2)</span></span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.mean((y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> lin_eq(<span class="va">self</span>,X,W,B):</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> X.shape[<span class="dv">1</span>] <span class="op">==</span> W.shape[<span class="dv">0</span>], <span class="st">"Linear eq: z = X @ W + B. Shape of X: </span><span class="sc">{}</span><span class="st">; Shape of W: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(X.shape,W.shape)</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> B.shape[<span class="dv">0</span>] <span class="op">==</span> X.shape[<span class="dv">0</span>], <span class="st">"Linear eq: z = X @ W + B. Length of B should match X rows; Length B = </span><span class="sc">{}</span><span class="st">; Shape of X = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(B.shape[<span class="dv">0</span>],X.shape)</span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X <span class="op">@</span> W <span class="op">+</span> B</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Sigmoid(<span class="va">self</span>,z,</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>                derivative <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> derivative:</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.Sigmoid(z) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.Sigmoid(z)) <span class="co"># dS/dz = S(z)(1-S(z))</span></span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sigmoid</span></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> math.e<span class="op">**</span>(<span class="op">-</span>z)) <span class="co"># S(z) = 1/(1 + e^(-z))</span></span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> FeedForward(<span class="va">self</span>,</span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>                    activation <span class="op">=</span> <span class="st">"sigmoid"</span>,</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>                    verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create H1</span></span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z1 = X @ W1 + B</span></span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Z1 <span class="op">=</span> <span class="va">self</span>.lin_eq(<span class="va">self</span>.X,<span class="va">self</span>.W1,<span class="va">self</span>.B)</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of Z1:"</span>,<span class="va">self</span>.Z1.shape)</span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Z1 matrix: </span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.Z1)</span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.H1 <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z1)</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>        <span class="co"># </span><span class="al">TODO</span><span class="co">: Add flexibility with other activation functions</span></span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose: </span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Activation function:"</span>,activation)</span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"H1 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.H1)</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z2 and y-hat</span></span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z2 = H1 @ W2 + C</span></span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Z2 <span class="op">=</span> <span class="va">self</span>.lin_eq(<span class="va">self</span>.H1,<span class="va">self</span>.W2,<span class="va">self</span>.C)</span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_hat <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z2)</span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of Z2:"</span>, <span class="va">self</span>.Z2.shape)</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Z2 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.Z2)</span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"y_hat:</span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.y_hat)</span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gradient descent----------------------------------------------</span></span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> grad_desc(<span class="va">self</span>,y_hat,y,LR,</span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>                  verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Error = y^ - y = E</span></span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.E <span class="op">=</span> y_hat <span class="op">-</span> y                                      <span class="co"># shape = n x 1 </span></span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dy^/dZ2 = S(Z2)(1 - S(Z2)) = y^(1 - y^) = y^ - (y^)(y^) = Phi</span></span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Phi <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z2,derivative<span class="op">=</span><span class="va">True</span>)        <span class="co"># shape = Z2.shape = n x 1</span></span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dL/dZ2  = [y^-y][S(Z2)(1 - S(Z2))] is a term that shows up in every gradient </span></span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># so it's going to be useful to save this</span></span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dL_dZ2 <span class="op">=</span> <span class="va">self</span>.E <span class="op">*</span> <span class="va">self</span>.Phi                                   <span class="co"># shape = [n x 1]*[n x 1] =&gt; [n x 1]</span></span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dH_dZ1 <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z1,derivative<span class="op">=</span><span class="va">True</span>)     <span class="co"># shape = Z1.shape = n x 4</span></span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dL/dC = [dL/dy^][dy^/dZ2][dZ2/C] </span></span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>        <span class="co">#       = [y^-y][S(Z2)(1 - S(Z2))][1]</span></span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dZ2_dC <span class="op">=</span> np.array([[<span class="dv">1</span>]]<span class="op">*</span><span class="va">self</span>.C.shape[<span class="dv">0</span>])           <span class="co"># vector of 1s with same shape of C</span></span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dL_dC <span class="op">=</span> <span class="va">self</span>.dL_dZ2 <span class="op">*</span> <span class="va">self</span>.dZ2_dC                            <span class="co"># should match shape of C (n x 1)</span></span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-149"><a href="#cb31-149" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dL/dW2 = [dL/dy^][dy^/dZ2][dZ2/W2] </span></span>
<span id="cb31-150"><a href="#cb31-150" aria-hidden="true" tabindex="-1"></a>        <span class="co">#        = [y^-y][S(Z2)(1 - S(Z2))][H1]</span></span>
<span id="cb31-151"><a href="#cb31-151" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dL_dW2 <span class="op">=</span>  <span class="va">self</span>.H1.T <span class="op">@</span> <span class="va">self</span>.dL_dZ2                         <span class="co"># should match shape of W2 (4 x 1)</span></span>
<span id="cb31-152"><a href="#cb31-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-153"><a href="#cb31-153" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dL/dB = [dL/dy^][dy^/dZ2][dZ2/dH1][dH1/dZ1][dZ1/dB] </span></span>
<span id="cb31-154"><a href="#cb31-154" aria-hidden="true" tabindex="-1"></a>        <span class="co">#       = [y^-y][S(Z2)(1 - S(Z2))][W2][S(Z1)(1-S(Z1))][1]</span></span>
<span id="cb31-155"><a href="#cb31-155" aria-hidden="true" tabindex="-1"></a>        <span class="co">#       = ([y^-y] * [S(Z2)(1 - S(Z2))]) * ([S(Z1)(1-S(Z1))] @ [W2]) * [1] </span></span>
<span id="cb31-156"><a href="#cb31-156" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-157"><a href="#cb31-157" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dH1/dZ1 = S(Z1)(1-S(Z1)) = H1(1-H1)  # I'm going to call this matrix Omega</span></span>
<span id="cb31-158"><a href="#cb31-158" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Omega <span class="op">=</span> <span class="va">self</span>.Sigmoid(<span class="va">self</span>.Z1,derivative <span class="op">=</span> <span class="va">True</span>)      <span class="co"># should match shape of Z1 (n x 4)</span></span>
<span id="cb31-159"><a href="#cb31-159" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dZ1_dB <span class="op">=</span> np.array([[<span class="dv">1</span>]]<span class="op">*</span><span class="va">self</span>.B.shape[<span class="dv">0</span>])           <span class="co"># vector of 1s with same shape of B</span></span>
<span id="cb31-160"><a href="#cb31-160" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [n x n][n x 1][n x 1]</span></span>
<span id="cb31-161"><a href="#cb31-161" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dL_dB <span class="op">=</span> <span class="va">self</span>.dL_dZ2 <span class="op">*</span> (<span class="va">self</span>.Omega <span class="op">@</span> <span class="va">self</span>.W2) <span class="op">*</span> <span class="va">self</span>.dZ1_dB               <span class="co"># should match shape of B (n x 1)</span></span>
<span id="cb31-162"><a href="#cb31-162" aria-hidden="true" tabindex="-1"></a>        <span class="co"># dL/dW1 = [dL/dy^][dy^/dZ2][dZ2/dH1][dH1/dZ1][dZ1/dW1] </span></span>
<span id="cb31-163"><a href="#cb31-163" aria-hidden="true" tabindex="-1"></a>        <span class="co">#        = [y^-y][S(Z2)(1 - S(Z2))][W2][S(Z1)(1-S(Z1))][X] </span></span>
<span id="cb31-164"><a href="#cb31-164" aria-hidden="true" tabindex="-1"></a>        <span class="co">#        = [X]^T @ [([[y^-y] * [S(Z2)(1 - S(Z2))]] @ [W2]) * [S(Z1)(1-S(Z1))]] </span></span>
<span id="cb31-165"><a href="#cb31-165" aria-hidden="true" tabindex="-1"></a>        <span class="co">#        = [X]^T @ [([E * Phi] * [W2]^T) * Omega]</span></span>
<span id="cb31-166"><a href="#cb31-166" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dL_W1 <span class="op">=</span> <span class="va">self</span>.X.T <span class="op">@</span> (( (<span class="va">self</span>.E <span class="op">*</span> <span class="va">self</span>.Phi) <span class="op">@</span> <span class="va">self</span>.W2.T) <span class="op">*</span> <span class="va">self</span>.Omega)    <span class="co"># should match shape of W1 (3 x 4)</span></span>
<span id="cb31-167"><a href="#cb31-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-168"><a href="#cb31-168" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Gradient descent</span></span>
<span id="cb31-169"><a href="#cb31-169" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.C <span class="op">=</span> <span class="va">self</span>.C <span class="op">-</span> (LR<span class="op">*</span><span class="va">self</span>.dL_dC)</span>
<span id="cb31-170"><a href="#cb31-170" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W2 <span class="op">=</span> <span class="va">self</span>.W2 <span class="op">-</span> (LR<span class="op">*</span><span class="va">self</span>.dL_dW2)</span>
<span id="cb31-171"><a href="#cb31-171" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.B <span class="op">=</span> <span class="va">self</span>.B <span class="op">-</span> (LR<span class="op">*</span><span class="va">self</span>.dL_dB)</span>
<span id="cb31-172"><a href="#cb31-172" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W1 <span class="op">=</span> <span class="va">self</span>.W1 <span class="op">-</span> (LR<span class="op">*</span><span class="va">self</span>.dL_W1)</span>
<span id="cb31-173"><a href="#cb31-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-174"><a href="#cb31-174" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-175"><a href="#cb31-175" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of X cols (should be # of W1 rows):", self.X.shape[1])</span></span>
<span id="cb31-176"><a href="#cb31-176" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("# of hidden units (should be # of W1 cols):", hidden_units)</span></span>
<span id="cb31-177"><a href="#cb31-177" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated W1 has shape:"</span>, <span class="va">self</span>.W1.shape)</span>
<span id="cb31-178"><a href="#cb31-178" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated W1 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W1)</span>
<span id="cb31-179"><a href="#cb31-179" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of updated B:"</span>, <span class="va">self</span>.B.shape)</span>
<span id="cb31-180"><a href="#cb31-180" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated B (bias vector for Z1): </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.B)</span>
<span id="cb31-181"><a href="#cb31-181" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of updated W2:"</span>,<span class="va">self</span>.W2.shape)</span>
<span id="cb31-182"><a href="#cb31-182" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated W2 matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.W2)</span>
<span id="cb31-183"><a href="#cb31-183" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of updated  C :"</span>, <span class="va">self</span>.C.shape)</span>
<span id="cb31-184"><a href="#cb31-184" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Updated C (bias vector for Z2): </span><span class="ch">\n</span><span class="st">"</span>,<span class="va">self</span>.C)</span>
<span id="cb31-185"><a href="#cb31-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-186"><a href="#cb31-186" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualizations (confusion matrix &amp; Lce plot)==================</span></span>
<span id="cb31-187"><a href="#cb31-187" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Confusion matrix-------------------------------------------------------------</span></span>
<span id="cb31-188"><a href="#cb31-188" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ConfusionMatrix(<span class="va">self</span>, y_hat,y):</span>
<span id="cb31-189"><a href="#cb31-189" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prediction <span class="op">=</span> y_hat</span>
<span id="cb31-190"><a href="#cb31-190" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prediction[y_hat <span class="op">&gt;=</span> <span class="fl">.5</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb31-191"><a href="#cb31-191" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prediction[y_hat <span class="op">&lt;</span> <span class="fl">.5</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-192"><a href="#cb31-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-193"><a href="#cb31-193" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> y</span>
<span id="cb31-194"><a href="#cb31-194" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-195"><a href="#cb31-195" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-196"><a href="#cb31-196" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cm <span class="op">=</span> confusion_matrix(<span class="va">self</span>.labels, <span class="va">self</span>.prediction)</span>
<span id="cb31-197"><a href="#cb31-197" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="va">self</span>.cm)</span>
<span id="cb31-198"><a href="#cb31-198" aria-hidden="true" tabindex="-1"></a>        plt.figure()</span>
<span id="cb31-199"><a href="#cb31-199" aria-hidden="true" tabindex="-1"></a>        ax<span class="op">=</span> plt.subplot()</span>
<span id="cb31-200"><a href="#cb31-200" aria-hidden="true" tabindex="-1"></a>        sns.heatmap(<span class="va">self</span>.cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'g'</span>, ax<span class="op">=</span>ax, cmap<span class="op">=</span><span class="st">'Blues'</span>)  </span>
<span id="cb31-201"><a href="#cb31-201" aria-hidden="true" tabindex="-1"></a>        <span class="co">#annot=True to annotate cells, ftm='g' to disable scientific notation</span></span>
<span id="cb31-202"><a href="#cb31-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-203"><a href="#cb31-203" aria-hidden="true" tabindex="-1"></a>        <span class="co"># labels, title and ticks</span></span>
<span id="cb31-204"><a href="#cb31-204" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">"Predicted labels"</span>)</span>
<span id="cb31-205"><a href="#cb31-205" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">"True labels"</span>)</span>
<span id="cb31-206"><a href="#cb31-206" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="st">"Confusion Matrix"</span>)</span>
<span id="cb31-207"><a href="#cb31-207" aria-hidden="true" tabindex="-1"></a>        ax.xaxis.set_ticklabels([<span class="st">"0"</span>, <span class="st">"1"</span>])</span>
<span id="cb31-208"><a href="#cb31-208" aria-hidden="true" tabindex="-1"></a>        ax.yaxis.set_ticklabels([<span class="st">"0"</span>, <span class="st">"1"</span>])</span>
<span id="cb31-209"><a href="#cb31-209" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-210"><a href="#cb31-210" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot of Lce vs. Epochs--------------------------------------------------------</span></span>
<span id="cb31-211"><a href="#cb31-211" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_LCE(<span class="va">self</span>):</span>
<span id="cb31-212"><a href="#cb31-212" aria-hidden="true" tabindex="-1"></a>        plt.figure()</span>
<span id="cb31-213"><a href="#cb31-213" aria-hidden="true" tabindex="-1"></a>        plt.plot(np.arange(<span class="dv">0</span>,<span class="bu">len</span>(<span class="va">self</span>.loss_record)),<span class="va">self</span>.loss_record,<span class="st">'-'</span>,label<span class="op">=</span><span class="st">"LR = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="va">self</span>.LR))</span>
<span id="cb31-214"><a href="#cb31-214" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">"epochs"</span>)</span>
<span id="cb31-215"><a href="#cb31-215" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb31-216"><a href="#cb31-216" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">"Loss over epochs"</span>)</span>
<span id="cb31-217"><a href="#cb31-217" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb31-218"><a href="#cb31-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-219"><a href="#cb31-219" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run multiple iterations (with specified epochs, etc.)========================================================</span></span>
<span id="cb31-220"><a href="#cb31-220" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run_model(<span class="va">self</span>, </span>
<span id="cb31-221"><a href="#cb31-221" aria-hidden="true" tabindex="-1"></a>                  epochs,</span>
<span id="cb31-222"><a href="#cb31-222" aria-hidden="true" tabindex="-1"></a>                  LR<span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb31-223"><a href="#cb31-223" aria-hidden="true" tabindex="-1"></a>                  hidden_units<span class="op">=</span> <span class="dv">4</span>,</span>
<span id="cb31-224"><a href="#cb31-224" aria-hidden="true" tabindex="-1"></a>                  randomize_parameters <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb31-225"><a href="#cb31-225" aria-hidden="true" tabindex="-1"></a>                  activation <span class="op">=</span> <span class="st">"sigmoid"</span>, </span>
<span id="cb31-226"><a href="#cb31-226" aria-hidden="true" tabindex="-1"></a>                  verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb31-227"><a href="#cb31-227" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-228"><a href="#cb31-228" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save LCE values (for plotting)------------------------------------</span></span>
<span id="cb31-229"><a href="#cb31-229" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_record <span class="op">=</span> []</span>
<span id="cb31-230"><a href="#cb31-230" aria-hidden="true" tabindex="-1"></a>        <span class="co">#-------------------------------------------------------------------</span></span>
<span id="cb31-231"><a href="#cb31-231" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.LR <span class="op">=</span> LR</span>
<span id="cb31-232"><a href="#cb31-232" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Running model for </span><span class="sc">{}</span><span class="st"> epochs..."</span>.<span class="bu">format</span>(epochs))</span>
<span id="cb31-233"><a href="#cb31-233" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb31-234"><a href="#cb31-234" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Epoch"</span>,i)</span>
<span id="cb31-235"><a href="#cb31-235" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.FeedForward(activation<span class="op">=</span> activation,</span>
<span id="cb31-236"><a href="#cb31-236" aria-hidden="true" tabindex="-1"></a>                             verbose<span class="op">=</span>verbose)</span>
<span id="cb31-237"><a href="#cb31-237" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-238"><a href="#cb31-238" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> verbose:</span>
<span id="cb31-239"><a href="#cb31-239" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">"MSE Loss:"</span>,<span class="va">self</span>.MSE_loss(y_hat<span class="op">=</span><span class="va">self</span>.y_hat,y<span class="op">=</span><span class="va">self</span>.y))</span>
<span id="cb31-240"><a href="#cb31-240" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.loss_record.append(<span class="va">self</span>.MSE_loss(y_hat<span class="op">=</span><span class="va">self</span>.y_hat,</span>
<span id="cb31-241"><a href="#cb31-241" aria-hidden="true" tabindex="-1"></a>                                                  y<span class="op">=</span><span class="va">self</span>.y))</span>
<span id="cb31-242"><a href="#cb31-242" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update params with gradient descent---------------------------</span></span>
<span id="cb31-243"><a href="#cb31-243" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.grad_desc(y_hat<span class="op">=</span><span class="va">self</span>.y_hat,</span>
<span id="cb31-244"><a href="#cb31-244" aria-hidden="true" tabindex="-1"></a>                           y<span class="op">=</span><span class="va">self</span>.y,</span>
<span id="cb31-245"><a href="#cb31-245" aria-hidden="true" tabindex="-1"></a>                           LR<span class="op">=</span><span class="va">self</span>.LR,</span>
<span id="cb31-246"><a href="#cb31-246" aria-hidden="true" tabindex="-1"></a>                           verbose<span class="op">=</span>verbose)</span>
<span id="cb31-247"><a href="#cb31-247" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Finished running all epochs"</span>)</span>
<span id="cb31-248"><a href="#cb31-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-249"><a href="#cb31-249" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Visualizations</span></span>
<span id="cb31-250"><a href="#cb31-250" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ConfusionMatrix(y_hat<span class="op">=</span><span class="va">self</span>.y_hat,y<span class="op">=</span><span class="va">self</span>.y)</span>
<span id="cb31-251"><a href="#cb31-251" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.plot_LCE()</span>
<span id="cb31-252"><a href="#cb31-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-253"><a href="#cb31-253" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> test_model(<span class="va">self</span>,</span>
<span id="cb31-254"><a href="#cb31-254" aria-hidden="true" tabindex="-1"></a>                   test_data,</span>
<span id="cb31-255"><a href="#cb31-255" aria-hidden="true" tabindex="-1"></a>                   verbose <span class="op">=</span> <span class="va">True</span>):</span>
<span id="cb31-256"><a href="#cb31-256" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.test_df <span class="op">=</span> pd.read_csv(test_data)</span>
<span id="cb31-257"><a href="#cb31-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-258"><a href="#cb31-258" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"X is now input from test data"</span>)</span>
<span id="cb31-259"><a href="#cb31-259" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.data_scaler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb31-260"><a href="#cb31-260" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X <span class="op">=</span> <span class="va">self</span>.data_scaler.transform(<span class="va">self</span>.test_df.drop(columns<span class="op">=</span><span class="st">"LABEL"</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb31-261"><a href="#cb31-261" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Test input X was normalized using same normalizer as training (</span><span class="sc">{}</span><span class="st">)"</span>.<span class="bu">format</span>(<span class="va">self</span>.data_scaler))</span>
<span id="cb31-262"><a href="#cb31-262" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb31-263"><a href="#cb31-263" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.X <span class="op">=</span> <span class="va">self</span>.test_df.drop(columns<span class="op">=</span><span class="st">"LABEL"</span>,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-264"><a href="#cb31-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-265"><a href="#cb31-265" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> np.array(<span class="va">self</span>.test_df[[<span class="st">'LABEL'</span>]])</span>
<span id="cb31-266"><a href="#cb31-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-267"><a href="#cb31-267" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb31-268"><a href="#cb31-268" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of X:"</span>, <span class="va">self</span>.X.shape)</span>
<span id="cb31-269"><a href="#cb31-269" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"X matrix: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.X)</span>
<span id="cb31-270"><a href="#cb31-270" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Shape of y:"</span>, <span class="va">self</span>.y.shape)</span>
<span id="cb31-271"><a href="#cb31-271" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"y vector: </span><span class="ch">\n</span><span class="st">"</span>, <span class="va">self</span>.y)</span>
<span id="cb31-272"><a href="#cb31-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-273"><a href="#cb31-273" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Testing model with test data"</span>)</span>
<span id="cb31-274"><a href="#cb31-274" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.FeedForward()</span>
<span id="cb31-275"><a href="#cb31-275" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Finished testing model"</span>)</span>
<span id="cb31-276"><a href="#cb31-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-277"><a href="#cb31-277" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ConfusionMatrix(y_hat<span class="op">=</span><span class="va">self</span>.y_hat,</span>
<span id="cb31-278"><a href="#cb31-278" aria-hidden="true" tabindex="-1"></a>                             y<span class="op">=</span><span class="va">self</span>.y)</span>
<span id="cb31-279"><a href="#cb31-279" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>NN <span class="op">=</span> OneLayer_OneOutput()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>NN.run_model(epochs<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X was normalized using StandardScaler()
Shape of X: (6, 3)
X matrix: 
 [[ 0.85698896 -1.28062485 -1.31222665]
 [-0.89126852  0.78086881  0.61237244]
 [-1.09694587  1.15568584  1.22474487]
 [ 1.16550499 -0.53099079 -0.96229954]
 [ 0.95982764 -1.09321633 -0.61237244]
 [-0.9941072   0.96827732  1.04978132]]
Shape of y: (6, 1)
y vector: 
 [[0]
 [1]
 [1]
 [0]
 [0]
 [1]]
Parameters built for simple calculation (not randomized)
W1 has shape: (3, 4)
W1 matrix: 
 [[1 1 1 1]
 [1 1 1 1]
 [1 1 1 1]]
Shape of B: (6, 1)
B (bias vector for Z1): 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]
Shape of W2: (4, 1)
W2 matrix: 
 [[2]
 [2]
 [2]
 [2]]
Shape of C : (6, 1)
C (bias vector for Z2): 
 [[0]
 [0]
 [0]
 [0]
 [0]
 [0]]
Running model for 100 epochs...
Epoch 0
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-1.73586253 -1.73586253 -1.73586253 -1.73586253]
 [ 0.50197272  0.50197272  0.50197272  0.50197272]
 [ 1.28348484  1.28348484  1.28348484  1.28348484]
 [-0.32778534 -0.32778534 -0.32778534 -0.32778534]
 [-0.74576113 -0.74576113 -0.74576113 -0.74576113]
 [ 1.02395145  1.02395145  1.02395145  1.02395145]]
Activation function: sigmoid
H1 matrix: 
 [[0.14983923 0.14983923 0.14983923 0.14983923]
 [0.62292282 0.62292282 0.62292282 0.62292282]
 [0.78304239 0.78304239 0.78304239 0.78304239]
 [0.41877958 0.41877958 0.41877958 0.41877958]
 [0.32174563 0.32174563 0.32174563 0.32174563]
 [0.73574158 0.73574158 0.73574158 0.73574158]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[1.19871386]
 [4.98338253]
 [6.26433911]
 [3.35023665]
 [2.57396504]
 [5.88593262]]
y_hat:
 [[0.76829591]
 [0.99319576]
 [0.99810064]
 [0.96611258]
 [0.9291671 ]
 [0.99722944]]
MSE Loss: 0.39784353521125104
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.92654998 0.92654998 0.92654998 0.92654998]
 [1.08199975 1.08199975 1.08199975 1.08199975]
 [1.07690469 1.07690469 1.07690469 1.07690469]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-1.39382205e-01]
 [ 8.64068130e-05]
 [ 4.89369997e-06]
 [-6.15900104e-02]
 [-1.06762296e-01]
 [ 1.19062030e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.94662182]
 [1.94662182]
 [1.94662182]
 [1.94662182]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.36769968e-01]
 [ 4.59825982e-05]
 [ 3.60070208e-06]
 [-3.16296167e-02]
 [-6.11536891e-02]
 [ 7.65471733e-06]]
Epoch 1
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-2.1441179  -2.1441179  -2.1441179  -2.1441179 ]
 [ 0.67864818  0.67864818  0.67864818  0.67864818]
 [ 1.55301501  1.55301501  1.55301501  1.55301501]
 [-0.59252818 -0.59252818 -0.59252818 -0.59252818]
 [-1.05976057 -1.05976057 -1.05976057 -1.05976057]
 [ 1.25711215  1.25711215  1.25711215  1.25711215]]
Activation function: sigmoid
H1 matrix: 
 [[0.10488216 0.10488216 0.10488216 0.10488216]
 [0.66343692 0.66343692 0.66343692 0.66343692]
 [0.82534877 0.82534877 0.82534877 0.82534877]
 [0.35605498 0.35605498 0.35605498 0.35605498]
 [0.25735521 0.25735521 0.25735521 0.25735521]
 [0.77852858 0.77852858 0.77852858 0.77852858]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[0.67989367]
 [5.16588911]
 [6.42657126]
 [2.74078797]
 [1.94273941]
 [6.06201054]]
y_hat:
 [[0.66371496]
 [0.99432441]
 [0.99838462]
 [0.93939098]
 [0.87465279]
 [0.9976757 ]]
MSE Loss: 0.3480051136197237
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.84126836 0.84126836 0.84126836 0.84126836]
 [1.16836097 1.16836097 1.16836097 1.16836097]
 [1.15726044 1.15726044 1.15726044 1.15726044]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-2.47673660e-01]
 [ 1.42094313e-04]
 [ 7.81782220e-06]
 [-1.57075525e-01]
 [-2.49468133e-01]
 [ 1.91423363e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.8873902]
 [1.8873902]
 [1.8873902]
 [1.8873902]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.84909429e-01]
 [ 7.80120890e-05]
 [ 6.20592434e-06]
 [-8.51143778e-02]
 [-1.57046500e-01]
 [ 1.30445184e-05]]
Epoch 2
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-2.54153604 -2.54153604 -2.54153604 -2.54153604]
 [ 0.87135712  0.87135712  0.87135712  0.87135712]
 [ 1.84478898  1.84478898  1.84478898  1.84478898]
 [-0.91059316 -0.91059316 -0.91059316 -0.91059316]
 [-1.4279412  -1.4279412  -1.4279412  -1.4279412 ]
 [ 1.50987603  1.50987603  1.50987603  1.50987603]]
Activation function: sigmoid
H1 matrix: 
 [[0.07299716 0.07299716 0.07299716 0.07299716]
 [0.70502801 0.70502801 0.70502801 0.70502801]
 [0.86351411 0.86351411 0.86351411 0.86351411]
 [0.28687847 0.28687847 0.28687847 0.28687847]
 [0.19341967 0.19341967 0.19341967 0.19341967]
 [0.81904283 0.81904283 0.81904283 0.81904283]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[0.2661871 ]
 [5.32272981]
 [6.51915845]
 [2.0806921 ]
 [1.30318707]
 [6.18342671]]
y_hat:
 [[0.5661566 ]
 [0.99514428]
 [0.99852726]
 [0.88901234]
 [0.78637087]
 [0.9979409 ]]
MSE Loss: 0.2882142298571802
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.7492272  0.7492272  0.7492272  0.7492272 ]
 [1.2516227  1.2516227  1.2516227  1.2516227 ]
 [1.23698661 1.23698661 1.23698661 1.23698661]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-3.18715611e-01]
 [ 1.78932870e-04]
 [ 9.74485712e-06]
 [-2.92554988e-01]
 [-4.05059414e-01]
 [ 2.38767081e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.82654503]
 [1.82654503]
 [1.82654503]
 [1.82654503]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-4.23970685e-01]
 [ 1.01475642e-04]
 [ 8.37168618e-06]
 [-1.72832691e-01]
 [-2.89150298e-01]
 [ 1.72756669e-05]]
Epoch 3
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-2.90270209 -2.90270209 -2.90270209 -2.90270209]
 [ 1.06726594  1.06726594  1.06726594  1.06726594]
 [ 2.13962369  2.13962369  2.13962369  2.13962369]
 [-1.27427872 -1.27427872 -1.27427872 -1.27427872]
 [-1.81172132 -1.81172132 -1.81172132 -1.81172132]
 [ 1.76569504  1.76569504  1.76569504  1.76569504]]
Activation function: sigmoid
H1 matrix: 
 [[0.05202015 0.05202015 0.05202015 0.05202015]
 [0.74407663 0.74407663 0.74407663 0.74407663]
 [0.89469516 0.89469516 0.89469516 0.89469516]
 [0.21852569 0.21852569 0.21852569 0.21852569]
 [0.14043022 0.14043022 0.14043022 0.14043022]
 [0.85392149 0.85392149 0.85392149 0.85392149]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.0439021 ]
 [ 5.43645932]
 [ 6.53681237]
 [ 1.42375533]
 [ 0.73685816]
 [ 6.23892148]]
y_hat:
 [[0.48902624]
 [0.99566401]
 [0.998553  ]
 [0.80592646]
 [0.67630844]
 [0.99805184]]
MSE Loss: 0.22434698598963146
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.66262878 0.66262878 0.66262878 0.66262878]
 [1.32228896 1.32228896 1.32228896 1.32228896]
 [1.30926213 1.30926213 1.30926213 1.30926213]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-3.62743110e-01]
 [ 2.04976880e-04]
 [ 1.11840668e-05]
 [-4.49831813e-01]
 [-5.35632321e-01]
 [ 2.73289054e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.77186995]
 [1.77186995]
 [1.77186995]
 [1.77186995]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-5.46168354e-01]
 [ 1.20194953e-04]
 [ 1.04624755e-05]
 [-2.98886844e-01]
 [-4.37204586e-01]
 [ 2.10635883e-05]]
Epoch 4
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.20628231 -3.20628231 -3.20628231 -3.20628231]
 [ 1.24391505  1.24391505  1.24391505  1.24391505]
 [ 2.40480598  2.40480598  2.40480598  2.40480598]
 [-1.63956027 -1.63956027 -1.63956027 -1.63956027]
 [-2.14692683 -2.14692683 -2.14692683 -2.14692683]
 [ 1.99608463  1.99608463  1.99608463  1.99608463]]
Activation function: sigmoid
H1 matrix: 
 [[0.03892999 0.03892999 0.03892999 0.03892999]
 [0.77624475 0.77624475 0.77624475 0.77624475]
 [0.91719305 0.91719305 0.91719305 0.91719305]
 [0.16252491 0.16252491 0.16252491 0.16252491]
 [0.10461875 0.10461875 0.10461875 0.10461875]
 [0.88038538 0.88038538 0.88038538 0.88038538]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.27025282]
 [ 5.50173919]
 [ 6.50059769]
 [ 0.85300514]
 [ 0.30427868]
 [ 6.23973465]]
y_hat:
 [[0.43284503]
 [0.99593691]
 [0.99849971]
 [0.70119716]
 [0.57548814]
 [0.99805342]]
MSE Loss: 0.1683735708546026
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.59289305 0.59289305 0.59289305 0.59289305]
 [1.37563926 1.37563926 1.37563926 1.37563926]
 [1.36689555 1.36689555 1.36689555 1.36689555]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-3.90920306e-01]
 [ 2.25216822e-04]
 [ 1.23938729e-05]
 [-5.91557534e-01]
 [-6.28973211e-01]
 [ 3.01514814e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.72916553]
 [1.72916553]
 [1.72916553]
 [1.72916553]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-6.52427571e-01]
 [ 1.36636608e-04]
 [ 1.27099585e-05]
 [-4.45801465e-01]
 [-5.77797226e-01]
 [ 2.48453723e-05]]
Epoch 5
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.43817209 -3.43817209 -3.43817209 -3.43817209]
 [ 1.38304125  1.38304125  1.38304125  1.38304125]
 [ 2.61354593  2.61354593  2.61354593  2.61354593]
 [-1.94635247 -1.94635247 -1.94635247 -1.94635247]
 [-2.40081854 -2.40081854 -2.40081854 -2.40081854]
 [ 2.17757262  2.17757262  2.17757262  2.17757262]]
Activation function: sigmoid
H1 matrix: 
 [[0.03112356 0.03112356 0.03112356 0.03112356]
 [0.79947899 0.79947899 0.79947899 0.79947899]
 [0.9317283  0.9317283  0.9317283  0.9317283 ]
 [0.12495163 0.12495163 0.12495163 0.12495163]
 [0.0831103  0.0831103  0.0831103  0.0831103 ]
 [0.89821737 0.89821737 0.89821737 0.89821737]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-4.37156440e-01]
 [ 5.52986271e+00]
 [ 6.44446254e+00]
 [ 4.18446736e-01]
 [-2.95136213e-03]
 [ 6.21269088e+00]]
y_hat:
 [[0.39241874]
 [0.99604914]
 [0.99841322]
 [0.60311151]
 [0.49926216]
 [0.99800017]]
MSE Loss: 0.12783679832357212
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.54110962 0.54110962 0.54110962 0.54110962]
 [1.41436405 1.41436405 1.41436405 1.41436405]
 [1.40963794 1.40963794 1.40963794 1.40963794]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.10434834e-01]
 [ 2.42456457e-04]
 [ 1.34999070e-05]
 [-7.00735320e-01]
 [-6.94759625e-01]
 [ 3.26753620e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.69785972]
 [1.69785972]
 [1.69785972]
 [1.69785972]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-7.45990508e-01]
 [ 1.52184251e-04]
 [ 1.52238234e-05]
 [-5.90167071e-01]
 [-7.02612494e-01]
 [ 2.88366975e-05]]
Epoch 6
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.60774407 -3.60774407 -3.60774407 -3.60774407]
 [ 1.48562467  1.48562467  1.48562467  1.48562467]
 [ 2.76745287  2.76745287  2.76745287  2.76745287]
 [-2.17757758 -2.17757758 -2.17757758 -2.17757758]
 [-2.58481695 -2.58481695 -2.58481695 -2.58481695]
 [ 2.31141991  2.31141991  2.31141991  2.31141991]]
Activation function: sigmoid
H1 matrix: 
 [[0.02639724 0.02639724 0.02639724 0.02639724]
 [0.81542065 0.81542065 0.81542065 0.81542065]
 [0.94089149 0.94089149 0.94089149 0.94089149]
 [0.10178218 0.10178218 0.10178218 0.10178218]
 [0.07012199 0.07012199 0.07012199 0.07012199]
 [0.90981843 0.90981843 0.90981843 0.90981843]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.56671529]
 [ 5.5380317 ]
 [ 6.39002226]
 [ 0.10108037]
 [-0.22638328]
 [ 6.17900507]]
y_hat:
 [[0.3619951 ]
 [0.99608115]
 [0.99832459]
 [0.5252486 ]
 [0.44364466]
 [0.9979318 ]]
MSE Loss: 0.10062826096627976
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.50264752 0.50264752 0.50264752 0.50264752]
 [1.44308817 1.44308817 1.44308817 1.44308817]
 [1.44141634 1.44141634 1.44141634 1.44141634]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.25027392e-01]
 [ 2.58092886e-04]
 [ 1.45583412e-05]
 [-7.82057922e-01]
 [-7.43251032e-01]
 [ 3.50539614e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.67466212]
 [1.67466212]
 [1.67466212]
 [1.67466212]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-8.29594959e-01]
 [ 1.67481416e-04]
 [ 1.80261097e-05]
 [-7.21144379e-01]
 [-8.12114676e-01]
 [ 3.31053124e-05]]
Epoch 7
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.73378352 -3.73378352 -3.73378352 -3.73378352]
 [ 1.56181036  1.56181036  1.56181036  1.56181036]
 [ 2.88176127  2.88176127  2.88176127  2.88176127]
 [-2.34956054 -2.34956054 -2.34956054 -2.34956054]
 [-2.72108724 -2.72108724 -2.72108724 -2.72108724]
 [ 2.41083103  2.41083103  2.41083103  2.41083103]]
Activation function: sigmoid
H1 matrix: 
 [[0.02334425 0.02334425 0.02334425 0.02334425]
 [0.82661297 0.82661297 0.82661297 0.82661297]
 [0.94693743 0.94693743 0.94693743 0.94693743]
 [0.08710071 0.08710071 0.08710071 0.08710071]
 [0.06174045 0.06174045 0.06174045 0.06174045]
 [0.9176495  0.9176495  0.9176495  0.9176495 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.67322003]
 [ 5.53735723]
 [ 6.34321902]
 [-0.13768735]
 [-0.39853708]
 [ 6.14704457]]
y_hat:
 [[0.3377762 ]
 [0.99607852]
 [0.99824446]
 [0.46563244]
 [0.40166387]
 [0.99786477]]
MSE Loss: 0.08204386930698401
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.47320179 0.47320179 0.47320179 0.47320179]
 [1.46521569 1.46521569 1.46521569 1.46521569]
 [1.4657856  1.4657856  1.4657856  1.4657856 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.36566481e-01]
 [ 2.72799048e-04]
 [ 1.55938586e-05]
 [-8.43768312e-01]
 [-7.80709566e-01]
 [ 3.73569419e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.65686685]
 [1.65686685]
 [1.65686685]
 [1.65686685]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-9.05149900e-01]
 [ 1.82799109e-04]
 [ 2.11026363e-05]
 [-8.37002517e-01]
 [-9.08646557e-01]
 [ 3.76547740e-05]]
Epoch 8
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.83087231 -3.83087231 -3.83087231 -3.83087231]
 [ 1.62027087  1.62027087  1.62027087  1.62027087]
 [ 2.96948126  2.96948126  2.96948126  2.96948126]
 [-2.48079011 -2.48079011 -2.48079011 -2.48079011]
 [-2.82592183 -2.82592183 -2.82592183 -2.82592183]
 [ 2.48711352  2.48711352  2.48711352  2.48711352]]
Activation function: sigmoid
H1 matrix: 
 [[0.02123019 0.02123019 0.02123019 0.02123019]
 [0.83483248 0.83483248 0.83483248 0.83483248]
 [0.95117619 0.95117619 0.95117619 0.95117619]
 [0.07721588 0.07721588 0.07721588 0.07721588]
 [0.05593938 0.05593938 0.05593938 0.05593938]
 [0.92323348 0.92323348 0.92323348 0.92323348]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.76444751]
 [ 5.53300786]
 [ 6.30391031]
 [-0.32525676]
 [-0.53791016]
 [ 6.11873743]]
y_hat:
 [[0.31768144]
 [0.9960615 ]
 [0.9981742 ]
 [0.41939517]
 [0.36867387]
 [0.9978036 ]]
MSE Loss: 0.06879298318630903
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.44990743 0.44990743 0.44990743 0.44990743]
 [1.48286551 1.48286551 1.48286551 1.48286551]
 [1.48509956 1.48509956 1.48509956 1.48509956]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.46049637e-01]
 [ 2.86918586e-04]
 [ 1.66179821e-05]
 [-8.91994381e-01]
 [-8.10742902e-01]
 [ 3.96179307e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.64273968]
 [1.64273968]
 [1.64273968]
 [1.64273968]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-9.74010511e-01]
 [ 1.98249835e-04]
 [ 2.44300906e-05]
 [-9.39126442e-01]
 [-9.94456670e-01]
 [ 4.24683451e-05]]
Epoch 9
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.90826558 -3.90826558 -3.90826558 -3.90826558]
 [ 1.66665606  1.66665606  1.66665606  1.66665606]
 [ 3.03908727  3.03908727  3.03908727  3.03908727]
 [-2.58412359 -2.58412359 -2.58412359 -2.58412359]
 [-2.90943615 -2.90943615 -2.90943615 -2.90943615]
 [ 2.54763823  2.54763823  2.54763823  2.54763823]]
Activation function: sigmoid
H1 matrix: 
 [[0.0196802  0.0196802  0.0196802  0.0196802 ]
 [0.84112948 0.84112948 0.84112948 0.84112948]
 [0.95430905 0.95430905 0.95430905 0.95430905]
 [0.07016721 0.07016721 0.07016721 0.07016721]
 [0.05168907 0.05168907 0.05168907 0.05168907]
 [0.92741469 0.92741469 0.92741469 0.92741469]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.8446927 ]
 [ 5.52722532]
 [ 6.27074979]
 [-0.47806057]
 [-0.65480995]
 [ 6.09404611]]
y_hat:
 [[0.30054737]
 [0.99603875]
 [0.99811276]
 [0.3827102 ]
 [0.34190645]
 [0.99774882]]
MSE Loss: 0.05895335927068402
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.43094757 0.43094757 0.43094757 0.43094757]
 [1.49735095 1.49735095 1.49735095 1.49735095]
 [1.50084859 1.50084859 1.50084859 1.50084859]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.54059227e-01]
 [ 3.00642459e-04]
 [ 1.76365330e-05]
 [-9.30755562e-01]
 [-8.35521710e-01]
 [ 4.18545595e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.631197]
 [1.631197]
 [1.631197]
 [1.631197]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.03719117e+00]
 [ 2.13879216e-04]
 [ 2.79850510e-05]
 [-1.02953909e+00]
 [-1.07138782e+00]
 [ 4.75247574e-05]]
Epoch 10
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-3.97174027 -3.97174027 -3.97174027 -3.97174027]
 [ 1.70452361  1.70452361  1.70452361  1.70452361]
 [ 3.09591539  3.09591539  3.09591539  3.09591539]
 [-2.6678295  -2.6678295  -2.6678295  -2.6678295 ]
 [-2.97789315 -2.97789315 -2.97789315 -2.97789315]
 [ 2.59704757  2.59704757  2.59704757  2.59704757]]
Activation function: sigmoid
H1 matrix: 
 [[0.01849221 0.01849221 0.01849221 0.01849221]
 [0.84612462 0.84612462 0.84612462 0.84612462]
 [0.95672394 0.95672394 0.95672394 0.95672394]
 [0.06489856 0.06489856 0.06489856 0.06489856]
 [0.04843464 0.04843464 0.04843464 0.04843464]
 [0.93067132 0.93067132 0.93067132 0.93067132]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.91653341]
 [ 5.52099764]
 [ 6.24244889]
 [-0.60608971]
 [-0.75536207]
 [ 6.0724806 ]]
y_hat:
 [[0.28566476]
 [0.9960141 ]
 [0.99805869]
 [0.3529517 ]
 [0.31965406]
 [0.99769986]]
MSE Loss: 0.05139715390786421
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.41514842 0.41514842 0.41514842 0.41514842]
 [1.50951498 1.50951498 1.50951498 1.50951498]
 [1.5139952  1.5139952  1.5139952  1.5139952 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.60962649e-01]
 [ 3.14085227e-04]
 [ 1.86526571e-05]
 [-9.62672960e-01]
 [-8.56426766e-01]
 [ 4.40767728e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.6215427]
 [1.6215427]
 [1.6215427]
 [1.6215427]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.09548404e+00]
 [ 2.29703309e-04]
 [ 3.17464208e-05]
 [-1.11014507e+00]
 [-1.14090469e+00]
 [ 5.28032521e-05]]
Epoch 11
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.02501228 -4.02501228 -4.02501228 -4.02501228]
 [ 1.73616747  1.73616747  1.73616747  1.73616747]
 [ 3.14340626  3.14340626  3.14340626  3.14340626]
 [-2.73727085 -2.73727085 -2.73727085 -2.73727085]
 [-3.0353112  -3.0353112  -3.0353112  -3.0353112 ]
 [ 2.63833505  2.63833505  2.63833505  2.63833505]]
Activation function: sigmoid
H1 matrix: 
 [[0.01754971 0.01754971 0.01754971 0.01754971]
 [0.85019961 0.85019961 0.85019961 0.85019961]
 [0.95864812 0.95864812 0.95864812 0.95864812]
 [0.06080958 0.06080958 0.06080958 0.06080958]
 [0.04585588 0.04585588 0.04585588 0.04585588]
 [0.93328838 0.93328838 0.93328838 0.93328838]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-0.98165362]
 [ 5.51476956]
 [ 6.21798719]
 [-0.71572373]
 [-0.8434756 ]
 [ 6.05352061]]
y_hat:
 [[0.27256379]
 [0.9959893 ]
 [0.99801071]
 [0.32833534]
 [0.30080329]
 [0.99765593]]
MSE Loss: 0.04543387894780479
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.40172612 0.40172612 0.40172612 0.40172612]
 [1.51992087 1.51992087 1.51992087 1.51992087]
 [1.52518228 1.52518228 1.52518228 1.52518228]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.67006311e-01]
 [ 3.27320054e-04]
 [ 1.96681419e-05]
 [-9.89495619e-01]
 [-8.74380796e-01]
 [ 4.62905143e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.61331261]
 [1.61331261]
 [1.61331261]
 [1.61331261]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.14952602e+00]
 [ 2.45724546e-04]
 [ 3.56958156e-05]
 [-1.18255327e+00]
 [-1.20416984e+00]
 [ 5.82850267e-05]]
Epoch 12
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.07056472 -4.07056472 -4.07056472 -4.07056472]
 [ 1.76311986  1.76311986  1.76311986  1.76311986]
 [ 3.18385805  3.18385805  3.18385805  3.18385805]
 [-2.79602801 -2.79602801 -2.79602801 -2.79602801]
 [-3.08437487 -3.08437487 -3.08437487 -3.08437487]
 [ 2.67350024  2.67350024  2.67350024  2.67350024]]
Activation function: sigmoid
H1 matrix: 
 [[0.01678133 0.01678133 0.01678133 0.01678133]
 [0.85359997 0.85359997 0.85359997 0.85359997]
 [0.96022229 0.96022229 0.96022229 0.96022229]
 [0.05753919 0.05753919 0.05753919 0.05753919]
 [0.0437564  0.0437564  0.0437564  0.0437564 ]
 [0.93544473 0.93544473 0.93544473 0.93544473]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.04123191]
 [ 5.5087401 ]
 [ 6.19659059]
 [-0.81123845]
 [-0.92179885]
 [ 6.03671736]]
y_hat:
 [[0.26091237]
 [0.99596514]
 [0.99796778]
 [0.30762665]
 [0.28459151]
 [0.99761631]]
MSE Loss: 0.04062130641243275
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.39013929 0.39013929 0.39013929 0.39013929]
 [1.52895918 1.52895918 1.52895918 1.52895918]
 [1.5348541  1.5348541  1.5348541  1.5348541 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.72363540e-01]
 [ 3.40396076e-04]
 [ 2.06840383e-05]
 [-1.01242508e+00]
 [-8.90026193e-01]
 [ 4.84995001e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.60618593]
 [1.60618593]
 [1.60618593]
 [1.60618593]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.19983960e+00]
 [ 2.61938971e-04]
 [ 3.98173541e-05]
 [-1.24807544e+00]
 [-1.26211244e+00]
 [ 6.39534795e-05]]
Epoch 13
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.11011805 -4.11011805 -4.11011805 -4.11011805]
 [ 1.78644041  1.78644041  1.78644041  1.78644041]
 [ 3.21886017  3.21886017  3.21886017  3.21886017]
 [-2.84656844 -2.84656844 -2.84656844 -2.84656844]
 [-3.12694522 -3.12694522 -3.12694522 -3.12694522]
 [ 2.70392589  2.70392589  2.70392589  2.70392589]]
Activation function: sigmoid
H1 matrix: 
 [[0.01614103 0.01614103 0.01614103 0.01614103]
 [0.85649031 0.85649031 0.85649031 0.85649031]
 [0.96153788 0.96153788 0.96153788 0.96153788]
 [0.05485897 0.05485897 0.05485897 0.05485897]
 [0.04200937 0.04200937 0.04200937 0.04200937]
 [0.9372579  0.9372579  0.9372579  0.9372579 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.09613762]
 [ 5.50299264]
 [ 6.17767428]
 [-0.89562061]
 [-0.99221298]
 [ 6.02170578]]
y_hat:
 [[0.25046429]
 [0.99594198]
 [0.99792905]
 [0.28995129]
 [0.27047519]
 [0.99758034]]
MSE Loss: 0.03666459231007466
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.38000232 0.38000232 0.38000232 0.38000232]
 [1.53690963 1.53690963 1.53690963 1.53690963]
 [1.54332734 1.54332734 1.54332734 1.54332734]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.77160917e-01]
 [ 3.53347661e-04]
 [ 2.17009768e-05]
 [-1.03231066e+00]
 [-9.03825530e-01]
 [ 5.07061345e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.59993377]
 [1.59993377]
 [1.59993377]
 [1.59993377]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.24685975e+00]
 [ 2.78339711e-04]
 [ 4.40973100e-05]
 [-1.30777048e+00]
 [-1.31548216e+00]
 [ 6.97940660e-05]]
Epoch 14
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.14490305 -4.14490305 -4.14490305 -4.14490305]
 [ 1.80688516  1.80688516  1.80688516  1.80688516]
 [ 3.24954667  3.24954667  3.24954667  3.24954667]
 [-2.89064412 -2.89064412 -2.89064412 -2.89064412]
 [-3.16435464 -3.16435464 -3.16435464 -3.16435464]
 [ 2.73059862  2.73059862  2.73059862  2.73059862]]
Activation function: sigmoid
H1 matrix: 
 [[0.01559782 0.01559782 0.01559782 0.01559782]
 [0.858985   0.858985   0.858985   0.858985  ]
 [0.96265682 0.96265682 0.96265682 0.96265682]
 [0.052618   0.052618   0.052618   0.052618  ]
 [0.04052938 0.04052938 0.04052938 0.04052938]
 [0.93880824 0.93880824 0.93880824 0.93880824]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.1470378 ]
 [ 5.49755476]
 [ 6.16079273]
 [-0.97102921]
 [-1.05610489]
 [ 6.0081938 ]]
y_hat:
 [[0.24103056]
 [0.99591994]
 [0.99789387]
 [0.27467541]
 [0.25805452]
 [0.9975475 ]]
MSE Loss: 0.033360256680588056
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.37103303 0.37103303 0.37103303 0.37103303]
 [1.54397814 1.54397814 1.54397814 1.54397814]
 [1.55083396 1.55083396 1.55083396 1.55083396]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.81493702e-01]
 [ 3.66199663e-04]
 [ 2.27193367e-05]
 [-1.04976862e+00]
 [-9.16121380e-01]
 [ 5.29120141e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.59438826]
 [1.59438826]
 [1.59438826]
 [1.59438826]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.29095263e+00]
 [ 2.94918694e-04]
 [ 4.85237694e-05]
 [-1.36249373e+00]
 [-1.36488990e+00]
 [ 7.57940478e-05]]
Epoch 15
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.17582491 -4.17582491 -4.17582491 -4.17582491]
 [ 1.82500848  1.82500848  1.82500848  1.82500848]
 [ 3.27674918  3.27674918  3.27674918  3.27674918]
 [-2.92953275 -2.92953275 -2.92953275 -2.92953275]
 [-3.19758371 -3.19758371 -3.19758371 -3.19758371]
 [ 2.75424184  2.75424184  2.75424184  2.75424184]]
Activation function: sigmoid
H1 matrix: 
 [[0.01513008 0.01513008 0.01513008 0.01513008]
 [0.86116602 0.86116602 0.86116602 0.86116602]
 [0.9636225  0.9636225  0.9636225  0.9636225 ]
 [0.05071281 0.05071281 0.05071281 0.05071281]
 [0.03925675 0.03925675 0.03925675 0.03925675]
 [0.94015247 0.94015247 0.94015247 0.94015247]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.19445976]
 [ 5.4924269 ]
 [ 6.14560214]
 [-1.03907007]
 [-1.11452787]
 [ 5.99594802]]
y_hat:
 [[0.23246226]
 [0.99589905]
 [0.9978617 ]
 [0.26132946]
 [0.24702772]
 [0.99751736]]
MSE Loss: 0.030563673053310817
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.36301998 0.36301998 0.36301998 0.36301998]
 [1.55032001 1.55032001 1.55032001 1.55032001]
 [1.55754793 1.55754793 1.55754793 1.55754793]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.85435358e-01]
 [ 3.78970557e-04]
 [ 2.37393427e-05]
 [-1.06525668e+00]
 [-9.27173514e-01]
 [ 5.51182184e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.58942327]
 [1.58942327]
 [1.58942327]
 [1.58942327]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.33242937e+00]
 [ 3.11667527e-04]
 [ 5.30863323e-05]
 [-1.41293983e+00]
 [-1.41083829e+00]
 [ 8.19422354e-05]]
Epoch 16
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.20356547 -4.20356547 -4.20356547 -4.20356547]
 [ 1.84122665  1.84122665  1.84122665  1.84122665]
 [ 3.30109219  3.30109219  3.30109219  3.30109219]
 [-2.96418839 -2.96418839 -2.96418839 -2.96418839]
 [-3.22737148 -3.22737148 -3.22737148 -3.22737148]
 [ 2.77539877  2.77539877  2.77539877  2.77539877]]
Activation function: sigmoid
H1 matrix: 
 [[0.01472222 0.01472222 0.01472222 0.01472222]
 [0.86309372 0.86309372 0.86309372 0.86309372]
 [0.96446626 0.96446626 0.96446626 0.96446626]
 [0.0490702  0.0490702  0.0490702  0.0490702 ]
 [0.03814858 0.03814858 0.03814858 0.03814858]
 [0.94133185 0.94133185 0.94133185 0.94133185]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.23883   ]
 [ 5.48759661]
 [ 6.13183355]
 [-1.10096658]
 [-1.16830134]
 [ 5.98478093]]
y_hat:
 [[0.22463971]
 [0.99587927]
 [0.99783212]
 [0.24955883]
 [0.23716216]
 [0.99748955]]
MSE Loss: 0.02816941368616957
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.3558014  0.3558014  0.3558014  0.3558014 ]
 [1.55605475 1.55605475 1.55605475 1.55605475]
 [1.56360252 1.56360252 1.56360252 1.56360252]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.89043705e-01]
 [ 3.91674400e-04]
 [ 2.47611218e-05]
 [-1.07912195e+00]
 [-9.37182935e-01]
 [ 5.73254866e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.58494204]
 [1.58494204]
 [1.58494204]
 [1.58494204]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.37155638e+00]
 [ 3.28577941e-04]
 [ 5.77758642e-05]
 [-1.45967701e+00]
 [-1.45374479e+00]
 [ 8.82287568e-05]]
Epoch 17
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.2286491  -4.2286491  -4.2286491  -4.2286491 ]
 [ 1.85585879  1.85585879  1.85585879  1.85585879]
 [ 3.32305449  3.32305449  3.32305449  3.32305449]
 [-2.99533837 -2.99533837 -2.99533837 -2.99533837]
 [-3.25428647 -3.25428647 -3.25428647 -3.25428647]
 [ 2.79448584  2.79448584  2.79448584  2.79448584]]
Activation function: sigmoid
H1 matrix: 
 [[0.01436277 0.01436277 0.01436277 0.01436277]
 [0.86481353 0.86481353 0.86481353 0.86481353]
 [0.9652113  0.9652113  0.9652113  0.9652113 ]
 [0.04763691 0.04763691 0.04763691 0.04763691]
 [0.03717316 0.03717316 0.03717316 0.03717316]
 [0.94237712 0.94237712 0.94237712 0.94237712]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.28049976]
 [ 5.48304584]
 [ 6.11927367]
 [-1.15767001]
 [-1.21807554]
 [ 5.9745407 ]]
y_hat:
 [[0.21746516]
 [0.99586056]
 [0.99780478]
 [0.23909091]
 [0.2282753 ]
 [0.99746378]]
MSE Loss: 0.026098926718038526
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.34925128 0.34925128 0.34925128 0.34925128]
 [1.56127604 1.56127604 1.56127604 1.56127604]
 [1.56910164 1.56910164 1.56910164 1.56910164]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.92365032e-01]
 [ 4.04322101e-04]
 [ 2.57847379e-05]
 [-1.09163256e+00]
 [-9.46307902e-01]
 [ 5.95343270e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.58086901]
 [1.58086901]
 [1.58086901]
 [1.58086901]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.40856331e+00]
 [ 3.45642006e-04]
 [ 6.25842926e-05]
 [-1.50317397e+00]
 [-1.49395906e+00]
 [ 9.46448591e-05]]
Epoch 18
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.25148642 -4.25148642 -4.25148642 -4.25148642]
 [ 1.86915401  1.86915401  1.86915401  1.86915401]
 [ 3.34300984  3.34300984  3.34300984  3.34300984]
 [-3.02354744 -3.02354744 -3.02354744 -3.02354744]
 [-3.27877394 -3.27877394 -3.27877394 -3.27877394]
 [ 2.8118281   2.8118281   2.8118281   2.8118281 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.01404303 0.01404303 0.01404303 0.01404303]
 [0.86636036 0.86636036 0.86636036 0.86636036]
 [0.96587519 0.96587519 0.96587519 0.96587519]
 [0.04637334 0.04637334 0.04637334 0.04637334]
 [0.03630659 0.03630659 0.03630659 0.03630659]
 [0.94331166 0.94331166 0.94331166 0.94331166]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.31976254]
 [ 5.47875462]
 [ 6.10775119]
 [-1.20993324]
 [-1.26437521]
 [ 5.96510331]]
y_hat:
 [[0.2108578 ]
 [0.99584283]
 [0.99777939]
 [0.22971286]
 [0.22022164]
 [0.99743979]]
MSE Loss: 0.024292558868619734
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.34326984 0.34326984 0.34326984 0.34326984]
 [1.56605844 1.56605844 1.56605844 1.56605844]
 [1.57412765 1.57412765 1.57412765 1.57412765]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.95436948e-01]
 [ 4.16922269e-04]
 [ 2.68102138e-05]
 [-1.10299904e+00]
 [-9.54674934e-01]
 [ 6.17450892e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.57714419]
 [1.57714419]
 [1.57714419]
 [1.57714419]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.44364937e+00]
 [ 3.62852233e-04]
 [ 6.75044423e-05]
 [-1.54382048e+00]
 [-1.53177642e+00]
 [ 1.01182743e-04]]
Epoch 19
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.27240409 -4.27240409 -4.27240409 -4.27240409]
 [ 1.88130989  1.88130989  1.88130989  1.88130989]
 [ 3.36125471  3.36125471  3.36125471  3.36125471]
 [-3.04926125 -3.04926125 -3.04926125 -3.04926125]
 [-3.3011881  -3.3011881  -3.3011881  -3.3011881 ]
 [ 2.82768341  2.82768341  2.82768341  2.82768341]]
Activation function: sigmoid
H1 matrix: 
 [[0.01375633 0.01375633 0.01375633 0.01375633]
 [0.86776151 0.86776151 0.86776151 0.86776151]
 [0.96647146 0.96647146 0.96647146 0.96647146]
 [0.04524938 0.04524938 0.04524938 0.04524938]
 [0.03553045 0.03553045 0.03553045 0.03553045]
 [0.94415358 0.94415358 0.94415358 0.94415358]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.35686648]
 [ 5.47470297]
 [ 6.0971269 ]
 [-1.25836131]
 [-1.30762983]
 [ 5.95636652]]
y_hat:
 [[0.20475005]
 [0.99582602]
 [0.99775573]
 [0.22125611]
 [0.21288373]
 [0.99741738]]
MSE Loss: 0.022704243790850648
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.33777699 0.33777699 0.33777699 0.33777699]
 [1.57046215 1.57046215 1.57046215 1.57046215]
 [1.57874675 1.57874675 1.57874675 1.57874675]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-4.98290397e-01]
 [ 4.29481802e-04]
 [ 2.78375454e-05]
 [-1.11338912e+00]
 [-9.62386534e-01]
 [ 6.39580104e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5737193]
 [1.5737193]
 [1.5737193]
 [1.5737193]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.47698831e+00]
 [ 3.80201608e-04]
 [ 7.25298991e-05]
 [-1.58194332e+00]
 [-1.56744812e+00]
 [ 1.07835422e-04]]
Epoch 20
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.29166565 -4.29166565 -4.29166565 -4.29166565]
 [ 1.89248538  1.89248538  1.89248538  1.89248538]
 [ 3.37802761  3.37802761  3.37802761  3.37802761]
 [-3.07283657 -3.07283657 -3.07283657 -3.07283657]
 [-3.3218147  -3.3218147  -3.3218147  -3.3218147 ]
 [ 2.84225915  2.84225915  2.84225915  2.84225915]]
Activation function: sigmoid
H1 matrix: 
 [[0.01349744 0.01349744 0.01349744 0.01349744]
 [0.86903865 0.86903865 0.86903865 0.86903865]
 [0.96701074 0.96701074 0.96701074 0.96701074]
 [0.04424173 0.04424173 0.04424173 0.04424173]
 [0.03483035 0.03483035 0.03483035 0.03483035]
 [0.94491717 0.94491717 0.94491717 0.94491717]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.39202356]
 [ 5.4708718 ]
 [ 6.0872864 ]
 [-1.30344706]
 [-1.34819533]
 [ 5.94824536]]
y_hat:
 [[0.1990849 ]
 [0.99581007]
 [0.99773358]
 [0.21358545]
 [0.20616557]
 [0.99739638]]
MSE Loss: 0.021297876315681103
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.33270759 0.33270759 0.33270759 0.33270759]
 [1.57453634 1.57453634 1.57453634 1.57453634]
 [1.58301282 1.58301282 1.58301282 1.58301282]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.00951122e-01]
 [ 4.42006296e-04]
 [ 2.88667106e-05]
 [-1.12293822e+00]
 [-9.69526744e-01]
 [ 6.61732483e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.57055497]
 [1.57055497]
 [1.57055497]
 [1.57055497]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.50873241e+00]
 [ 3.97683590e-04]
 [ 7.76549005e-05]
 [-1.61781856e+00]
 [-1.60118945e+00]
 [ 1.14596611e-04]]
Epoch 21
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.30948636 -4.30948636 -4.30948636 -4.30948636]
 [ 1.90280994  1.90280994  1.90280994  1.90280994]
 [ 3.39352284  3.39352284  3.39352284  3.39352284]
 [-3.09456267 -3.09456267 -3.09456267 -3.09456267]
 [-3.34088707 -3.34088707 -3.34088707 -3.34088707]
 [ 2.85572429  2.85572429  2.85572429  2.85572429]]
Activation function: sigmoid
H1 matrix: 
 [[0.0132622  0.0132622  0.0132622  0.0132622 ]
 [0.87020923 0.87020923 0.87020923 0.87020923]
 [0.96750149 0.96750149 0.96750149 0.96750149]
 [0.0433321  0.0433321  0.0433321  0.0433321 ]
 [0.03419485 0.03419485 0.03419485 0.03419485]
 [0.94561383 0.94561383 0.94561383 0.94561383]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.42541635]
 [ 5.46724336]
 [ 6.07813476]
 [-1.3455968 ]
 [-1.38636989]
 [ 5.94066856]]
y_hat:
 [[0.19381387]
 [0.9957949 ]
 [0.99771279]
 [0.20659117]
 [0.19998792]
 [0.99737663]]
MSE Loss: 0.02004478230001754
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.32800807 0.32800807 0.32800807 0.32800807]
 [1.57832167 1.57832167 1.57832167 1.57832167]
 [1.58697024 1.58697024 1.58697024 1.58697024]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.03440757e-01]
 [ 4.54500341e-04]
 [ 2.98976759e-05]
 [-1.13175692e+00]
 [-9.76165205e-01]
 [ 6.83909027e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.56761875]
 [1.56761875]
 [1.56761875]
 [1.56761875]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.53901584e+00]
 [ 4.15292093e-04]
 [ 8.28742437e-05]
 [-1.65168118e+00]
 [-1.63318607e+00]
 [ 1.21460629e-04]]
Epoch 22
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.32604404 -4.32604404 -4.32604404 -4.32604404]
 [ 1.91239022  1.91239022  1.91239022  1.91239022]
 [ 3.40790045  3.40790045  3.40790045  3.40790045]
 [-3.11467688 -3.11467688 -3.11467688 -3.11467688]
 [-3.35859785 -3.35859785 -3.35859785 -3.35859785]
 [ 2.86821799  2.86821799  2.86821799  2.86821799]]
Activation function: sigmoid
H1 matrix: 
 [[0.01304726 0.01304726 0.01304726 0.01304726]
 [0.87128744 0.87128744 0.87128744 0.87128744]
 [0.96795053 0.96795053 0.96795053 0.96795053]
 [0.04250589 0.04250589 0.04250589 0.04250589]
 [0.03361474 0.03361474 0.03361474 0.03361474]
 [0.94625279 0.94625279 0.94625279 0.94625279]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.45720333]
 [ 5.46380139]
 [ 6.06959249]
 [-1.38514905]
 [-1.42240567]
 [ 5.93357591]]
y_hat:
 [[0.18889544]
 [0.99578046]
 [0.99769322]
 [0.20018331]
 [0.19428473]
 [0.99735801]]
MSE Loss: 0.018921917934217485
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.32363392 0.32363392 0.32363392 0.32363392]
 [1.58185204 1.58185204 1.58185204 1.58185204]
 [1.59065588 1.59065588 1.59065588 1.59065588]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.05777634e-01]
 [ 4.66967745e-04]
 [ 3.09304002e-05]
 [-1.13993652e+00]
 [-9.82360178e-01]
 [ 7.06110318e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.56488362]
 [1.56488362]
 [1.56488362]
 [1.56488362]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.56795726e+00]
 [ 4.33021460e-04]
 [ 8.81832105e-05]
 [-1.68373252e+00]
 [-1.66359904e+00]
 [ 1.28422319e-04]]
Epoch 23
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.341487   -4.341487   -4.341487   -4.341487  ]
 [ 1.92131498  1.92131498  1.92131498  1.92131498]
 [ 3.42129367  3.42129367  3.42129367  3.42129367]
 [-3.13337586 -3.13337586 -3.13337586 -3.13337586]
 [-3.3751077  -3.3751077  -3.3751077  -3.3751077 ]
 [ 2.87985609  2.87985609  2.87985609  2.87985609]]
Activation function: sigmoid
H1 matrix: 
 [[0.01284989 0.01284989 0.01284989 0.01284989]
 [0.872285   0.872285   0.872285   0.872285  ]
 [0.96836343 0.96836343 0.96836343 0.96836343]
 [0.04175134 0.04175134 0.04175134 0.04175134]
 [0.03308253 0.03308253 0.03308253 0.03308253]
 [0.94684162 0.94684162 0.94684162 0.94684162]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.48752294]
 [ 5.46053105]
 [ 6.06159245]
 [-1.4223886 ]
 [-1.45651779]
 [ 5.92691619]]
y_hat:
 [[0.18429381]
 [0.9957667 ]
 [0.99767473]
 [0.1942874 ]
 [0.1890005 ]
 [0.9973404 ]]
MSE Loss: 0.017910565388397092
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.31954782 0.31954782 0.31954782 0.31954782]
 [1.585156   1.585156   1.585156   1.585156  ]
 [1.59410074 1.59410074 1.59410074 1.59410074]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.07977417e-01]
 [ 4.79411692e-04]
 [ 3.19648382e-05]
 [-1.14755310e+00]
 [-9.88160828e-01]
 [ 7.28336627e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.56232688]
 [1.56232688]
 [1.56232688]
 [1.56232688]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.59566208e+00]
 [ 4.50866428e-04]
 [ 9.35775046e-05]
 [-1.71414624e+00]
 [-1.69256891e+00]
 [ 1.35476981e-04]]
Epoch 24
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.3559401  -4.3559401  -4.3559401  -4.3559401 ]
 [ 1.92965873  1.92965873  1.92965873  1.92965873]
 [ 3.43381435  3.43381435  3.43381435  3.43381435]
 [-3.15082417 -3.15082417 -3.15082417 -3.15082417]
 [-3.39055179 -3.39055179 -3.39055179 -3.39055179]
 [ 2.89073584  2.89073584  2.89073584  2.89073584]]
Activation function: sigmoid
H1 matrix: 
 [[0.01266784 0.01266784 0.01266784 0.01266784]
 [0.87321164 0.87321164 0.87321164 0.87321164]
 [0.96874477 0.96874477 0.96874477 0.96874477]
 [0.04105882 0.04105882 0.04105882 0.04105882]
 [0.03259205 0.03259205 0.03259205 0.03259205]
 [0.94738657 0.94738657 0.94738657 0.94738657]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.51649685]
 [ 5.45741893]
 [ 6.05407752]
 [-1.45755707]
 [-1.48889115]
 [ 5.92064549]]
y_hat:
 [[0.17997795]
 [0.99575356]
 [0.99765723]
 [0.18884125]
 [0.18408822]
 [0.99732371]]
MSE Loss: 0.016995372841307792
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.3157182  0.3157182  0.3157182  0.3157182 ]
 [1.5882578  1.5882578  1.5882578  1.5882578 ]
 [1.59733102 1.59733102 1.59733102 1.59733102]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.10053582e-01]
 [ 4.91834865e-04]
 [ 3.30009417e-05]
 [-1.15467064e+00]
 [-9.93608971e-01]
 [ 7.50588000e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.55992927]
 [1.55992927]
 [1.55992927]
 [1.55992927]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.62222428e+00]
 [ 4.68822104e-04]
 [ 9.90531983e-05]
 [-1.74307298e+00]
 [-1.72021891e+00]
 [ 1.42620318e-04]]
Epoch 25
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.3695093  -4.3695093  -4.3695093  -4.3695093 ]
 [ 1.9374846   1.9374846   1.9374846   1.9374846 ]
 [ 3.44555724  3.44555724  3.44555724  3.44555724]
 [-3.16716067 -3.16716067 -3.16716067 -3.16716067]
 [-3.40504477 -3.40504477 -3.40504477 -3.40504477]
 [ 2.9009396   2.9009396   2.9009396   2.9009396 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.01249924 0.01249924 0.01249924 0.01249924]
 [0.87407554 0.87407554 0.87407554 0.87407554]
 [0.96909837 0.96909837 0.96909837 0.96909837]
 [0.0404204  0.0404204  0.0404204  0.0404204 ]
 [0.03213817 0.03213817 0.03213817 0.03213817]
 [0.94789287 0.94789287 0.94789287 0.94789287]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.54423255]
 [ 5.45445291]
 [ 6.04699872]
 [-1.49086112]
 [-1.5196858 ]
 [ 5.91472593]]
y_hat:
 [[0.17592083]
 [0.995741  ]
 [0.99764063]
 [0.18379251]
 [0.17950779]
 [0.99730787]]
MSE Loss: 0.016163637715868016
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.31211817 0.31211817 0.31211817 0.31211817]
 [1.59117815 1.59117815 1.59117815 1.59117815]
 [1.60036907 1.60036907 1.60036907 1.60036907]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.12017799e-01]
 [ 5.04239544e-04]
 [ 3.40386617e-05]
 [-1.16134335e+00]
 [-9.98740426e-01]
 [ 7.72864319e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.55767438]
 [1.55767438]
 [1.55767438]
 [1.55767438]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.64772800e+00]
 [ 4.86883926e-04]
 [ 1.04606689e-04]
 [-1.77064422e+00]
 [-1.74665767e+00]
 [ 1.49848383e-04]]
Epoch 26
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.38228519 -4.38228519 -4.38228519 -4.38228519]
 [ 1.94484644  1.94484644  1.94484644  1.94484644]
 [ 3.45660317  3.45660317  3.45660317  3.45660317]
 [-3.18250344 -3.18250344 -3.18250344 -3.18250344]
 [-3.41868463 -3.41868463 -3.41868463 -3.41868463]
 [ 2.91053764  2.91053764  2.91053764  2.91053764]]
Activation function: sigmoid
H1 matrix: 
 [[0.01234253 0.01234253 0.01234253 0.01234253]
 [0.87488361 0.87488361 0.87488361 0.87488361]
 [0.96942745 0.96942745 0.96942745 0.96942745]
 [0.03982948 0.03982948 0.03982948 0.03982948]
 [0.0317166  0.0317166  0.0317166  0.0317166 ]
 [0.9483649  0.9483649  0.9483649  0.9483649 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.57082545]
 [ 5.45162203]
 [ 6.04031384]
 [-1.52247875]
 [-1.54904114]
 [ 5.90912468]]
y_hat:
 [[0.17209875]
 [0.99572898]
 [0.99762484]
 [0.1790968 ]
 [0.1752248 ]
 [0.99729279]]
MSE Loss: 0.015404764446580663
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.30872465 0.30872465 0.30872465 0.30872465]
 [1.5939349  1.5939349  1.5939349  1.5939349 ]
 [1.6032341  1.6032341  1.6032341  1.6032341 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.13880234e-01]
 [ 5.16627677e-04]
 [ 3.50779485e-05]
 [-1.16761754e+00]
 [-1.00358608e+00]
 [ 7.95165339e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.55554808]
 [1.55554808]
 [1.55554808]
 [1.55554808]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.67224876e+00]
 [ 5.05047643e-04]
 [ 1.10234659e-04]
 [-1.79697523e+00]
 [-1.77198135e+00]
 [ 1.57157545e-04]]
Epoch 27
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.39434577 -4.39434577 -4.39434577 -4.39434577]
 [ 1.95179049  1.95179049  1.95179049  1.95179049]
 [ 3.46702158  3.46702158  3.46702158  3.46702158]
 [-3.19695361 -3.19695361 -3.19695361 -3.19695361]
 [-3.43155567 -3.43155567 -3.43155567 -3.43155567]
 [ 2.91959035  2.91959035  2.91959035  2.91959035]]
Activation function: sigmoid
H1 matrix: 
 [[0.01219637 0.01219637 0.01219637 0.01219637]
 [0.87564174 0.87564174 0.87564174 0.87564174]
 [0.96973473 0.96973473 0.96973473 0.96973473]
 [0.03928052 0.03928052 0.03928052 0.03928052]
 [0.03132369 0.03132369 0.03132369 0.03132369]
 [0.9488064  0.9488064  0.9488064  0.9488064 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.59636062]
 [ 5.44891639]
 [ 6.03398621]
 [-1.55256425]
 [-1.5770793 ]
 [ 5.90381309]]
y_hat:
 [[0.16849088]
 [0.99571746]
 [0.9976098 ]
 [0.17471622]
 [0.17120952]
 [0.99727841]]
MSE Loss: 0.014709849340586854
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.30551771 0.30551771 0.30551771 0.30551771]
 [1.5965435  1.5965435  1.5965435  1.5965435 ]
 [1.60594271 1.60594271 1.60594271 1.60594271]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.15649790e-01]
 [ 5.29000940e-04]
 [ 3.61187533e-05]
 [-1.17353298e+00]
 [-1.00817273e+00]
 [ 8.17490727e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.55353815]
 [1.55353815]
 [1.55353815]
 [1.55353815]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.69585462e+00]
 [ 5.23309280e-04]
 [ 1.15934048e-04]
 [-1.82216764e+00]
 [-1.79627544e+00]
 [ 1.64544447e-04]]
Epoch 28
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.40575858 -4.40575858 -4.40575858 -4.40575858]
 [ 1.95835675  1.95835675  1.95835675  1.95835675]
 [ 3.47687254  3.47687254  3.47687254  3.47687254]
 [-3.21059839 -3.21059839 -3.21059839 -3.21059839]
 [-3.44373087 -3.44373087 -3.44373087 -3.44373087]
 [ 2.92814991  2.92814991  2.92814991  2.92814991]]
Activation function: sigmoid
H1 matrix: 
 [[0.01205963 0.01205963 0.01205963 0.01205963]
 [0.87635501 0.87635501 0.87635501 0.87635501]
 [0.97002251 0.97002251 0.97002251 0.97002251]
 [0.03876883 0.03876883 0.03876883 0.03876883]
 [0.03095637 0.03095637 0.03095637 0.03095637]
 [0.94922057 0.94922057 0.94922057 0.94922057]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.62091422]
 [ 5.44632704]
 [ 6.02798384]
 [-1.58125223]
 [-1.60390783]
 [ 5.89876604]]
y_hat:
 [[0.16507883]
 [0.9957064 ]
 [0.99759545]
 [0.17061821]
 [0.16743615]
 [0.99726468]]
MSE Loss: 0.014071359234635102
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.30248004 0.30248004 0.30248004 0.30248004]
 [1.59901742 1.59901742 1.59901742 1.59901742]
 [1.60850931 1.60850931 1.60850931 1.60850931]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.17334305e-01]
 [ 5.41360780e-04]
 [ 3.71610279e-05]
 [-1.17912408e+00]
 [-1.01252375e+00]
 [ 8.39840086e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.55163395]
 [1.55163395]
 [1.55163395]
 [1.55163395]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.71860707e+00]
 [ 5.41665123e-04]
 [ 1.21702020e-04]
 [-1.84631142e+00]
 [-1.81961625e+00]
 [ 1.72005983e-04]]
Epoch 29
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.41658248 -4.41658248 -4.41658248 -4.41658248]
 [ 1.96458002  1.96458002  1.96458002  1.96458002]
 [ 3.48620825  3.48620825  3.48620825  3.48620825]
 [-3.22351339 -3.22351339 -3.22351339 -3.22351339]
 [-3.45527378 -3.45527378 -3.45527378 -3.45527378]
 [ 2.93626174  2.93626174  2.93626174  2.93626174]]
Activation function: sigmoid
H1 matrix: 
 [[0.01193135 0.01193135 0.01193135 0.01193135]
 [0.87702776 0.87702776 0.87702776 0.87702776]
 [0.97029279 0.97029279 0.97029279 0.97029279]
 [0.0382904  0.0382904  0.0382904  0.0382904 ]
 [0.03061197 0.03061197 0.03061197 0.03061197]
 [0.94961015 0.94961015 0.94961015 0.94961015]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.6445547 ]
 [ 5.44384588]
 [ 6.02227869]
 [-1.6086607 ]
 [-1.62962195]
 [ 5.89396141]]
y_hat:
 [[0.16184626]
 [0.99569578]
 [0.99758172]
 [0.16677464]
 [0.16388216]
 [0.99725154]]
MSE Loss: 0.01348288023001814
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.29959651 0.29959651 0.29959651 0.29959651]
 [1.60136846 1.60136846 1.60136846 1.60136846]
 [1.61094653 1.61094653 1.61094653 1.61094653]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.18940711e-01]
 [ 5.53708456e-04]
 [ 3.82047251e-05]
 [-1.18442079e+00]
 [-1.01665964e+00]
 [ 8.62212972e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54982619]
 [1.54982619]
 [1.54982619]
 [1.54982619]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.74056185e+00]
 [ 5.60111690e-04]
 [ 1.27535943e-04]
 [-1.86948657e+00]
 [-1.84207217e+00]
 [ 1.79539266e-04]]
Epoch 30
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.42686901 -4.42686901 -4.42686901 -4.42686901]
 [ 1.9704907   1.9704907   1.9704907   1.9704907 ]
 [ 3.4950744   3.4950744   3.4950744   3.4950744 ]
 [-3.23576457 -3.23576457 -3.23576457 -3.23576457]
 [-3.46624004 -3.46624004 -3.46624004 -3.46624004]
 [ 2.94396551  2.94396551  2.94396551  2.94396551]]
Activation function: sigmoid
H1 matrix: 
 [[0.01181069 0.01181069 0.01181069 0.01181069]
 [0.87766381 0.87766381 0.87766381 0.87766381]
 [0.9705473  0.9705473  0.9705473  0.9705473 ]
 [0.0378418  0.0378418  0.0378418  0.0378418 ]
 [0.03028822 0.03028822 0.03028822 0.03028822]
 [0.94997751 0.94997751 0.94997751 0.94997751]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.66734377]
 [ 5.44146555]
 [ 6.01684601]
 [-1.63489372]
 [-1.65430626]
 [ 5.88937962]]
y_hat:
 [[0.15877865]
 [0.99568557]
 [0.99756858]
 [0.16316107]
 [0.16052779]
 [0.99723895]]
MSE Loss: 0.012938919381426732
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.29685384 0.29685384 0.29685384 0.29685384]
 [1.60360699 1.60360699 1.60360699 1.60360699]
 [1.61326545 1.61326545 1.61326545 1.61326545]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.20475161e-01]
 [ 5.66045067e-04]
 [ 3.92497992e-05]
 [-1.18944926e+00]
 [-1.02059847e+00]
 [ 8.84608908e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54810668]
 [1.54810668]
 [1.54810668]
 [1.54810668]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.76176959e+00]
 [ 5.78645713e-04]
 [ 1.33433365e-04]
 [-1.89176451e+00]
 [-1.86370467e+00]
 [ 1.87141611e-04]]
Epoch 31
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.43666356 -4.43666356 -4.43666356 -4.43666356]
 [ 1.97611553  1.97611553  1.97611553  1.97611553]
 [ 3.50351112  3.50351112  3.50351112  3.50351112]
 [-3.24740977 -3.24740977 -3.24740977 -3.24740977]
 [-3.47667859 -3.47667859 -3.47667859 -3.47667859]
 [ 2.95129613  2.95129613  2.95129613  2.95129613]]
Activation function: sigmoid
H1 matrix: 
 [[0.01169692 0.01169692 0.01169692 0.01169692]
 [0.87826647 0.87826647 0.87826647 0.87826647]
 [0.97078751 0.97078751 0.97078751 0.97078751]
 [0.03742008 0.03742008 0.03742008 0.03742008]
 [0.02998313 0.02998313 0.02998313 0.02998313]
 [0.95032471 0.95032471 0.95032471 0.95032471]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.68933725]
 [ 5.43917937]
 [ 6.01166392]
 [-1.66004344]
 [-1.67803634]
 [ 5.88500327]]
y_hat:
 [[0.15586302]
 [0.99567573]
 [0.99755598]
 [0.15975617]
 [0.15735566]
 [0.99722687]]
MSE Loss: 0.012434746821267904
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.29424032 0.29424032 0.29424032 0.29424032]
 [1.6057422  1.6057422  1.6057422  1.6057422 ]
 [1.61547584 1.61547584 1.61547584 1.61547584]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.21943147e-01]
 [ 5.78371573e-04]
 [ 4.02962061e-05]
 [-1.19423251e+00]
 [-1.02435620e+00]
 [ 9.07027396e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54646819]
 [1.54646819]
 [1.54646819]
 [1.54646819]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.78227645e+00]
 [ 5.97264124e-04]
 [ 1.39392002e-04]
 [-1.91320924e+00]
 [-1.88456923e+00]
 [ 1.94810510e-04]]
Epoch 32
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.44600624 -4.44600624 -4.44600624 -4.44600624]
 [ 1.98147811  1.98147811  1.98147811  1.98147811]
 [ 3.51155385  3.51155385  3.51155385  3.51155385]
 [-3.25849992 -3.25849992 -3.25849992 -3.25849992]
 [-3.48663268 -3.48663268 -3.48663268 -3.48663268]
 [ 2.95828439  2.95828439  2.95828439  2.95828439]]
Activation function: sigmoid
H1 matrix: 
 [[0.01158941 0.01158941 0.01158941 0.01158941]
 [0.87883864 0.87883864 0.87883864 0.87883864]
 [0.97101473 0.97101473 0.97101473 0.97101473]
 [0.03702265 0.03702265 0.03702265 0.03702265]
 [0.02969497 0.02969497 0.02969497 0.02969497]
 [0.95065357 0.95065357 0.95065357 0.95065357]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.71058582]
 [ 5.43698127]
 [ 6.00671295]
 [-1.68419182]
 [-1.7008799 ]
 [ 5.88081685]]
y_hat:
 [[0.15308775]
 [0.99566626]
 [0.99754388]
 [0.1565412 ]
 [0.15435038]
 [0.99721527]]
MSE Loss: 0.011966269061658203
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.29174557 0.29174557 0.29174557 0.29174557]
 [1.60778223 1.60778223 1.60778223 1.60778223]
 [1.61758638 1.61758638 1.61758638 1.61758638]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.23349580e-01]
 [ 5.90688822e-04]
 [ 4.13439028e-05]
 [-1.19879084e+00]
 [-1.02794706e+00]
 [ 9.29467926e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54490431]
 [1.54490431]
 [1.54490431]
 [1.54490431]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.80212457e+00]
 [ 6.15964031e-04]
 [ 1.45409714e-04]
 [-1.93387832e+00]
 [-1.90471602e+00]
 [ 2.02543619e-04]]
Epoch 33
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.45493267 -4.45493267 -4.45493267 -4.45493267]
 [ 1.98659935  1.98659935  1.98659935  1.98659935]
 [ 3.51923402  3.51923402  3.51923402  3.51923402]
 [-3.26908011 -3.26908011 -3.26908011 -3.26908011]
 [-3.4961407  -3.4961407  -3.4961407  -3.4961407 ]
 [ 2.96495761  2.96495761  2.96495761  2.96495761]]
Activation function: sigmoid
H1 matrix: 
 [[0.0114876  0.0114876  0.0114876  0.0114876 ]
 [0.8793829  0.8793829  0.8793829  0.8793829 ]
 [0.97123011 0.97123011 0.97123011 0.97123011]
 [0.03664729 0.03664729 0.03664729 0.03664729]
 [0.02942224 0.02942224 0.02942224 0.02942224]
 [0.95096568 0.95096568 0.95096568 0.95096568]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.73113557]
 [ 5.43486568]
 [ 6.00197572]
 [-1.70741209]
 [-1.72289784]
 [ 5.87680647]]
y_hat:
 [[0.15044239]
 [0.99565712]
 [0.99753225]
 [0.15349968]
 [0.15149828]
 [0.99720411]]
MSE Loss: 0.011529926553916423
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.28936035 0.28936035 0.28936035 0.28936035]
 [1.60973436 1.60973436 1.60973436 1.60973436]
 [1.61960479 1.61960479 1.61960479 1.61960479]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.24698873e-01]
 [ 6.02997560e-04]
 [ 4.23928483e-05]
 [-1.20314226e+00]
 [-1.03138371e+00]
 [ 9.51929981e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54340932]
 [1.54340932]
 [1.54340932]
 [1.54340932]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.82135253e+00]
 [ 6.34742711e-04]
 [ 1.51484500e-04]
 [-1.95382369e+00]
 [-1.92419060e+00]
 [ 2.10338742e-04]]
Epoch 34
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.46347462 -4.46347462 -4.46347462 -4.46347462]
 [ 1.99149791  1.99149791  1.99149791  1.99149791]
 [ 3.52657961  3.52657961  3.52657961  3.52657961]
 [-3.27919039 -3.27919039 -3.27919039 -3.27919039]
 [-3.50523687 -3.50523687 -3.50523687 -3.50523687]
 [ 2.97134011  2.97134011  2.97134011  2.97134011]]
Activation function: sigmoid
H1 matrix: 
 [[0.01139101 0.01139101 0.01139101 0.01139101]
 [0.87990152 0.87990152 0.87990152 0.87990152]
 [0.97143465 0.97143465 0.97143465 0.97143465]
 [0.03629202 0.03629202 0.03629202 0.03629202]
 [0.02916359 0.02916359 0.02916359 0.02916359]
 [0.95126245 0.95126245 0.95126245 0.95126245]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.75102858]
 [ 5.43282756]
 [ 5.99743666]
 [-1.72976991]
 [-1.74414516]
 [ 5.87295963]]
y_hat:
 [[0.14791751]
 [0.9956483 ]
 [0.99752105]
 [0.15061701]
 [0.14878719]
 [0.99719337]]
MSE Loss: 0.011122610280897574
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.28707642 0.28707642 0.28707642 0.28707642]
 [1.61160508 1.61160508 1.61160508 1.61160508]
 [1.62153797 1.62153797 1.62153797 1.62153797]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.25995004e-01]
 [ 6.15298449e-04]
 [ 4.34430026e-05]
 [-1.20730279e+00]
 [-1.03467751e+00]
 [ 9.74413041e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54197812]
 [1.54197812]
 [1.54197812]
 [1.54197812]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.83999574e+00]
 [ 6.53597592e-04]
 [ 1.57614478e-04]
 [-1.97309236e+00]
 [-1.94303443e+00]
 [ 2.18193815e-04]]
Epoch 35
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.47166052 -4.47166052 -4.47166052 -4.47166052]
 [ 1.99619042  1.99619042  1.99619042  1.99619042]
 [ 3.53361563  3.53361563  3.53361563  3.53361563]
 [-3.2888665  -3.2888665  -3.2888665  -3.2888665 ]
 [-3.51395178 -3.51395178 -3.51395178 -3.51395178]
 [ 2.97745363  2.97745363  2.97745363  2.97745363]]
Activation function: sigmoid
H1 matrix: 
 [[0.01129919 0.01129919 0.01129919 0.01129919]
 [0.88039652 0.88039652 0.88039652 0.88039652]
 [0.97162925 0.97162925 0.97162925 0.97162925]
 [0.03595512 0.03595512 0.03595512 0.03595512]
 [0.02891786 0.02891786 0.02891786 0.02891786]
 [0.9515451  0.9515451  0.9515451  0.9515451 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.77030331]
 [ 5.43086225]
 [ 5.99308179]
 [-1.75132435]
 [-1.76467162]
 [ 5.86926509]]
y_hat:
 [[0.14550461]
 [0.99563978]
 [0.99751025]
 [0.14788024]
 [0.14620622]
 [0.99718301]]
MSE Loss: 0.010741593400731103
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.28488638 0.28488638 0.28488638 0.28488638]
 [1.61340024 1.61340024 1.61340024 1.61340024]
 [1.6233921  1.6233921  1.6233921  1.6233921 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.27241565e-01]
 [ 6.27592076e-04]
 [ 4.44943276e-05]
 [-1.21128677e+00]
 [-1.03783866e+00]
 [ 9.96916589e-05]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.54060612]
 [1.54060612]
 [1.54060612]
 [1.54060612]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.85808677e+00]
 [ 6.72526245e-04]
 [ 1.63797879e-04]
 [-1.99172699e+00]
 [-1.96128535e+00]
 [ 2.26106898e-04]]
Epoch 36
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.47951589 -4.47951589 -4.47951589 -4.47951589]
 [ 2.00069183  2.00069183  2.00069183  2.00069183]
 [ 3.54036451  3.54036451  3.54036451  3.54036451]
 [-3.29814042 -3.29814042 -3.29814042 -3.29814042]
 [-3.52231291 -3.52231291 -3.52231291 -3.52231291]
 [ 2.98331766  2.98331766  2.98331766  2.98331766]]
Activation function: sigmoid
H1 matrix: 
 [[0.01121177 0.01121177 0.01121177 0.01121177]
 [0.8808697  0.8808697  0.8808697  0.8808697 ]
 [0.9718147  0.9718147  0.9718147  0.9718147 ]
 [0.03563504 0.03563504 0.03563504 0.03563504]
 [0.02868399 0.02868399 0.02868399 0.02868399]
 [0.95181476 0.95181476 0.95181476 0.95181476]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.78899507]
 [ 5.42896551]
 [ 5.98889848]
 [-1.77212875]
 [-1.78452245]
 [ 5.86571268]]
y_hat:
 [[0.14319597]
 [0.99563153]
 [0.99749984]
 [0.1452778 ]
 [0.1437456 ]
 [0.99717301]]
MSE Loss: 0.010384474881401545
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.28278359 0.28278359 0.28278359 0.28278359]
 [1.6151251  1.6151251  1.6151251  1.6151251 ]
 [1.62517275 1.62517275 1.62517275 1.62517275]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.28441817e-01]
 [ 6.39878965e-04]
 [ 4.55467865e-05]
 [-1.21510704e+00]
 [-1.04087635e+00]
 [ 1.01944011e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53928919]
 [1.53928919]
 [1.53928919]
 [1.53928919]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.87565561e+00]
 [ 6.91526367e-04]
 [ 1.70033036e-04]
 [-2.00976645e+00]
 [-1.97897796e+00]
 [ 2.34076163e-04]]
Epoch 37
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.48706373 -4.48706373 -4.48706373 -4.48706373]
 [ 2.00501558  2.00501558  2.00501558  2.00501558]
 [ 3.54684645  3.54684645  3.54684645  3.54684645]
 [-3.3070409  -3.3070409  -3.3070409  -3.3070409 ]
 [-3.53034498 -3.53034498 -3.53034498 -3.53034498]
 [ 2.98894975  2.98894975  2.98894975  2.98894975]]
Activation function: sigmoid
H1 matrix: 
 [[0.0111284  0.0111284  0.0111284  0.0111284 ]
 [0.88132268 0.88132268 0.88132268 0.88132268]
 [0.9719917  0.9719917  0.9719917  0.9719917 ]
 [0.03533043 0.03533043 0.03533043 0.03533043]
 [0.02846105 0.02846105 0.02846105 0.02846105]
 [0.95207241 0.95207241 0.95207241 0.95207241]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.80713628]
 [ 5.42713341]
 [ 5.98487532]
 [-1.79223143]
 [-1.80373883]
 [ 5.86229316]]
y_hat:
 [[0.14098459]
 [0.99562356]
 [0.99748979]
 [0.14279936]
 [0.14139655]
 [0.99716336]]
MSE Loss: 0.010049132754224373
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.28076206 0.28076206 0.28076206 0.28076206]
 [1.61678442 1.61678442 1.61678442 1.61678442]
 [1.62688496 1.62688496 1.62688496 1.62688496]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.29598720e-01]
 [ 6.52159583e-04]
 [ 4.66003439e-05]
 [-1.21877515e+00]
 [-1.04379890e+00]
 [ 1.04198311e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53802361]
 [1.53802361]
 [1.53802361]
 [1.53802361]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.89272996e+00]
 [ 7.10595780e-04]
 [ 1.76318375e-04]
 [-2.02724619e+00]
 [-1.99614400e+00]
 [ 2.42099883e-04]]
Epoch 38
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.49432483 -4.49432483 -4.49432483 -4.49432483]
 [ 2.0091738   2.0091738   2.0091738   2.0091738 ]
 [ 3.55307968  3.55307968  3.55307968  3.55307968]
 [-3.31559386 -3.31559386 -3.31559386 -3.31559386]
 [-3.53807035 -3.53807035 -3.53807035 -3.53807035]
 [ 2.99436574  2.99436574  2.99436574  2.99436574]]
Activation function: sigmoid
H1 matrix: 
 [[0.01104878 0.01104878 0.01104878 0.01104878]
 [0.88175691 0.88175691 0.88175691 0.88175691]
 [0.9721609  0.9721609  0.9721609  0.9721609 ]
 [0.03504009 0.03504009 0.03504009 0.03504009]
 [0.02824821 0.02824821 0.02824821 0.02824821]
 [0.95231894 0.95231894 0.95231894 0.95231894]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.82475682]
 [ 5.42536236]
 [ 5.98100195]
 [-1.81167628]
 [-1.82235835]
 [ 5.85899814]]
y_hat:
 [[0.13886407]
 [0.99561584]
 [0.99748007]
 [0.14043565]
 [0.13915113]
 [0.99715402]]
MSE Loss: 0.009733685133811693
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27881635 0.27881635 0.27881635 0.27881635]
 [1.6183825  1.6183825  1.6183825  1.6183825 ]
 [1.62853326 1.62853326 1.62853326 1.62853326]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.30714976e-01]
 [ 6.64434347e-04]
 [ 4.76549658e-05]
 [-1.22230155e+00]
 [-1.04661384e+00]
 [ 1.06454507e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53680598]
 [1.53680598]
 [1.53680598]
 [1.53680598]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.90933545e+00]
 [ 7.29732412e-04]
 [ 1.82652409e-04]
 [-2.04419867e+00]
 [-2.01281265e+00]
 [ 2.50176428e-04]]
Epoch 39
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.50131802 -4.50131802 -4.50131802 -4.50131802]
 [ 2.01317749  2.01317749  2.01317749  2.01317749]
 [ 3.5590807   3.5590807   3.5590807   3.5590807 ]
 [-3.32382271 -3.32382271 -3.32382271 -3.32382271]
 [-3.54550926 -3.54550926 -3.54550926 -3.54550926]
 [ 2.99957998  2.99957998  2.99957998  2.99957998]]
Activation function: sigmoid
H1 matrix: 
 [[0.01097263 0.01097263 0.01097263 0.01097263]
 [0.8821737  0.8821737  0.8821737  0.8821737 ]
 [0.97232285 0.97232285 0.97232285 0.97232285]
 [0.03476291 0.03476291 0.03476291 0.03476291]
 [0.02804472 0.02804472 0.02804472 0.02804472]
 [0.95255515 0.95255515 0.95255515 0.95255515]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.84188423]
 [ 5.42364903]
 [ 5.97726894]
 [-1.83050327]
 [-1.84041545]
 [ 5.85581998]]
y_hat:
 [[0.1368286 ]
 [0.99560835]
 [0.99747067]
 [0.13817833]
 [0.13700217]
 [0.99714499]]
MSE Loss: 0.009436457547398646
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27694153 0.27694153 0.27694153 0.27694153]
 [1.61992326 1.61992326 1.61992326 1.61992326]
 [1.63012178 1.63012178 1.63012178 1.63012178]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.31793051e-01]
 [ 6.76703632e-04]
 [ 4.87106195e-05]
 [-1.22569566e+00]
 [-1.04932804e+00]
 [ 1.08712552e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53563325]
 [1.53563325]
 [1.53563325]
 [1.53563325]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.92549580e+00]
 [ 7.48934299e-04]
 [ 1.89033730e-04]
 [-2.06065365e+00]
 [-2.02901077e+00]
 [ 2.58304253e-04]]
Epoch 40
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.50806043 -4.50806043 -4.50806043 -4.50806043]
 [ 2.01703662  2.01703662  2.01703662  2.01703662]
 [ 3.5648645   3.5648645   3.5648645   3.5648645 ]
 [-3.3317487  -3.3317487  -3.3317487  -3.3317487 ]
 [-3.55268011 -3.55268011 -3.55268011 -3.55268011]
 [ 3.00460549  3.00460549  3.00460549  3.00460549]]
Activation function: sigmoid
H1 matrix: 
 [[0.0108997  0.0108997  0.0108997  0.0108997 ]
 [0.88257424 0.88257424 0.88257424 0.88257424]
 [0.97247807 0.97247807 0.97247807 0.97247807]
 [0.03449794 0.03449794 0.03449794 0.03449794]
 [0.02784992 0.02784992 0.02784992 0.02784992]
 [0.95278175 0.95278175 0.95278175 0.95278175]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.85854403]
 [ 5.42199035]
 [ 5.9736677 ]
 [-1.84874892]
 [-1.85794172]
 [ 5.85275169]]
y_hat:
 [[0.13487285]
 [0.99560109]
 [0.99746157]
 [0.13601985]
 [0.13494314]
 [0.99713624]]
MSE Loss: 0.009155955419513688
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27513314 0.27513314 0.27513314 0.27513314]
 [1.62141027 1.62141027 1.62141027 1.62141027]
 [1.6316543  1.6316543  1.6316543  1.6316543 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.32835204e-01]
 [ 6.88967776e-04]
 [ 4.97672736e-05]
 [-1.22896607e+00]
 [-1.05194774e+00]
 [ 1.10972398e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53450262]
 [1.53450262]
 [1.53450262]
 [1.53450262]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.94123305e+00]
 [ 7.68199569e-04]
 [ 1.95461002e-04]
 [-2.07663849e+00]
 [-2.04476315e+00]
 [ 2.66481892e-04]]
Epoch 41
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.51456767 -4.51456767 -4.51456767 -4.51456767]
 [ 2.02076029  2.02076029  2.02076029  2.02076029]
 [ 3.57044473  3.57044473  3.57044473  3.57044473]
 [-3.33939113 -3.33939113 -3.33939113 -3.33939113]
 [-3.55959965 -3.55959965 -3.55959965 -3.55959965]
 [ 3.00945414  3.00945414  3.00945414  3.00945414]]
Activation function: sigmoid
H1 matrix: 
 [[0.01082977 0.01082977 0.01082977 0.01082977]
 [0.8829596  0.8829596  0.8829596  0.8829596 ]
 [0.97262703 0.97262703 0.97262703 0.97262703]
 [0.03424429 0.03424429 0.03424429 0.03424429]
 [0.02766319 0.02766319 0.02766319 0.02766319]
 [0.95299941 0.95299941 0.95299941 0.95299941]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.87475982]
 [ 5.42038349]
 [ 5.97019038]
 [-1.86644669]
 [-1.87496621]
 [ 5.84978685]]
y_hat:
 [[0.13299193]
 [0.99559405]
 [0.99745275]
 [0.13395341]
 [0.13296814]
 [0.99712776]]
MSE Loss: 0.008890840792149475
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27338707 0.27338707 0.27338707 0.27338707]
 [1.62284679 1.62284679 1.62284679 1.62284679]
 [1.63313423 1.63313423 1.63313423 1.63313423]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.33843508e-01]
 [ 7.01227081e-04]
 [ 5.08248978e-05]
 [-1.23212058e+00]
 [-1.05447865e+00]
 [ 1.13233997e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53341153]
 [1.53341153]
 [1.53341153]
 [1.53341153]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.95656770e+00]
 [ 7.87526443e-04]
 [ 2.01932957e-04]
 [-2.09217841e+00]
 [-2.06009273e+00]
 [ 2.74707957e-04]]
Epoch 42
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.52085399 -4.52085399 -4.52085399 -4.52085399]
 [ 2.02435677  2.02435677  2.02435677  2.02435677]
 [ 3.57583384  3.57583384  3.57583384  3.57583384]
 [-3.34676761 -3.34676761 -3.34676761 -3.34676761]
 [-3.56628319 -3.56628319 -3.56628319 -3.56628319]
 [ 3.01413674  3.01413674  3.01413674  3.01413674]]
Activation function: sigmoid
H1 matrix: 
 [[0.01076263 0.01076263 0.01076263 0.01076263]
 [0.88333076 0.88333076 0.88333076 0.88333076]
 [0.97277015 0.97277015 0.97277015 0.97277015]
 [0.03400117 0.03400117 0.03400117 0.03400117]
 [0.02748398 0.02748398 0.02748398 0.02748398]
 [0.95320871 0.95320871 0.95320871 0.95320871]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.89055351]
 [ 5.4188258 ]
 [ 5.96682976]
 [-1.88362725]
 [-1.89151571]
 [ 5.8469196 ]]
y_hat:
 [[0.13118137]
 [0.99558721]
 [0.9974442 ]
 [0.1319728 ]
 [0.13107175]
 [0.99711954]]
MSE Loss: 0.008639912542780143
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27169959 0.27169959 0.27169959 0.27169959]
 [1.62423581 1.62423581 1.62423581 1.62423581]
 [1.63456473 1.63456473 1.63456473 1.63456473]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.34819871e-01]
 [ 7.13481821e-04]
 [ 5.18834630e-05]
 [-1.23516631e+00]
 [-1.05692600e+00]
 [ 1.15497305e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53235765]
 [1.53235765]
 [1.53235765]
 [1.53235765]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.97151881e+00]
 [ 8.06913221e-04]
 [ 2.08448391e-04]
 [-2.10729668e+00]
 [-2.07502075e+00]
 [ 2.82981125e-04]]
Epoch 43
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.52693246 -4.52693246 -4.52693246 -4.52693246]
 [ 2.02783366  2.02783366  2.02783366  2.02783366]
 [ 3.58104324  3.58104324  3.58104324  3.58104324]
 [-3.35389423 -3.35389423 -3.35389423 -3.35389423]
 [-3.57274473 -3.57274473 -3.57274473 -3.57274473]
 [ 3.0186632   3.0186632   3.0186632   3.0186632 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.01069811 0.01069811 0.01069811 0.01069811]
 [0.8836886  0.8836886  0.8836886  0.8836886 ]
 [0.97290779 0.97290779 0.97290779 0.97290779]
 [0.03376787 0.03376787 0.03376787 0.03376787]
 [0.0273118  0.0273118  0.0273118  0.0273118 ]
 [0.95341018 0.95341018 0.95341018 0.95341018]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.90594549]
 [ 5.41731484]
 [ 5.96357924]
 [-1.90031884]
 [-1.90761497]
 [ 5.84414451]]
y_hat:
 [[0.12943704]
 [0.99558057]
 [0.9974359 ]
 [0.13007239]
 [0.12924904]
 [0.99711156]]
MSE Loss: 0.008402089505261588
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.27006727 0.27006727 0.27006727 0.27006727]
 [1.62558007 1.62558007 1.62558007 1.62558007]
 [1.63594866 1.63594866 1.63594866 1.63594866]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.35766050e-01]
 [ 7.25732242e-04]
 [ 5.29429413e-05]
 [-1.23810977e+00]
 [-1.05929461e+00]
 [ 1.17762276e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53133882]
 [1.53133882]
 [1.53133882]
 [1.53133882]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-1.98610418e+00]
 [ 8.26358283e-04]
 [ 2.15006156e-04]
 [-2.12201484e+00]
 [-2.08956692e+00]
 [ 2.91300139e-04]]
Epoch 44
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.53281504 -4.53281504 -4.53281504 -4.53281504]
 [ 2.03119792  2.03119792  2.03119792  2.03119792]
 [ 3.58608337  3.58608337  3.58608337  3.58608337]
 [-3.36078572 -3.36078572 -3.36078572 -3.36078572]
 [-3.57899713 -3.57899713 -3.57899713 -3.57899713]
 [ 3.02304261  3.02304261  3.02304261  3.02304261]]
Activation function: sigmoid
H1 matrix: 
 [[0.01063603 0.01063603 0.01063603 0.01063603]
 [0.88403394 0.88403394 0.88403394 0.88403394]
 [0.97304033 0.97304033 0.97304033 0.97304033]
 [0.03354374 0.03354374 0.03354374 0.03354374]
 [0.02714619 0.02714619 0.02714619 0.02714619]
 [0.95360433 0.95360433 0.95360433 0.95360433]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.92095472]
 [ 5.41584834]
 [ 5.96043272]
 [-1.9165475 ]
 [-1.92328686]
 [ 5.8414566 ]]
y_hat:
 [[0.12775514]
 [0.99557411]
 [0.99742784]
 [0.12824706]
 [0.12749549]
 [0.9971038 ]]
MSE Loss: 0.008176396011113769
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26848697 0.26848697 0.26848697 0.26848697]
 [1.62688209 1.62688209 1.62688209 1.62688209]
 [1.63728868 1.63728868 1.63728868 1.63728868]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.36683669e-01]
 [ 7.37978567e-04]
 [ 5.40033057e-05]
 [-1.24095694e+00]
 [-1.06158888e+00]
 [ 1.20028868e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.53035309]
 [1.53035309]
 [1.53035309]
 [1.53035309]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.00034041e+00]
 [ 8.45860083e-04]
 [ 2.21605160e-04]
 [-2.13635283e+00]
 [-2.10374956e+00]
 [ 2.99663799e-04]]
Epoch 45
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.53851277 -4.53851277 -4.53851277 -4.53851277]
 [ 2.03445594  2.03445594  2.03445594  2.03445594]
 [ 3.59096384  3.59096384  3.59096384  3.59096384]
 [-3.3674556  -3.3674556  -3.3674556  -3.3674556 ]
 [-3.5850522  -3.5850522  -3.5850522  -3.5850522 ]
 [ 3.02728331  3.02728331  3.02728331  3.02728331]]
Activation function: sigmoid
H1 matrix: 
 [[0.01057624 0.01057624 0.01057624 0.01057624]
 [0.88436753 0.88436753 0.88436753 0.88436753]
 [0.97316806 0.97316806 0.97316806 0.97316806]
 [0.03332819 0.03332819 0.03332819 0.03332819]
 [0.02698674 0.02698674 0.02698674 0.02698674]
 [0.95379159 0.95379159 0.95379159 0.95379159]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.93559889]
 [ 5.41442418]
 [ 5.95738459]
 [-1.93233726]
 [-1.93855262]
 [ 5.83885126]]
y_hat:
 [[0.12613216]
 [0.99556783]
 [0.99742001]
 [0.12649211]
 [0.12580695]
 [0.99709627]]
MSE Loss: 0.00796194945785378
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26695578 0.26695578 0.26695578 0.26695578]
 [1.62814418 1.62814418 1.62814418 1.62814418]
 [1.63858723 1.63858723 1.63858723 1.63858723]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.37574228e-01]
 [ 7.50220999e-04]
 [ 5.50645302e-05]
 [-1.24371330e+00]
 [-1.06381289e+00]
 [ 1.22297039e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52939862]
 [1.52939862]
 [1.52939862]
 [1.52939862]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.01424306e+00]
 [ 8.65417139e-04]
 [ 2.28244360e-04]
 [-2.15032917e+00]
 [-2.11758576e+00]
 [ 3.08070963e-04]]
Epoch 46
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.54403579 -4.54403579 -4.54403579 -4.54403579]
 [ 2.0376136   2.0376136   2.0376136   2.0376136 ]
 [ 3.5956935   3.5956935   3.5956935   3.5956935 ]
 [-3.37391631 -3.37391631 -3.37391631 -3.37391631]
 [-3.59092082 -3.59092082 -3.59092082 -3.59092082]
 [ 3.03139299  3.03139299  3.03139299  3.03139299]]
Activation function: sigmoid
H1 matrix: 
 [[0.0105186  0.0105186  0.0105186  0.0105186 ]
 [0.88469005 0.88469005 0.88469005 0.88469005]
 [0.97329129 0.97329129 0.97329129 0.97329129]
 [0.03312066 0.03312066 0.03312066 0.03312066]
 [0.02683306 0.02683306 0.02683306 0.02683306]
 [0.95397238 0.95397238 0.95397238 0.95397238]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.94989452]
 [ 5.41304038]
 [ 5.95442966]
 [-1.94771038]
 [-1.95343196]
 [ 5.83632423]]
y_hat:
 [[0.12456486]
 [0.99556172]
 [0.99741239]
 [0.12480323]
 [0.12417962]
 [0.99708894]]
MSE Loss: 0.007757949582153018
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26547103 0.26547103 0.26547103 0.26547103]
 [1.6293685  1.6293685  1.6293685  1.6293685 ]
 [1.63984653 1.63984653 1.63984653 1.63984653]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.38439118e-01]
 [ 7.62459721e-04]
 [ 5.61265898e-05]
 [-1.24638391e+00]
 [-1.06597041e+00]
 [ 1.24566747e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52847376]
 [1.52847376]
 [1.52847376]
 [1.52847376]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.02782666e+00]
 [ 8.85028035e-04]
 [ 2.34922759e-04]
 [-2.16396110e+00]
 [-2.13109141e+00]
 [ 3.16520538e-04]]
Epoch 47
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.54939348 -4.54939348 -4.54939348 -4.54939348]
 [ 2.04067634  2.04067634  2.04067634  2.04067634]
 [ 3.60028051  3.60028051  3.60028051  3.60028051]
 [-3.38017933 -3.38017933 -3.38017933 -3.38017933]
 [-3.59661305 -3.59661305 -3.59661305 -3.59661305]
 [ 3.03537873  3.03537873  3.03537873  3.03537873]]
Activation function: sigmoid
H1 matrix: 
 [[0.01046298 0.01046298 0.01046298 0.01046298]
 [0.88500212 0.88500212 0.88500212 0.88500212]
 [0.97341027 0.97341027 0.97341027 0.97341027]
 [0.03292069 0.03292069 0.03292069 0.03292069]
 [0.02668482 0.02668482 0.02668482 0.02668482]
 [0.95414707 0.95414707 0.95414707 0.95414707]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.96385708]
 [ 5.41169509]
 [ 5.95156312]
 [-1.96268749]
 [-1.96794322]
 [ 5.83387155]]
y_hat:
 [[0.12305023]
 [0.99555577]
 [0.99740498]
 [0.12317649]
 [0.12260998]
 [0.99708182]]
MSE Loss: 0.007563669172598813
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26403026 0.26403026 0.26403026 0.26403026]
 [1.63055703 1.63055703 1.63055703 1.63055703]
 [1.64106869 1.64106869 1.64106869 1.64106869]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.39279633e-01]
 [ 7.74694899e-04]
 [ 5.71894605e-05]
 [-1.24897341e+00]
 [-1.06806491e+00]
 [ 1.26837952e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52757694]
 [1.52757694]
 [1.52757694]
 [1.52757694]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.04110487e+00]
 [ 9.04691414e-04]
 [ 2.41639406e-04]
 [-2.17726466e+00]
 [-2.14428140e+00]
 [ 3.25011481e-04]]
Epoch 48
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.55459452 -4.55459452 -4.55459452 -4.55459452]
 [ 2.04364919  2.04364919  2.04364919  2.04364919]
 [ 3.60473241  3.60473241  3.60473241  3.60473241]
 [-3.38625523 -3.38625523 -3.38625523 -3.38625523]
 [-3.60213817 -3.60213817 -3.60213817 -3.60213817]
 [ 3.0392471   3.0392471   3.0392471   3.0392471 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.01040927 0.01040927 0.01040927 0.01040927]
 [0.88530433 0.88530433 0.88530433 0.88530433]
 [0.97352525 0.97352525 0.97352525 0.97352525]
 [0.03272779 0.03272779 0.03272779 0.03272779]
 [0.02654169 0.02654169 0.02654169 0.02654169]
 [0.95431602 0.95431602 0.95431602 0.95431602]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.97750102]
 [ 5.41038659]
 [ 5.94878053]
 [-1.97728776]
 [-1.98210348]
 [ 5.83148955]]
y_hat:
 [[0.12158548]
 [0.99554998]
 [0.99739777]
 [0.12160826]
 [0.12109478]
 [0.99707488]]
MSE Loss: 0.0073784460027818384
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26263118 0.26263118 0.26263118 0.26263118]
 [1.6317116  1.6317116  1.6317116  1.6317116 ]
 [1.64225561 1.64225561 1.64225561 1.64225561]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.40096971e-01]
 [ 7.86926683e-04]
 [ 5.82531189e-05]
 [-1.25148613e+00]
 [-1.07009962e+00]
 [ 1.29110615e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52670672]
 [1.52670672]
 [1.52670672]
 [1.52670672]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.05409050e+00]
 [ 9.24405975e-04]
 [ 2.48393391e-04]
 [-2.19025482e+00]
 [-2.15716962e+00]
 [ 3.33542794e-04]]
Epoch 49
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.55964694 -4.55964694 -4.55964694 -4.55964694]
 [ 2.04653679  2.04653679  2.04653679  2.04653679]
 [ 3.60905619  3.60905619  3.60905619  3.60905619]
 [-3.39215383 -3.39215383 -3.39215383 -3.39215383]
 [-3.60750479 -3.60750479 -3.60750479 -3.60750479]
 [ 3.04300417  3.04300417  3.04300417  3.04300417]]
Activation function: sigmoid
H1 matrix: 
 [[0.01035736 0.01035736 0.01035736 0.01035736]
 [0.88559721 0.88559721 0.88559721 0.88559721]
 [0.97363646 0.97363646 0.97363646 0.97363646]
 [0.03254158 0.03254158 0.03254158 0.03254158]
 [0.02640339 0.02640339 0.02640339 0.02640339]
 [0.95447953 0.95447953 0.95447953 0.95447953]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-1.99083992]
 [ 5.40911327]
 [ 5.94607773]
 [-1.99152903]
 [-1.99592871]
 [ 5.82917482]]
y_hat:
 [[0.12016803]
 [0.99554433]
 [0.99739074]
 [0.12009519]
 [0.11963104]
 [0.99706812]]
MSE Loss: 0.007201675802636341
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.26127167 0.26127167 0.26127167 0.26127167]
 [1.63283393 1.63283393 1.63283393 1.63283393]
 [1.64340909 1.64340909 1.64340909 1.64340909]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.40892252e-01]
 [ 7.99155211e-04]
 [ 5.93175427e-05]
 [-1.25392603e+00]
 [-1.07207753e+00]
 [ 1.31384699e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52586178]
 [1.52586178]
 [1.52586178]
 [1.52586178]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.06679559e+00]
 [ 9.44170471e-04]
 [ 2.55183840e-04]
 [-2.20294556e+00]
 [-2.16976909e+00]
 [ 3.42113519e-04]]
Epoch 50
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.56455821 -4.56455821 -4.56455821 -4.56455821]
 [ 2.04934345  2.04934345  2.04934345  2.04934345]
 [ 3.61325833  3.61325833  3.61325833  3.61325833]
 [-3.39788419 -3.39788419 -3.39788419 -3.39788419]
 [-3.6127209  -3.6127209  -3.6127209  -3.6127209 ]
 [ 3.04665556  3.04665556  3.04665556  3.04665556]]
Activation function: sigmoid
H1 matrix: 
 [[0.01030714 0.01030714 0.01030714 0.01030714]
 [0.88588126 0.88588126 0.88588126 0.88588126]
 [0.97374411 0.97374411 0.97374411 0.97374411]
 [0.03236165 0.03236165 0.03236165 0.03236165]
 [0.02626963 0.02626963 0.02626963 0.02626963]
 [0.95463792 0.95463792 0.95463792 0.95463792]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.00388653]
 [ 5.4078736 ]
 [ 5.94345088]
 [-2.00542791]
 [-2.00943379]
 [ 5.82692416]]
y_hat:
 [[0.11879546]
 [0.99553883]
 [0.9973839 ]
 [0.1186342 ]
 [0.11821599]
 [0.99706153]]
MSE Loss: 0.007032806116233283
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25994976 0.25994976 0.25994976 0.25994976]
 [1.63392558 1.63392558 1.63392558 1.63392558]
 [1.64453078 1.64453078 1.64453078 1.64453078]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.41666518e-01]
 [ 8.11380608e-04]
 [ 6.03827103e-05]
 [-1.25629683e+00]
 [-1.07400143e+00]
 [ 1.33660167e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52504087]
 [1.52504087]
 [1.52504087]
 [1.52504087]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.07923147e+00]
 [ 9.63983701e-04]
 [ 2.62009918e-04]
 [-2.21534997e+00]
 [-2.18209204e+00]
 [ 3.50722740e-04]]
Epoch 51
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.56933526 -4.56933526 -4.56933526 -4.56933526]
 [ 2.05207319  2.05207319  2.05207319  2.05207319]
 [ 3.61734487  3.61734487  3.61734487  3.61734487]
 [-3.40345475 -3.40345475 -3.40345475 -3.40345475]
 [-3.61779392 -3.61779392 -3.61779392 -3.61779392]
 [ 3.05020652  3.05020652  3.05020652  3.05020652]]
Activation function: sigmoid
H1 matrix: 
 [[0.01025852 0.01025852 0.01025852 0.01025852]
 [0.88615694 0.88615694 0.88615694 0.88615694]
 [0.97384839 0.97384839 0.97384839 0.97384839]
 [0.03218767 0.03218767 0.03218767 0.03218767]
 [0.02614018 0.02614018 0.02614018 0.02614018]
 [0.95479144 0.95479144 0.95479144 0.95479144]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.01665282]
 [ 5.40666616]
 [ 5.9408964 ]
 [-2.01899992]
 [-2.02263269]
 [ 5.82473461]]
y_hat:
 [[0.11746554]
 [0.99553347]
 [0.99737723]
 [0.11722244]
 [0.11684704]
 [0.99705511]]
MSE Loss: 0.006871330918970045
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25866361 0.25866361 0.25866361 0.25866361]
 [1.63498806 1.63498806 1.63498806 1.63498806]
 [1.64562222 1.64562222 1.64562222 1.64562222]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.42420742e-01]
 [ 8.23602986e-04]
 [ 6.14486007e-05]
 [-1.25860196e+00]
 [-1.07587391e+00]
 [ 1.35936983e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52424284]
 [1.52424284]
 [1.52424284]
 [1.52424284]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.09140881e+00]
 [ 9.83844514e-04]
 [ 2.68870821e-04]
 [-2.22748030e+00]
 [-2.19414993e+00]
 [ 3.59369578e-04]]
Epoch 52
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.57398455 -4.57398455 -4.57398455 -4.57398455]
 [ 2.05472974  2.05472974  2.05472974  2.05472974]
 [ 3.62132139  3.62132139  3.62132139  3.62132139]
 [-3.40887334 -3.40887334 -3.40887334 -3.40887334]
 [-3.62273076 -3.62273076 -3.62273076 -3.62273076]
 [ 3.05366191  3.05366191  3.05366191  3.05366191]]
Activation function: sigmoid
H1 matrix: 
 [[0.01021142 0.01021142 0.01021142 0.01021142]
 [0.88642466 0.88642466 0.88642466 0.88642466]
 [0.97394947 0.97394947 0.97394947 0.97394947]
 [0.0320193  0.0320193  0.0320193  0.0320193 ]
 [0.02601479 0.02601479 0.02601479 0.02601479]
 [0.95494036 0.95494036 0.95494036 0.95494036]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.02915007]
 [ 5.40548963]
 [ 5.93841093]
 [-2.03225955]
 [-2.03553848]
 [ 5.8226034 ]]
y_hat:
 [[0.11617616]
 [0.99552823]
 [0.99737072]
 [0.11585727]
 [0.11552181]
 [0.99704885]]
MSE Loss: 0.006716785887411141
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25741152 0.25741152 0.25741152 0.25741152]
 [1.63602272 1.63602272 1.63602272 1.63602272]
 [1.64668486 1.64668486 1.64668486 1.64668486]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.43155836e-01]
 [ 8.35822450e-04]
 [ 6.25151938e-05]
 [-1.26084461e+00]
 [-1.07769739e+00]
 [ 1.38215112e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52346662]
 [1.52346662]
 [1.52346662]
 [1.52346662]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.10333770e+00]
 [ 1.00375180e-03]
 [ 2.75765779e-04]
 [-2.23934807e+00]
 [-2.20595355e+00]
 [ 3.68053186e-04]]
Epoch 53
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.5785121  -4.5785121  -4.5785121  -4.5785121 ]
 [ 2.05731656  2.05731656  2.05731656  2.05731656]
 [ 3.62519313  3.62519313  3.62519313  3.62519313]
 [-3.41414728 -3.41414728 -3.41414728 -3.41414728]
 [-3.62753787 -3.62753787 -3.62753787 -3.62753787]
 [ 3.05702627  3.05702627  3.05702627  3.05702627]]
Activation function: sigmoid
H1 matrix: 
 [[0.01016576 0.01016576 0.01016576 0.01016576]
 [0.88668483 0.88668483 0.88668483 0.88668483]
 [0.97404753 0.97404753 0.97404753 0.97404753]
 [0.03185624 0.03185624 0.03185624 0.03185624]
 [0.02589327 0.02589327 0.02589327 0.02589327]
 [0.9550849  0.9550849  0.9550849  0.9550849 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.0413889 ]
 [ 5.40434273]
 [ 5.93599134]
 [-2.04522039]
 [-2.04816343]
 [ 5.82052794]]
y_hat:
 [[0.11492538]
 [0.99552312]
 [0.99736436]
 [0.11453623]
 [0.11423809]
 [0.99704273]]
MSE Loss: 0.0065687442317758265
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25619191 0.25619191 0.25619191 0.25619191]
 [1.63703086 1.63703086 1.63703086 1.63703086]
 [1.64772003 1.64772003 1.64772003 1.64772003]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.43872651e-01]
 [ 8.48039092e-04]
 [ 6.35824700e-05]
 [-1.26302776e+00]
 [-1.07947414e+00]
 [ 1.40494521e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5227112]
 [1.5227112]
 [1.5227112]
 [1.5227112]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.11502762e+00]
 [ 1.02370450e-03]
 [ 2.82694052e-04]
 [-2.25096407e+00]
 [-2.21751305e+00]
 [ 3.76772755e-04]]
Epoch 54
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.58292353 -4.58292353 -4.58292353 -4.58292353]
 [ 2.05983692  2.05983692  2.05983692  2.05983692]
 [ 3.62896496  3.62896496  3.62896496  3.62896496]
 [-3.41928335 -3.41928335 -3.41928335 -3.41928335]
 [-3.63222126 -3.63222126 -3.63222126 -3.63222126]
 [ 3.06030384  3.06030384  3.06030384  3.06030384]]
Activation function: sigmoid
H1 matrix: 
 [[0.01012147 0.01012147 0.01012147 0.01012147]
 [0.88693782 0.88693782 0.88693782 0.88693782]
 [0.9741427  0.9741427  0.9741427  0.9741427 ]
 [0.03169822 0.03169822 0.03169822 0.03169822]
 [0.0257754  0.0257754  0.0257754  0.0257754 ]
 [0.95522529 0.95522529 0.95522529 0.95522529]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.05337933]
 [ 5.40322429]
 [ 5.9336347 ]
 [-2.05789514]
 [-2.06051908]
 [ 5.81850578]]
y_hat:
 [[0.11371136]
 [0.99551814]
 [0.99735816]
 [0.11325705]
 [0.11299379]
 [0.99703676]]
MSE Loss: 0.006426813014921794
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25500327 0.25500327 0.25500327 0.25500327]
 [1.63801367 1.63801367 1.63801367 1.63801367]
 [1.64872899 1.64872899 1.64872899 1.64872899]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.44571987e-01]
 [ 8.60252999e-04]
 [ 6.46504105e-05]
 [-1.26515419e+00]
 [-1.08120626e+00]
 [ 1.42775177e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52197563]
 [1.52197563]
 [1.52197563]
 [1.52197563]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.12648758e+00]
 [ 1.04370158e-03]
 [ 2.89654927e-04]
 [-2.26233846e+00]
 [-2.22883798e+00]
 [ 3.85527502e-04]]
Epoch 55
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.58722412 -4.58722412 -4.58722412 -4.58722412]
 [ 2.06229384  2.06229384  2.06229384  2.06229384]
 [ 3.63264144  3.63264144  3.63264144  3.63264144]
 [-3.42428794 -3.42428794 -3.42428794 -3.42428794]
 [-3.63678656 -3.63678656 -3.63678656 -3.63678656]
 [ 3.06349857  3.06349857  3.06349857  3.06349857]]
Activation function: sigmoid
H1 matrix: 
 [[0.01007847 0.01007847 0.01007847 0.01007847]
 [0.88718396 0.88718396 0.88718396 0.88718396]
 [0.97423515 0.97423515 0.97423515 0.97423515]
 [0.03154497 0.03154497 0.03154497 0.03154497]
 [0.02566101 0.02566101 0.02566101 0.02566101]
 [0.95536173 0.95536173 0.95536173 0.95536173]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.06513083]
 [ 5.40213318]
 [ 5.93133828]
 [-2.07029576]
 [-2.07261626]
 [ 5.81653465]]
y_hat:
 [[0.1125324 ]
 [0.99551327]
 [0.9973521 ]
 [0.11201762]
 [0.111787  ]
 [0.99703093]]
MSE Loss: 0.006290629893182049
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25384422 0.25384422 0.25384422 0.25384422]
 [1.63897229 1.63897229 1.63897229 1.63897229]
 [1.64971291 1.64971291 1.64971291 1.64971291]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.45254594e-01]
 [ 8.72464249e-04]
 [ 6.57189971e-05]
 [-1.26722650e+00]
 [-1.08289573e+00]
 [ 1.45057047e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52125905]
 [1.52125905]
 [1.52125905]
 [1.52125905]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.13772606e+00]
 [ 1.06374205e-03]
 [ 2.96647718e-04]
 [-2.27348081e+00]
 [-2.23993739e+00]
 [ 3.94316677e-04]]
Epoch 56
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.59141878 -4.59141878 -4.59141878 -4.59141878]
 [ 2.06469016  2.06469016  2.06469016  2.06469016]
 [ 3.63622684  3.63622684  3.63622684  3.63622684]
 [-3.42916697 -3.42916697 -3.42916697 -3.42916697]
 [-3.64123903 -3.64123903 -3.64123903 -3.64123903]
 [ 3.06661419  3.06661419  3.06661419  3.06661419]]
Activation function: sigmoid
H1 matrix: 
 [[0.01003671 0.01003671 0.01003671 0.01003671]
 [0.88742358 0.88742358 0.88742358 0.88742358]
 [0.97432499 0.97432499 0.97432499 0.97432499]
 [0.03139626 0.03139626 0.03139626 0.03139626]
 [0.02554992 0.02554992 0.02554992 0.02554992]
 [0.95549441 0.95549441 0.95549441 0.95549441]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.07665233]
 [ 5.40106836]
 [ 5.92909949]
 [-2.08243346]
 [-2.08446519]
 [ 5.8146124 ]]
y_hat:
 [[0.11138689]
 [0.99550851]
 [0.99734618]
 [0.11081596]
 [0.11061592]
 [0.99702524]]
MSE Loss: 0.00615986022400554
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25271345 0.25271345 0.25271345 0.25271345]
 [1.63990777 1.63990777 1.63990777 1.63990777]
 [1.65067289 1.65067289 1.65067289 1.65067289]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.45921177e-01]
 [ 8.84672912e-04]
 [ 6.67882120e-05]
 [-1.26924712e+00]
 [-1.08454441e+00]
 [ 1.47340101e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.52056062]
 [1.52056062]
 [1.52056062]
 [1.52056062]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.14875112e+00]
 [ 1.08382495e-03]
 [ 3.03671765e-04]
 [-2.28440015e+00]
 [-2.25081979e+00]
 [ 4.03139555e-04]]
Epoch 57
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.59551213 -4.59551213 -4.59551213 -4.59551213]
 [ 2.06702854  2.06702854  2.06702854  2.06702854]
 [ 3.63972515  3.63972515  3.63972515  3.63972515]
 [-3.43392602 -3.43392602 -3.43392602 -3.43392602]
 [-3.6455836  -3.6455836  -3.6455836  -3.6455836 ]
 [ 3.06965415  3.06965415  3.06965415  3.06965415]]
Activation function: sigmoid
H1 matrix: 
 [[0.00999612 0.00999612 0.00999612 0.00999612]
 [0.88765698 0.88765698 0.88765698 0.88765698]
 [0.97441236 0.97441236 0.97441236 0.97441236]
 [0.03125185 0.03125185 0.03125185 0.03125185]
 [0.02544198 0.02544198 0.02544198 0.02544198]
 [0.95562351 0.95562351 0.95562351 0.95562351]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.08795231]
 [ 5.40002882]
 [ 5.92691591]
 [-2.09431881]
 [-2.09607551]
 [ 5.81273703]]
y_hat:
 [[0.11027332]
 [0.99550386]
 [0.9973404 ]
 [0.10965023]
 [0.10947885]
 [0.99701967]]
MSE Loss: 0.006034194493378511
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25160975 0.25160975 0.25160975 0.25160975]
 [1.6408211  1.6408211  1.6408211  1.6408211 ]
 [1.65160997 1.65160997 1.65160997 1.65160997]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.46572400e-01]
 [ 8.96879053e-04]
 [ 6.78580382e-05]
 [-1.27121831e+00]
 [-1.08615405e+00]
 [ 1.49624308e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51987957]
 [1.51987957]
 [1.51987957]
 [1.51987957]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.15957038e+00]
 [ 1.10394937e-03]
 [ 3.10726431e-04]
 [-2.29510498e+00]
 [-2.26149324e+00]
 [ 4.11995440e-04]]
Epoch 58
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.59950851 -4.59950851 -4.59950851 -4.59950851]
 [ 2.06931147  2.06931147  2.06931147  2.06931147]
 [ 3.64314013  3.64314013  3.64314013  3.64314013]
 [-3.43857031 -3.43857031 -3.43857031 -3.43857031]
 [-3.64982491 -3.64982491 -3.64982491 -3.64982491]
 [ 3.07262172  3.07262172  3.07262172  3.07262172]]
Activation function: sigmoid
H1 matrix: 
 [[0.00995665 0.00995665 0.00995665 0.00995665]
 [0.88788444 0.88788444 0.88788444 0.88788444]
 [0.97449737 0.97449737 0.97449737 0.97449737]
 [0.03111155 0.03111155 0.03111155 0.03111155]
 [0.02533703 0.02533703 0.02533703 0.02533703]
 [0.95574918 0.95574918 0.95574918 0.95574918]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.09903877]
 [ 5.39901363]
 [ 5.92478528]
 [-2.10596173]
 [-2.10745632]
 [ 5.81090663]]
y_hat:
 [[0.10919028]
 [0.99549931]
 [0.99733474]
 [0.10851872]
 [0.10837422]
 [0.99701423]]
MSE Loss: 0.005913346022740923
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.25053195 0.25053195 0.25053195 0.25053195]
 [1.64171321 1.64171321 1.64171321 1.64171321]
 [1.65252511 1.65252511 1.65252511 1.65252511]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.47208887e-01]
 [ 9.09082731e-04]
 [ 6.89284591e-05]
 [-1.27314223e+00]
 [-1.08772627e+00]
 [ 1.51909639e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51921517]
 [1.51921517]
 [1.51921517]
 [1.51921517]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.17019107e+00]
 [ 1.12411442e-03]
 [ 3.17811103e-04]
 [-2.30560334e+00]
 [-2.27196535e+00]
 [ 4.20883658e-04]]
Epoch 59
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.60341199 -4.60341199 -4.60341199 -4.60341199]
 [ 2.07154131  2.07154131  2.07154131  2.07154131]
 [ 3.6464753   3.6464753   3.6464753   3.6464753 ]
 [-3.44310474 -3.44310474 -3.44310474 -3.44310474]
 [-3.6539673  -3.6539673  -3.6539673  -3.6539673 ]
 [ 3.07551996  3.07551996  3.07551996  3.07551996]]
Activation function: sigmoid
H1 matrix: 
 [[0.00991824 0.00991824 0.00991824 0.00991824]
 [0.88810622 0.88810622 0.88810622 0.88810622]
 [0.97458012 0.97458012 0.97458012 0.97458012]
 [0.03097516 0.03097516 0.03097516 0.03097516]
 [0.02523493 0.02523493 0.02523493 0.02523493]
 [0.9558716  0.9558716  0.9558716  0.9558716 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.1099193 ]
 [ 5.39802188]
 [ 5.92270545]
 [-2.11737163]
 [-2.11861619]
 [ 5.80911942]]
y_hat:
 [[0.10813645]
 [0.99549486]
 [0.99732921]
 [0.10741982]
 [0.10730055]
 [0.9970089 ]]
MSE Loss: 0.005797048920786429
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24947899 0.24947899 0.24947899 0.24947899]
 [1.64258498 1.64258498 1.64258498 1.64258498]
 [1.65341923 1.65341923 1.65341923 1.65341923]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.47831226e-01]
 [ 9.21284000e-04]
 [ 6.99994587e-05]
 [-1.27502087e+00]
 [-1.08926262e+00]
 [ 1.54196065e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51856675]
 [1.51856675]
 [1.51856675]
 [1.51856675]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.18062007e+00]
 [ 1.14431923e-03]
 [ 3.24925188e-04]
 [-2.31590284e+00]
 [-2.28224337e+00]
 [ 4.29803560e-04]]
Epoch 60
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.6072264  -4.6072264  -4.6072264  -4.6072264 ]
 [ 2.07372025  2.07372025  2.07372025  2.07372025]
 [ 3.64973397  3.64973397  3.64973397  3.64973397]
 [-3.44753393 -3.44753393 -3.44753393 -3.44753393]
 [-3.65801488 -3.65801488 -3.65801488 -3.65801488]
 [ 3.07835174  3.07835174  3.07835174  3.07835174]]
Activation function: sigmoid
H1 matrix: 
 [[0.00988085 0.00988085 0.00988085 0.00988085]
 [0.88832256 0.88832256 0.88832256 0.88832256]
 [0.97466073 0.97466073 0.97466073 0.97466073]
 [0.03084249 0.03084249 0.03084249 0.03084249]
 [0.02513556 0.02513556 0.02513556 0.02513556]
 [0.95599089 0.95599089 0.95599089 0.95599089]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.12060113]
 [ 5.39705274]
 [ 5.9206744 ]
 [-2.12855733]
 [-2.12956327]
 [ 5.80737371]]
y_hat:
 [[0.10711057]
 [0.99549052]
 [0.99732379]
 [0.10635203]
 [0.10625646]
 [0.99700369]]
MSE Loss: 0.005685056250327822
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24844984 0.24844984 0.24844984 0.24844984]
 [1.64343723 1.64343723 1.64343723 1.64343723]
 [1.65429318 1.65429318 1.65429318 1.65429318]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.48439975e-01]
 [ 9.33482907e-04]
 [ 7.10710214e-05]
 [-1.27685612e+00]
 [-1.09076455e+00]
 [ 1.56483558e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51793364]
 [1.51793364]
 [1.51793364]
 [1.51793364]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.19086390e+00]
 [ 1.16456298e-03]
 [ 3.32068113e-04]
 [-2.32601067e+00]
 [-2.29233412e+00]
 [ 4.38754519e-04]]
Epoch 61
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.61095535 -4.61095535 -4.61095535 -4.61095535]
 [ 2.07585038  2.07585038  2.07585038  2.07585038]
 [ 3.65291927  3.65291927  3.65291927  3.65291927]
 [-3.4518622  -3.4518622  -3.4518622  -3.4518622 ]
 [-3.6619715  -3.6619715  -3.6619715  -3.6619715 ]
 [ 3.08111979  3.08111979  3.08111979  3.08111979]]
Activation function: sigmoid
H1 matrix: 
 [[0.00984444 0.00984444 0.00984444 0.00984444]
 [0.88853371 0.88853371 0.88853371 0.88853371]
 [0.97473928 0.97473928 0.97473928 0.97473928]
 [0.03071337 0.03071337 0.03071337 0.03071337]
 [0.02503879 0.02503879 0.02503879 0.02503879]
 [0.9561072  0.9561072  0.9561072  0.9561072 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.13109108]
 [ 5.39610541]
 [ 5.91869023]
 [-2.13952722]
 [-2.14030524]
 [ 5.8056679 ]]
y_hat:
 [[0.10611146]
 [0.99548626]
 [0.99731849]
 [0.10531393]
 [0.10524064]
 [0.99699859]]
MSE Loss: 0.00557713838447153
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24744354 0.24744354 0.24744354 0.24744354]
 [1.64427074 1.64427074 1.64427074 1.64427074]
 [1.65514777 1.65514777 1.65514777 1.65514777]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.49035658e-01]
 [ 9.45679497e-04]
 [ 7.21431321e-05]
 [-1.27864976e+00]
 [-1.09223343e+00]
 [ 1.58772091e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51731526]
 [1.51731526]
 [1.51731526]
 [1.51731526]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.20092876e+00]
 [ 1.18484486e-03]
 [ 3.39239325e-04]
 [-2.33593366e+00]
 [-2.30224411e+00]
 [ 4.47735930e-04]]
Epoch 62
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.61460225 -4.61460225 -4.61460225 -4.61460225]
 [ 2.07793365  2.07793365  2.07793365  2.07793365]
 [ 3.65603412  3.65603412  3.65603412  3.65603412]
 [-3.45609364 -3.45609364 -3.45609364 -3.45609364]
 [-3.66584078 -3.66584078 -3.66584078 -3.66584078]
 [ 3.08382665  3.08382665  3.08382665  3.08382665]]
Activation function: sigmoid
H1 matrix: 
 [[0.00980895 0.00980895 0.00980895 0.00980895]
 [0.88873987 0.88873987 0.88873987 0.88873987]
 [0.97481586 0.97481586 0.97481586 0.97481586]
 [0.03058765 0.03058765 0.03058765 0.03058765]
 [0.02494451 0.02494451 0.02494451 0.02494451]
 [0.95622066 0.95622066 0.95622066 0.95622066]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.14139566]
 [ 5.39517912]
 [ 5.91675114]
 [-2.15028921]
 [-2.15084939]
 [ 5.80400051]]
y_hat:
 [[0.10513801]
 [0.9954821 ]
 [0.9973133 ]
 [0.1043042 ]
 [0.10425188]
 [0.9969936 ]]
MSE Loss: 0.0054730815297965125
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.2464592  0.2464592  0.2464592  0.2464592 ]
 [1.64508624 1.64508624 1.64508624 1.64508624]
 [1.65598377 1.65598377 1.65598377 1.65598377]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.49618771e-01]
 [ 9.57873811e-04]
 [ 7.32157761e-05]
 [-1.28040346e+00]
 [-1.09367056e+00]
 [ 1.61061638e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51671101]
 [1.51671101]
 [1.51671101]
 [1.51671101]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.21082057e+00]
 [ 1.20516410e-03]
 [ 3.46438291e-04]
 [-2.34567826e+00]
 [-2.31197951e+00]
 [ 4.56747207e-04]]
Epoch 63
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.61817031 -4.61817031 -4.61817031 -4.61817031]
 [ 2.0799719   2.0799719   2.0799719   2.0799719 ]
 [ 3.65908132  3.65908132  3.65908132  3.65908132]
 [-3.4602321  -3.4602321  -3.4602321  -3.4602321 ]
 [-3.66962617 -3.66962617 -3.66962617 -3.66962617]
 [ 3.08647473  3.08647473  3.08647473  3.08647473]]
Activation function: sigmoid
H1 matrix: 
 [[0.00977436 0.00977436 0.00977436 0.00977436]
 [0.88894126 0.88894126 0.88894126 0.88894126]
 [0.97489056 0.97489056 0.97489056 0.97489056]
 [0.03046518 0.03046518 0.03046518 0.03046518]
 [0.0248526  0.0248526  0.0248526  0.0248526 ]
 [0.95633138 0.95633138 0.95633138 0.95633138]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.15152106]
 [ 5.39427315]
 [ 5.91485542]
 [-2.16085078]
 [-2.16120265]
 [ 5.80237009]]
y_hat:
 [[0.10418917]
 [0.99547802]
 [0.99730822]
 [0.1033216 ]
 [0.10328901]
 [0.99698871]]
MSE Loss: 0.005372686397174395
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24549595 0.24549595 0.24549595 0.24549595]
 [1.64588443 1.64588443 1.64588443 1.64588443]
 [1.6568019  1.6568019  1.6568019  1.6568019 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.50189785e-01]
 [ 9.70065883e-04]
 [ 7.42889394e-05]
 [-1.28211879e+00]
 [-1.09507714e+00]
 [ 1.63352172e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51612037]
 [1.51612037]
 [1.51612037]
 [1.51612037]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.22054494e+00]
 [ 1.22551993e-03]
 [ 3.53664492e-04]
 [-2.35525062e+00]
 [-2.32154618e+00]
 [ 4.65787783e-04]]
Epoch 64
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.62166256 -4.62166256 -4.62166256 -4.62166256]
 [ 2.08196688  2.08196688  2.08196688  2.08196688]
 [ 3.66206347  3.66206347  3.66206347  3.66206347]
 [-3.46428122 -3.46428122 -3.46428122 -3.46428122]
 [-3.6733309  -3.6733309  -3.6733309  -3.6733309 ]
 [ 3.08906631  3.08906631  3.08906631  3.08906631]]
Activation function: sigmoid
H1 matrix: 
 [[0.00974062 0.00974062 0.00974062 0.00974062]
 [0.88913806 0.88913806 0.88913806 0.88913806]
 [0.97496346 0.97496346 0.97496346 0.97496346]
 [0.03034581 0.03034581 0.03034581 0.03034581]
 [0.02476298 0.02476298 0.02476298 0.02476298]
 [0.95643948 0.95643948 0.95643948 0.95643948]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.16147315]
 [ 5.39338681]
 [ 5.91300147]
 [-2.17121905]
 [-2.17137157]
 [ 5.8007753 ]]
y_hat:
 [[0.10326396]
 [0.99547403]
 [0.99730323]
 [0.10236497]
 [0.10235095]
 [0.99698392]]
MSE Loss: 0.005275767003381363
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.244553   0.244553   0.244553   0.244553  ]
 [1.64666596 1.64666596 1.64666596 1.64666596]
 [1.65760283 1.65760283 1.65760283 1.65760283]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.50749145e-01]
 [ 9.82255748e-04]
 [ 7.53626080e-05]
 [-1.28379726e+00]
 [-1.09645434e+00]
 [ 1.65643669e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51554281]
 [1.51554281]
 [1.51554281]
 [1.51554281]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.23010723e+00]
 [ 1.24591164e-03]
 [ 3.60917428e-04]
 [-2.36465656e+00]
 [-2.33094969e+00]
 [ 4.74857110e-04]]
Epoch 65
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.62508188 -4.62508188 -4.62508188 -4.62508188]
 [ 2.08392024  2.08392024  2.08392024  2.08392024]
 [ 3.66498306  3.66498306  3.66498306  3.66498306]
 [-3.46824443 -3.46824443 -3.46824443 -3.46824443]
 [-3.67695802 -3.67695802 -3.67695802 -3.67695802]
 [ 3.09160355  3.09160355  3.09160355  3.09160355]]
Activation function: sigmoid
H1 matrix: 
 [[0.00970769 0.00970769 0.00970769 0.00970769]
 [0.88933046 0.88933046 0.88933046 0.88933046]
 [0.97503462 0.97503462 0.97503462 0.97503462]
 [0.0302294  0.0302294  0.0302294  0.0302294 ]
 [0.02467553 0.02467553 0.02467553 0.02467553]
 [0.95654507 0.95654507 0.95654507 0.95654507]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.17125756]
 [ 5.39251945]
 [ 5.91118777]
 [-2.18140074]
 [-2.18136239]
 [ 5.79921486]]
y_hat:
 [[0.10236143]
 [0.99547012]
 [0.99729835]
 [0.10143319]
 [0.10143668]
 [0.99697922]]
MSE Loss: 0.005182149588805826
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24362957 0.24362957 0.24362957 0.24362957]
 [1.64743146 1.64743146 1.64743146 1.64743146]
 [1.65838722 1.65838722 1.65838722 1.65838722]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.51297273e-01]
 [ 9.94443435e-04]
 [ 7.64367685e-05]
 [-1.28544026e+00]
 [-1.09780325e+00]
 [ 1.67936104e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51497786]
 [1.51497786]
 [1.51497786]
 [1.51497786]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.23951257e+00]
 [ 1.26633850e-03]
 [ 3.68196615e-04]
 [-2.37390164e+00]
 [-2.34019537e+00]
 [ 4.83954656e-04]]
Epoch 66
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.62843098 -4.62843098 -4.62843098 -4.62843098]
 [ 2.08583354  2.08583354  2.08583354  2.08583354]
 [ 3.66784243  3.66784243  3.66784243  3.66784243]
 [-3.47212497 -3.47212497 -3.47212497 -3.47212497]
 [-3.68051045 -3.68051045 -3.68051045 -3.68051045]
 [ 3.09408847  3.09408847  3.09408847  3.09408847]]
Activation function: sigmoid
H1 matrix: 
 [[0.00967555 0.00967555 0.00967555 0.00967555]
 [0.88951863 0.88951863 0.88951863 0.88951863]
 [0.97510413 0.97510413 0.97510413 0.97510413]
 [0.03011585 0.03011585 0.03011585 0.03011585]
 [0.02459018 0.02459018 0.02459018 0.02459018]
 [0.95664824 0.95664824 0.95664824 0.95664824]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.18087962]
 [ 5.39167045]
 [ 5.90941287]
 [-2.19140225]
 [-2.19118105]
 [ 5.79768756]]
y_hat:
 [[0.10148069]
 [0.99546629]
 [0.99729356]
 [0.10052523]
 [0.10054523]
 [0.99697462]]
MSE Loss: 0.005091671638405674
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24272495 0.24272495 0.24272495 0.24272495]
 [1.64818151 1.64818151 1.64818151 1.64818151]
 [1.65915567 1.65915567 1.65915567 1.65915567]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.51834569e-01]
 [ 1.00662897e-03]
 [ 7.75114080e-05]
 [-1.28704912e+00]
 [-1.09912490e+00]
 [ 1.70229453e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51442505]
 [1.51442505]
 [1.51442505]
 [1.51442505]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.24876582e+00]
 [ 1.28679985e-03]
 [ 3.75501582e-04]
 [-2.38299112e+00]
 [-2.34928827e+00]
 [ 4.93079909e-04]]
Epoch 67
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.63171244 -4.63171244 -4.63171244 -4.63171244]
 [ 2.08770825  2.08770825  2.08770825  2.08770825]
 [ 3.6706438   3.6706438   3.6706438   3.6706438 ]
 [-3.47592592 -3.47592592 -3.47592592 -3.47592592]
 [-3.68399093 -3.68399093 -3.68399093 -3.68399093]
 [ 3.09652301  3.09652301  3.09652301  3.09652301]]
Activation function: sigmoid
H1 matrix: 
 [[0.00964415 0.00964415 0.00964415 0.00964415]
 [0.88970273 0.88970273 0.88970273 0.88970273]
 [0.97517205 0.97517205 0.97517205 0.97517205]
 [0.03000503 0.03000503 0.03000503 0.03000503]
 [0.02450684 0.02450684 0.02450684 0.02450684]
 [0.95674909 0.95674909 0.95674909 0.95674909]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.19034442]
 [ 5.39083921]
 [ 5.9076754 ]
 [-2.20122966]
 [-2.20083319]
 [ 5.79619225]]
y_hat:
 [[0.10062092]
 [0.99546254]
 [0.99728887]
 [0.09964012]
 [0.09967569]
 [0.9969701 ]]
MSE Loss: 0.0050041809946617015
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24183845 0.24183845 0.24183845 0.24183845]
 [1.64891667 1.64891667 1.64891667 1.64891667]
 [1.65990876 1.65990876 1.65990876 1.65990876]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.52361413e-01]
 [ 1.01881238e-03]
 [ 7.85865137e-05]
 [-1.28862512e+00]
 [-1.10042028e+00]
 [ 1.72523692e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51388394]
 [1.51388394]
 [1.51388394]
 [1.51388394]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.25787164e+00]
 [ 1.30729501e-03]
 [ 3.82831873e-04]
 [-2.39193003e+00]
 [-2.35823321e+00]
 [ 5.02232367e-04]]
Epoch 68
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.63492869 -4.63492869 -4.63492869 -4.63492869]
 [ 2.08954578  2.08954578  2.08954578  2.08954578]
 [ 3.67338928  3.67338928  3.67338928  3.67338928]
 [-3.4796502  -3.4796502  -3.4796502  -3.4796502 ]
 [-3.68740205 -3.68740205 -3.68740205 -3.68740205]
 [ 3.098909    3.098909    3.098909    3.098909  ]]
Activation function: sigmoid
H1 matrix: 
 [[0.00961348 0.00961348 0.00961348 0.00961348]
 [0.88988292 0.88988292 0.88988292 0.88988292]
 [0.97523843 0.97523843 0.97523843 0.97523843]
 [0.02989682 0.02989682 0.02989682 0.02989682]
 [0.02442542 0.02442542 0.02442542 0.02442542]
 [0.95684772 0.95684772 0.95684772 0.95684772]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.19965685]
 [ 5.39002518]
 [ 5.90597406]
 [-2.21088875]
 [-2.21032418]
 [ 5.79472783]]
y_hat:
 [[0.09978131]
 [0.99545886]
 [0.99728427]
 [0.09877693]
 [0.0988272 ]
 [0.99696568]]
MSE Loss: 0.00491953505264837
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24096943 0.24096943 0.24096943 0.24096943]
 [1.64963747 1.64963747 1.64963747 1.64963747]
 [1.66064704 1.66064704 1.66064704 1.66064704]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.52878168e-01]
 [ 1.03099368e-03]
 [ 7.96620734e-05]
 [-1.29016945e+00]
 [-1.10169032e+00]
 [ 1.74818800e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51335413]
 [1.51335413]
 [1.51335413]
 [1.51335413]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.26683450e+00]
 [ 1.32782334e-03]
 [ 3.90187049e-04]
 [-2.40072316e+00]
 [-2.36703480e+00]
 [ 5.11411549e-04]]
Epoch 69
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.63808206 -4.63808206 -4.63808206 -4.63808206]
 [ 2.09134745  2.09134745  2.09134745  2.09134745]
 [ 3.67608085  3.67608085  3.67608085  3.67608085]
 [-3.48330057 -3.48330057 -3.48330057 -3.48330057]
 [-3.6907463  -3.6907463  -3.6907463  -3.6907463 ]
 [ 3.10124817  3.10124817  3.10124817  3.10124817]]
Activation function: sigmoid
H1 matrix: 
 [[0.00958351 0.00958351 0.00958351 0.00958351]
 [0.89005935 0.89005935 0.89005935 0.89005935]
 [0.97530335 0.97530335 0.97530335 0.97530335]
 [0.02979113 0.02979113 0.02979113 0.02979113]
 [0.02434586 0.02434586 0.02434586 0.02434586]
 [0.9569442  0.9569442  0.9569442  0.9569442 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.20882154]
 [ 5.3892278 ]
 [ 5.9043076 ]
 [-2.22038502]
 [-2.21965916]
 [ 5.79329327]]
y_hat:
 [[0.0989611 ]
 [0.99545525]
 [0.99727975]
 [0.09793478]
 [0.09799893]
 [0.99696133]]
MSE Loss: 0.004837600028532423
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.24011725 0.24011725 0.24011725 0.24011725]
 [1.65034441 1.65034441 1.65034441 1.65034441]
 [1.66137103 1.66137103 1.66137103 1.66137103]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.53385177e-01]
 [ 1.04317289e-03]
 [ 8.07380751e-05]
 [-1.29168323e+00]
 [-1.10293590e+00]
 [ 1.77114754e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51283523]
 [1.51283523]
 [1.51283523]
 [1.51283523]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.27565864e+00]
 [ 1.34838421e-03]
 [ 3.97566678e-04]
 [-2.40937507e+00]
 [-2.37569743e+00]
 [ 5.20616985e-04]]
Epoch 70
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.64117474 -4.64117474 -4.64117474 -4.64117474]
 [ 2.09311452  2.09311452  2.09311452  2.09311452]
 [ 3.67872042  3.67872042  3.67872042  3.67872042]
 [-3.48687964 -3.48687964 -3.48687964 -3.48687964]
 [-3.69402601 -3.69402601 -3.69402601 -3.69402601]
 [ 3.10354216  3.10354216  3.10354216  3.10354216]]
Activation function: sigmoid
H1 matrix: 
 [[0.0095542  0.0095542  0.0095542  0.0095542 ]
 [0.89023214 0.89023214 0.89023214 0.89023214]
 [0.97536685 0.97536685 0.97536685 0.97536685]
 [0.02968786 0.02968786 0.02968786 0.02968786]
 [0.02426808 0.02426808 0.02426808 0.02426808]
 [0.95703862 0.95703862 0.95703862 0.95703862]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.21784295]
 [ 5.38844657]
 [ 5.90267486]
 [-2.22972371]
 [-2.22884301]
 [ 5.79188756]]
y_hat:
 [[0.09815959]
 [0.99545172]
 [0.99727532]
 [0.09711286]
 [0.09719011]
 [0.99695707]]
MSE Loss: 0.004758250293840767
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23928135 0.23928135 0.23928135 0.23928135]
 [1.65103797 1.65103797 1.65103797 1.65103797]
 [1.66208123 1.66208123 1.66208123 1.66208123]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.53882767e-01]
 [ 1.05535004e-03]
 [ 8.18145070e-05]
 [-1.29316756e+00]
 [-1.10415786e+00]
 [ 1.79411533e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51232684]
 [1.51232684]
 [1.51232684]
 [1.51232684]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.28434815e+00]
 [ 1.36897700e-03]
 [ 4.04970347e-04]
 [-2.41789011e+00]
 [-2.38422530e+00]
 [ 5.29848219e-04]]
Epoch 71
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.64420882 -4.64420882 -4.64420882 -4.64420882]
 [ 2.0948482   2.0948482   2.0948482   2.0948482 ]
 [ 3.68130978  3.68130978  3.68130978  3.68130978]
 [-3.49038991 -3.49038991 -3.49038991 -3.49038991]
 [-3.69724341 -3.69724341 -3.69724341 -3.69724341]
 [ 3.10579255  3.10579255  3.10579255  3.10579255]]
Activation function: sigmoid
H1 matrix: 
 [[0.00952553 0.00952553 0.00952553 0.00952553]
 [0.89040144 0.89040144 0.89040144 0.89040144]
 [0.97542898 0.97542898 0.97542898 0.97542898]
 [0.02958691 0.02958691 0.02958691 0.02958691]
 [0.02419201 0.02419201 0.02419201 0.02419201]
 [0.95713105 0.95713105 0.95713105 0.95713105]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.22672531]
 [ 5.38768099]
 [ 5.90107472]
 [-2.23890982]
 [-2.23788039]
 [ 5.79050977]]
y_hat:
 [[0.09737609]
 [0.99544825]
 [0.99727097]
 [0.09631038]
 [0.09640002]
 [0.99695289]]
MSE Loss: 0.004681367768735068
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23846116 0.23846116 0.23846116 0.23846116]
 [1.6517186  1.6517186  1.6517186  1.6517186 ]
 [1.66277811 1.66277811 1.66277811 1.66277811]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.54371250e-01]
 [ 1.06752513e-03]
 [ 8.28913580e-05]
 [-1.29462345e+00]
 [-1.10535701e+00]
 [ 1.81709114e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51182864]
 [1.51182864]
 [1.51182864]
 [1.51182864]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.29290692e+00]
 [ 1.38960114e-03]
 [ 4.12397650e-04]
 [-2.42627246e+00]
 [-2.39262242e+00]
 [ 5.39104809e-04]]
Epoch 72
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.64718629 -4.64718629 -4.64718629 -4.64718629]
 [ 2.09654961  2.09654961  2.09654961  2.09654961]
 [ 3.68385066  3.68385066  3.68385066  3.68385066]
 [-3.49383375 -3.49383375 -3.49383375 -3.49383375]
 [-3.70040062 -3.70040062 -3.70040062 -3.70040062]
 [ 3.10800081  3.10800081  3.10800081  3.10800081]]
Activation function: sigmoid
H1 matrix: 
 [[0.00949748 0.00949748 0.00949748 0.00949748]
 [0.89056737 0.89056737 0.89056737 0.89056737]
 [0.97548981 0.97548981 0.97548981 0.97548981]
 [0.02948819 0.02948819 0.02948819 0.02948819]
 [0.02411759 0.02411759 0.02411759 0.02411759]
 [0.95722157 0.95722157 0.95722157 0.95722157]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.23547269]
 [ 5.38693059]
 [ 5.89950609]
 [-2.2479481 ]
 [-2.24677576]
 [ 5.78915901]]
y_hat:
 [[0.09660995]
 [0.99544485]
 [0.99726669]
 [0.0955266 ]
 [0.09562794]
 [0.99694878]]
MSE Loss: 0.0046068413683104424
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23765616 0.23765616 0.23765616 0.23765616]
 [1.65238674 1.65238674 1.65238674 1.65238674]
 [1.66346211 1.66346211 1.66346211 1.66346211]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.54850923e-01]
 [ 1.07969817e-03]
 [ 8.39686168e-05]
 [-1.29605187e+00]
 [-1.10653410e+00]
 [ 1.84007478e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51134026]
 [1.51134026]
 [1.51134026]
 [1.51134026]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.30133870e+00]
 [ 1.41025605e-03]
 [ 4.19848195e-04]
 [-2.43452608e+00]
 [-2.40089263e+00]
 [ 5.48386325e-04]]
Epoch 73
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.65010905 -4.65010905 -4.65010905 -4.65010905]
 [ 2.09821986  2.09821986  2.09821986  2.09821986]
 [ 3.68634467  3.68634467  3.68634467  3.68634467]
 [-3.4972134  -3.4972134  -3.4972134  -3.4972134 ]
 [-3.70349967 -3.70349967 -3.70349967 -3.70349967]
 [ 3.11016837  3.11016837  3.11016837  3.11016837]]
Activation function: sigmoid
H1 matrix: 
 [[0.00947002 0.00947002 0.00947002 0.00947002]
 [0.89073004 0.89073004 0.89073004 0.89073004]
 [0.97554937 0.97554937 0.97554937 0.97554937]
 [0.02939162 0.02939162 0.02939162 0.02939162]
 [0.02404476 0.02404476 0.02404476 0.02404476]
 [0.95731024 0.95731024 0.95731024 0.95731024]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.244089  ]
 [ 5.38619492]
 [ 5.89796798]
 [-2.25684311]
 [-2.25553338]
 [ 5.7878344 ]]
y_hat:
 [[0.09586056]
 [0.99544151]
 [0.9972625 ]
 [0.09476082]
 [0.09487323]
 [0.99694475]]
MSE Loss: 0.004534566496616287
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23686583 0.23686583 0.23686583 0.23686583]
 [1.65304279 1.65304279 1.65304279 1.65304279]
 [1.66413367 1.66413367 1.66413367 1.66413367]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.55322069e-01]
 [ 1.09186919e-03]
 [ 8.50462729e-05]
 [-1.29745375e+00]
 [-1.10768986e+00]
 [ 1.86306605e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5108614]
 [1.5108614]
 [1.5108614]
 [1.5108614]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.30964706e+00]
 [ 1.43094115e-03]
 [ 4.27321601e-04]
 [-2.44265478e+00]
 [-2.40903962e+00]
 [ 5.57692349e-04]]
Epoch 74
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.65297889 -4.65297889 -4.65297889 -4.65297889]
 [ 2.09985996  2.09985996  2.09985996  2.09985996]
 [ 3.68879338  3.68879338  3.68879338  3.68879338]
 [-3.50053101 -3.50053101 -3.50053101 -3.50053101]
 [-3.70654247 -3.70654247 -3.70654247 -3.70654247]
 [ 3.11229657  3.11229657  3.11229657  3.11229657]]
Activation function: sigmoid
H1 matrix: 
 [[0.00944314 0.00944314 0.00944314 0.00944314]
 [0.89088957 0.89088957 0.89088957 0.89088957]
 [0.97560771 0.97560771 0.97560771 0.97560771]
 [0.02929713 0.02929713 0.02929713 0.02929713]
 [0.02397346 0.02397346 0.02397346 0.02397346]
 [0.95739713 0.95739713 0.95739713 0.95739713]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.25257796]
 [ 5.38547356]
 [ 5.89645941]
 [-2.26559919]
 [-2.26415732]
 [ 5.78653513]]
y_hat:
 [[0.09512733]
 [0.99543824]
 [0.99725838]
 [0.09401238]
 [0.09413526]
 [0.99694079]]
MSE Loss: 0.004464444583692243
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23608969 0.23608969 0.23608969 0.23608969]
 [1.65368716 1.65368716 1.65368716 1.65368716]
 [1.66479318 1.66479318 1.66479318 1.66479318]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.55784960e-01]
 [ 1.10403819e-03]
 [ 8.61243155e-05]
 [-1.29882997e+00]
 [-1.10882499e+00]
 [ 1.88606474e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.51039174]
 [1.51039174]
 [1.51039174]
 [1.51039174]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.31783544e+00]
 [ 1.45165592e-03]
 [ 4.34817496e-04]
 [-2.45066219e+00]
 [-2.41706689e+00]
 [ 5.67022476e-04]]
Epoch 75
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.65579754 -4.65579754 -4.65579754 -4.65579754]
 [ 2.10147091  2.10147091  2.10147091  2.10147091]
 [ 3.69119825  3.69119825  3.69119825  3.69119825]
 [-3.50378862 -3.50378862 -3.50378862 -3.50378862]
 [-3.70953085 -3.70953085 -3.70953085 -3.70953085]
 [ 3.1143867   3.1143867   3.1143867   3.1143867 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.00941681 0.00941681 0.00941681 0.00941681]
 [0.89104606 0.89104606 0.89104606 0.89104606]
 [0.97566487 0.97566487 0.97566487 0.97566487]
 [0.02920463 0.02920463 0.02920463 0.02920463]
 [0.02390363 0.02390363 0.02390363 0.02390363]
 [0.9574823  0.9574823  0.9574823  0.9574823 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.26094315]
 [ 5.38476608]
 [ 5.89497946]
 [-2.2742205 ]
 [-2.27265149]
 [ 5.78526042]]
y_hat:
 [[0.0944097 ]
 [0.99543502]
 [0.99725433]
 [0.09328063]
 [0.09341342]
 [0.9969369 ]]
MSE Loss: 0.004396382661433462
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.2353273  0.2353273  0.2353273  0.2353273 ]
 [1.65432021 1.65432021 1.65432021 1.65432021]
 [1.66544105 1.66544105 1.66544105 1.66544105]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.56239853e-01]
 [ 1.11620518e-03]
 [ 8.72027347e-05]
 [-1.30018137e+00]
 [-1.10994014e+00]
 [ 1.90907067e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50993099]
 [1.50993099]
 [1.50993099]
 [1.50993099]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.32590714e+00]
 [ 1.47239982e-03]
 [ 4.42335520e-04]
 [-2.45855181e+00]
 [-2.42497782e+00]
 [ 5.76376310e-04]]
Epoch 76
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.65856664 -4.65856664 -4.65856664 -4.65856664]
 [ 2.10305363  2.10305363  2.10305363  2.10305363]
 [ 3.69356071  3.69356071  3.69356071  3.69356071]
 [-3.50698818 -3.50698818 -3.50698818 -3.50698818]
 [-3.71246656 -3.71246656 -3.71246656 -3.71246656]
 [ 3.11643999  3.11643999  3.11643999  3.11643999]]
Activation function: sigmoid
H1 matrix: 
 [[0.00939101 0.00939101 0.00939101 0.00939101]
 [0.89119962 0.89119962 0.89119962 0.89119962]
 [0.9757209  0.9757209  0.9757209  0.9757209 ]
 [0.02911405 0.02911405 0.02911405 0.02911405]
 [0.02383523 0.02383523 0.02383523 0.02383523]
 [0.95756581 0.95756581 0.95756581 0.95756581]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.26918801]
 [ 5.3840721 ]
 [ 5.89352723]
 [-2.28271099]
 [-2.2810196 ]
 [ 5.78400952]]
y_hat:
 [[0.09370715]
 [0.99543187]
 [0.99725035]
 [0.09256499]
 [0.09270716]
 [0.99693308]]
MSE Loss: 0.00433029297455661
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23457821 0.23457821 0.23457821 0.23457821]
 [1.65494231 1.65494231 1.65494231 1.65494231]
 [1.66607763 1.66607763 1.66607763 1.66607763]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.56686996e-01]
 [ 1.12837016e-03]
 [ 8.82815203e-05]
 [-1.30150876e+00]
 [-1.11103595e+00]
 [ 1.93208365e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50947887]
 [1.50947887]
 [1.50947887]
 [1.50947887]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.33386532e+00]
 [ 1.49317233e-03]
 [ 4.49875321e-04]
 [-2.46632696e+00]
 [-2.43277566e+00]
 [ 5.85753467e-04]]
Epoch 77
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.66128776 -4.66128776 -4.66128776 -4.66128776]
 [ 2.10460904  2.10460904  2.10460904  2.10460904]
 [ 3.6958821   3.6958821   3.6958821   3.6958821 ]
 [-3.51013154 -3.51013154 -3.51013154 -3.51013154]
 [-3.71535127 -3.71535127 -3.71535127 -3.71535127]
 [ 3.1184576   3.1184576   3.1184576   3.1184576 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.00936573 0.00936573 0.00936573 0.00936573]
 [0.89135035 0.89135035 0.89135035 0.89135035]
 [0.97577583 0.97577583 0.97577583 0.97577583]
 [0.02902533 0.02902533 0.02902533 0.02902533]
 [0.02376821 0.02376821 0.02376821 0.02376821]
 [0.95764771 0.95764771 0.95764771 0.95764771]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.27731581]
 [ 5.38339123]
 [ 5.89210189]
 [-2.29107448]
 [-2.28926524]
 [ 5.78278172]]
y_hat:
 [[0.09301916]
 [0.99542877]
 [0.99724644]
 [0.09186487]
 [0.09201592]
 [0.99692932]]
MSE Loss: 0.00426609262334021
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.233842   0.233842   0.233842   0.233842  ]
 [1.65555378 1.65555378 1.65555378 1.65555378]
 [1.66670328 1.66670328 1.66670328 1.66670328]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.57126623e-01]
 [ 1.14053314e-03]
 [ 8.93606627e-05]
 [-1.30281289e+00]
 [-1.11211301e+00]
 [ 1.95510350e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50903512]
 [1.50903512]
 [1.50903512]
 [1.50903512]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.34171303e+00]
 [ 1.51397295e-03]
 [ 4.57436557e-04]
 [-2.47399086e+00]
 [-2.44046349e+00]
 [ 5.95153573e-04]]
Epoch 78
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.66396238 -4.66396238 -4.66396238 -4.66396238]
 [ 2.10613798  2.10613798  2.10613798  2.10613798]
 [ 3.6981637   3.6981637   3.6981637   3.6981637 ]
 [-3.51322048 -3.51322048 -3.51322048 -3.51322048]
 [-3.71818658 -3.71818658 -3.71818658 -3.71818658]
 [ 3.12044065  3.12044065  3.12044065  3.12044065]]
Activation function: sigmoid
H1 matrix: 
 [[0.00934095 0.00934095 0.00934095 0.00934095]
 [0.89149833 0.89149833 0.89149833 0.89149833]
 [0.97582971 0.97582971 0.97582971 0.97582971]
 [0.0289384  0.0289384  0.0289384  0.0289384 ]
 [0.02370251 0.02370251 0.02370251 0.02370251]
 [0.95772807 0.95772807 0.95772807 0.95772807]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.28532974]
 [ 5.38272312]
 [ 5.89070262]
 [-2.29931461]
 [-2.29739184]
 [ 5.78157633]]
y_hat:
 [[0.09234526]
 [0.99542573]
 [0.99724259]
 [0.09117974]
 [0.0913392 ]
 [0.99692563]]
MSE Loss: 0.004203703235166845
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23311828 0.23311828 0.23311828 0.23311828]
 [1.65615497 1.65615497 1.65615497 1.65615497]
 [1.66731834 1.66731834 1.66731834 1.66731834]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.57558962e-01]
 [ 1.15269414e-03]
 [ 9.04401523e-05]
 [-1.30409450e+00]
 [-1.11317190e+00]
 [ 1.97813003e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50859948]
 [1.50859948]
 [1.50859948]
 [1.50859948]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.34945319e+00]
 [ 1.53480120e-03]
 [ 4.65018896e-04]
 [-2.48154656e+00]
 [-2.44804431e+00]
 [ 6.04576262e-04]]
Epoch 79
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.66659194 -4.66659194 -4.66659194 -4.66659194]
 [ 2.10764127  2.10764127  2.10764127  2.10764127]
 [ 3.70040674  3.70040674  3.70040674  3.70040674]
 [-3.51625669 -3.51625669 -3.51625669 -3.51625669]
 [-3.720974   -3.720974   -3.720974   -3.720974  ]
 [ 3.12239021  3.12239021  3.12239021  3.12239021]]
Activation function: sigmoid
H1 matrix: 
 [[0.00931665 0.00931665 0.00931665 0.00931665]
 [0.89164365 0.89164365 0.89164365 0.89164365]
 [0.97588255 0.97588255 0.97588255 0.97588255]
 [0.0288532  0.0288532  0.0288532  0.0288532 ]
 [0.02363809 0.02363809 0.02363809 0.02363809]
 [0.95780693 0.95780693 0.95780693 0.95780693]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.29323282]
 [ 5.3820674 ]
 [ 5.88932866]
 [-2.30743486]
 [-2.30540268]
 [ 5.7803927 ]]
y_hat:
 [[0.09168497]
 [0.99542274]
 [0.99723881]
 [0.09050908]
 [0.0906765 ]
 [0.996922  ]]
MSE Loss: 0.004143050662207245
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23240666 0.23240666 0.23240666 0.23240666]
 [1.65674619 1.65674619 1.65674619 1.65674619]
 [1.66792313 1.66792313 1.66792313 1.66792313]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.57984229e-01]
 [ 1.16485314e-03]
 [ 9.15199800e-05]
 [-1.30535428e+00]
 [-1.11421318e+00]
 [ 2.00116307e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5081717]
 [1.5081717]
 [1.5081717]
 [1.5081717]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.35708861e+00]
 [ 1.55565659e-03]
 [ 4.72622012e-04]
 [-2.48899701e+00]
 [-2.45552098e+00]
 [ 6.14021181e-04]]
Epoch 80
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.6691778  -4.6691778  -4.6691778  -4.6691778 ]
 [ 2.10911969  2.10911969  2.10911969  2.10911969]
 [ 3.70261241  3.70261241  3.70261241  3.70261241]
 [-3.51924179 -3.51924179 -3.51924179 -3.51924179]
 [-3.72371499 -3.72371499 -3.72371499 -3.72371499]
 [ 3.1243073   3.1243073   3.1243073   3.1243073 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.00929281 0.00929281 0.00929281 0.00929281]
 [0.89178641 0.89178641 0.89178641 0.89178641]
 [0.97593441 0.97593441 0.97593441 0.97593441]
 [0.02876967 0.02876967 0.02876967 0.02876967]
 [0.02357491 0.02357491 0.02357491 0.02357491]
 [0.95788434 0.95788434 0.95788434 0.95788434]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.30102798]
 [ 5.38142375]
 [ 5.88797926]
 [-2.31543857]
 [-2.31330093]
 [ 5.77923021]]
y_hat:
 [[0.09103786]
 [0.99541981]
 [0.99723509]
 [0.08985239]
 [0.09002736]
 [0.99691843]]
MSE Loss: 0.004084064702862274
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23170677 0.23170677 0.23170677 0.23170677]
 [1.65732772 1.65732772 1.65732772 1.65732772]
 [1.66851796 1.66851796 1.66851796 1.66851796]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.58402631e-01]
 [ 1.17701016e-03]
 [ 9.26001367e-05]
 [-1.30659290e+00]
 [-1.11523736e+00]
 [ 2.02420245e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50775155]
 [1.50775155]
 [1.50775155]
 [1.50775155]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.36462199e+00]
 [ 1.57653866e-03]
 [ 4.80245590e-04]
 [-2.49634504e+00]
 [-2.46289624e+00]
 [ 6.23487983e-04]]
Epoch 81
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.67172128 -4.67172128 -4.67172128 -4.67172128]
 [ 2.11057399  2.11057399  2.11057399  2.11057399]
 [ 3.70478181  3.70478181  3.70478181  3.70478181]
 [-3.52217733 -3.52217733 -3.52217733 -3.52217733]
 [-3.72641094 -3.72641094 -3.72641094 -3.72641094]
 [ 3.12619289  3.12619289  3.12619289  3.12619289]]
Activation function: sigmoid
H1 matrix: 
 [[0.00926942 0.00926942 0.00926942 0.00926942]
 [0.89192667 0.89192667 0.89192667 0.89192667]
 [0.97598531 0.97598531 0.97598531 0.97598531]
 [0.02868776 0.02868776 0.02868776 0.02868776]
 [0.02351293 0.02351293 0.02351293 0.02351293]
 [0.95796034 0.95796034 0.95796034 0.95796034]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.30871803]
 [ 5.38079185]
 [ 5.88665371]
 [-2.32332897]
 [-2.3210896 ]
 [ 5.77808824]]
y_hat:
 [[0.09040351]
 [0.99541693]
 [0.99723143]
 [0.08920921]
 [0.08939133]
 [0.99691492]]
MSE Loss: 0.004026678844823103
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23101828 0.23101828 0.23101828 0.23101828]
 [1.65789986 1.65789986 1.65789986 1.65789986]
 [1.66910313 1.66910313 1.66910313 1.66910313]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.58814365e-01]
 [ 1.18916519e-03]
 [ 9.36806136e-05]
 [-1.30781100e+00]
 [-1.11624495e+00]
 [ 2.04724800e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50733881]
 [1.50733881]
 [1.50733881]
 [1.50733881]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.37205593e+00]
 [ 1.59744696e-03]
 [ 4.87889322e-04]
 [-2.50359337e+00]
 [-2.47017274e+00]
 [ 6.32976332e-04]]
Epoch 82
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.67422362 -4.67422362 -4.67422362 -4.67422362]
 [ 2.11200489  2.11200489  2.11200489  2.11200489]
 [ 3.70691603  3.70691603  3.70691603  3.70691603]
 [-3.52506479 -3.52506479 -3.52506479 -3.52506479]
 [-3.72906319 -3.72906319 -3.72906319 -3.72906319]
 [ 3.12804792  3.12804792  3.12804792  3.12804792]]
Activation function: sigmoid
H1 matrix: 
 [[0.00924647 0.00924647 0.00924647 0.00924647]
 [0.89206453 0.89206453 0.89206453 0.89206453]
 [0.97603528 0.97603528 0.97603528 0.97603528]
 [0.02860741 0.02860741 0.02860741 0.02860741]
 [0.02345211 0.02345211 0.02345211 0.02345211]
 [0.95803498 0.95803498 0.95803498 0.95803498]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.31630566]
 [ 5.38017138]
 [ 5.88535133]
 [-2.33110911]
 [-2.32877162]
 [ 5.77696622]]
y_hat:
 [[0.08978151]
 [0.9954141 ]
 [0.99722784]
 [0.08857908]
 [0.08876797]
 [0.99691147]]
MSE Loss: 0.003970830027826502
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.23034083 0.23034083 0.23034083 0.23034083]
 [1.65846289 1.65846289 1.65846289 1.65846289]
 [1.66967892 1.66967892 1.66967892 1.66967892]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.59219624e-01]
 [ 1.20131823e-03]
 [ 9.47614021e-05]
 [-1.30900919e+00]
 [-1.11723644e+00]
 [ 2.07029956e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50693326]
 [1.50693326]
 [1.50693326]
 [1.50693326]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.37939295e+00]
 [ 1.61838104e-03]
 [ 4.95552907e-04]
 [-2.51074461e+00]
 [-2.47735302e+00]
 [ 6.42485897e-04]]
Epoch 83
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.67668603 -4.67668603 -4.67668603 -4.67668603]
 [ 2.11341307  2.11341307  2.11341307  2.11341307]
 [ 3.7090161   3.7090161   3.7090161   3.7090161 ]
 [-3.52790558 -3.52790558 -3.52790558 -3.52790558]
 [-3.73167301 -3.73167301 -3.73167301 -3.73167301]
 [ 3.12987329  3.12987329  3.12987329  3.12987329]]
Activation function: sigmoid
H1 matrix: 
 [[0.00922394 0.00922394 0.00922394 0.00922394]
 [0.89220004 0.89220004 0.89220004 0.89220004]
 [0.97608435 0.97608435 0.97608435 0.97608435]
 [0.02852858 0.02852858 0.02852858 0.02852858]
 [0.02339242 0.02339242 0.02339242 0.02339242]
 [0.95810831 0.95810831 0.95810831 0.95810831]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.32379349]
 [ 5.37956205]
 [ 5.88407147]
 [-2.33878197]
 [-2.33634978]
 [ 5.7758636 ]]
y_hat:
 [[0.08917147]
 [0.99541131]
 [0.9972243 ]
 [0.08796158]
 [0.0881569 ]
 [0.99690807]]
MSE Loss: 0.0039164584243745445
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22967413 0.22967413 0.22967413 0.22967413]
 [1.65901705 1.65901705 1.65901705 1.65901705]
 [1.6702456  1.6702456  1.6702456  1.6702456 ]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.59618588e-01]
 [ 1.21346930e-03]
 [ 9.58424937e-05]
 [-1.31018805e+00]
 [-1.11821229e+00]
 [ 2.09335697e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5065347]
 [1.5065347]
 [1.5065347]
 [1.5065347]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.38663545e+00]
 [ 1.63934047e-03]
 [ 5.03236051e-04]
 [-2.51780127e+00]
 [-2.48443954e+00]
 [ 6.52016359e-04]]
Epoch 84
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.67910965 -4.67910965 -4.67910965 -4.67910965]
 [ 2.11479919  2.11479919  2.11479919  2.11479919]
 [ 3.71108301  3.71108301  3.71108301  3.71108301]
 [-3.53070107 -3.53070107 -3.53070107 -3.53070107]
 [-3.73424162 -3.73424162 -3.73424162 -3.73424162]
 [ 3.13166986  3.13166986  3.13166986  3.13166986]]
Activation function: sigmoid
H1 matrix: 
 [[0.00920182 0.00920182 0.00920182 0.00920182]
 [0.89233328 0.89233328 0.89233328 0.89233328]
 [0.97613256 0.97613256 0.97613256 0.97613256]
 [0.0284512  0.0284512  0.0284512  0.0284512 ]
 [0.02333381 0.02333381 0.02333381 0.02333381]
 [0.95818036 0.95818036 0.95818036 0.95818036]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.33118401]
 [ 5.37896356]
 [ 5.88281351]
 [-2.34635038]
 [-2.34382677]
 [ 5.77477985]]
y_hat:
 [[0.08857303]
 [0.99540858]
 [0.99722081]
 [0.0873563 ]
 [0.08755771]
 [0.99690473]]
MSE Loss: 0.00386350723685888
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22901784 0.22901784 0.22901784 0.22901784]
 [1.65956262 1.65956262 1.65956262 1.65956262]
 [1.67080343 1.67080343 1.67080343 1.67080343]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.60011435e-01]
 [ 1.22561838e-03]
 [ 9.69238802e-05]
 [-1.31134815e+00]
 [-1.11917294e+00]
 [ 2.11642007e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50614293]
 [1.50614293]
 [1.50614293]
 [1.50614293]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.39378576e+00]
 [ 1.66032483e-03]
 [ 5.10938470e-04]
 [-2.52476577e+00]
 [-2.49143464e+00]
 [ 6.61567405e-04]]
Epoch 85
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.68149558 -4.68149558 -4.68149558 -4.68149558]
 [ 2.11616388  2.11616388  2.11616388  2.11616388]
 [ 3.7131177   3.7131177   3.7131177   3.7131177 ]
 [-3.53345255 -3.53345255 -3.53345255 -3.53345255]
 [-3.73677021 -3.73677021 -3.73677021 -3.73677021]
 [ 3.13343844  3.13343844  3.13343844  3.13343844]]
Activation function: sigmoid
H1 matrix: 
 [[0.00918009 0.00918009 0.00918009 0.00918009]
 [0.89246432 0.89246432 0.89246432 0.89246432]
 [0.97617991 0.97617991 0.97617991 0.97617991]
 [0.02837525 0.02837525 0.02837525 0.02837525]
 [0.02327625 0.02327625 0.02327625 0.02327625]
 [0.95825117 0.95825117 0.95825117 0.95825117]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.33847964]
 [ 5.37837566]
 [ 5.88157684]
 [-2.35381707]
 [-2.35120519]
 [ 5.77371446]]
y_hat:
 [[0.08798584]
 [0.99540589]
 [0.99721738]
 [0.08676285]
 [0.08697003]
 [0.99690144]]
MSE Loss: 0.0038119225096822037
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22837169 0.22837169 0.22837169 0.22837169]
 [1.66009982 1.66009982 1.66009982 1.66009982]
 [1.67135267 1.67135267 1.67135267 1.67135267]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.60398332e-01]
 [ 1.23776548e-03]
 [ 9.80055537e-05]
 [-1.31249002e+00]
 [-1.12011882e+00]
 [ 2.13948870e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50575776]
 [1.50575776]
 [1.50575776]
 [1.50575776]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.40084612e+00]
 [ 1.68133371e-03]
 [ 5.18659883e-04]
 [-2.53164043e+00]
 [-2.49834061e+00]
 [ 6.71138729e-04]]
Epoch 86
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.6838449  -4.6838449  -4.6838449  -4.6838449 ]
 [ 2.11750774  2.11750774  2.11750774  2.11750774]
 [ 3.71512108  3.71512108  3.71512108  3.71512108]
 [-3.53616129 -3.53616129 -3.53616129 -3.53616129]
 [-3.7392599  -3.7392599  -3.7392599  -3.7392599 ]
 [ 3.13517982  3.13517982  3.13517982  3.13517982]]
Activation function: sigmoid
H1 matrix: 
 [[0.00915875 0.00915875 0.00915875 0.00915875]
 [0.89259323 0.89259323 0.89259323 0.89259323]
 [0.97622645 0.97622645 0.97622645 0.97622645]
 [0.02830066 0.02830066 0.02830066 0.02830066]
 [0.02321972 0.02321972 0.02321972 0.02321972]
 [0.95832078 0.95832078 0.95832078 0.95832078]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.3456827 ]
 [ 5.37779806]
 [ 5.88036089]
 [-2.36118467]
 [-2.35848752]
 [ 5.77266693]]
y_hat:
 [[0.08740955]
 [0.99540325]
 [0.99721401]
 [0.08618085]
 [0.0863935 ]
 [0.9968982 ]]
MSE Loss: 0.003761652955105216
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22773539 0.22773539 0.22773539 0.22773539]
 [1.66062889 1.66062889 1.66062889 1.66062889]
 [1.67189354 1.67189354 1.67189354 1.67189354]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.60779440e-01]
 [ 1.24991059e-03]
 [ 9.90875062e-05]
 [-1.31361417e+00]
 [-1.12105033e+00]
 [ 2.16256272e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50537901]
 [1.50537901]
 [1.50537901]
 [1.50537901]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.40781871e+00]
 [ 1.70236670e-03]
 [ 5.26400018e-04]
 [-2.53842749e+00]
 [-2.50515961e+00]
 [ 6.80730033e-04]]
Epoch 87
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.6861586  -4.6861586  -4.6861586  -4.6861586 ]
 [ 2.11883135  2.11883135  2.11883135  2.11883135]
 [ 3.71709402  3.71709402  3.71709402  3.71709402]
 [-3.53882847 -3.53882847 -3.53882847 -3.53882847]
 [-3.74171176 -3.74171176 -3.74171176 -3.74171176]
 [ 3.13689477  3.13689477  3.13689477  3.13689477]]
Activation function: sigmoid
H1 matrix: 
 [[0.00913777 0.00913777 0.00913777 0.00913777]
 [0.89272006 0.89272006 0.89272006 0.89272006]
 [0.9762722  0.9762722  0.9762722  0.9762722 ]
 [0.02822741 0.02822741 0.02822741 0.02822741]
 [0.02316417 0.02316417 0.02316417 0.02316417]
 [0.95838922 0.95838922 0.95838922 0.95838922]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.35279545]
 [ 5.37723051]
 [ 5.87916509]
 [-2.36845571]
 [-2.36567617]
 [ 5.7716368 ]]
y_hat:
 [[0.08684383]
 [0.99540065]
 [0.99721068]
 [0.08560995]
 [0.08582779]
 [0.99689502]]
MSE Loss: 0.003712649791668791
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22710866 0.22710866 0.22710866 0.22710866]
 [1.66115006 1.66115006 1.66115006 1.66115006]
 [1.67242628 1.67242628 1.67242628 1.67242628]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.61154917e-01]
 [ 1.26205371e-03]
 [ 1.00169730e-04]
 [-1.31472110e+00]
 [-1.12196788e+00]
 [ 2.18564198e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.5050065]
 [1.5050065]
 [1.5050065]
 [1.5050065]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.41470559e+00]
 [ 1.72342342e-03]
 [ 5.34158609e-04]
 [-2.54512911e+00]
 [-2.51189378e+00]
 [ 6.90341026e-04]]
Epoch 88
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.68843767 -4.68843767 -4.68843767 -4.68843767]
 [ 2.12013528  2.12013528  2.12013528  2.12013528]
 [ 3.71903737  3.71903737  3.71903737  3.71903737]
 [-3.54145525 -3.54145525 -3.54145525 -3.54145525]
 [-3.74412684 -3.74412684 -3.74412684 -3.74412684]
 [ 3.13858401  3.13858401  3.13858401  3.13858401]]
Activation function: sigmoid
H1 matrix: 
 [[0.00911716 0.00911716 0.00911716 0.00911716]
 [0.89284487 0.89284487 0.89284487 0.89284487]
 [0.97631717 0.97631717 0.97631717 0.97631717]
 [0.02815544 0.02815544 0.02815544 0.02815544]
 [0.02310959 0.02310959 0.02310959 0.02310959]
 [0.95845654 0.95845654 0.95845654 0.95845654]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.35982004]
 [ 5.37667277]
 [ 5.87798893]
 [-2.37563263]
 [-2.37277346]
 [ 5.7706236 ]]
y_hat:
 [[0.08628838]
 [0.9953981 ]
 [0.99720741]
 [0.0850498 ]
 [0.08527256]
 [0.99689188]]
MSE Loss: 0.0036648665941494216
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22649125 0.22649125 0.22649125 0.22649125]
 [1.66166353 1.66166353 1.66166353 1.66166353]
 [1.67295112 1.67295112 1.67295112 1.67295112]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.61524910e-01]
 [ 1.27419484e-03]
 [ 1.01252218e-04]
 [-1.31581129e+00]
 [-1.12287184e+00]
 [ 2.20872633e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50464007]
 [1.50464007]
 [1.50464007]
 [1.50464007]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.42150880e+00]
 [ 1.74450348e-03]
 [ 5.41935395e-04]
 [-2.55174738e+00]
 [-2.51854514e+00]
 [ 6.99971423e-04]]
Epoch 89
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.69068305 -4.69068305 -4.69068305 -4.69068305]
 [ 2.12142004  2.12142004  2.12142004  2.12142004]
 [ 3.72095192  3.72095192  3.72095192  3.72095192]
 [-3.54404273 -3.54404273 -3.54404273 -3.54404273]
 [-3.74650613 -3.74650613 -3.74650613 -3.74650613]
 [ 3.14024823  3.14024823  3.14024823  3.14024823]]
Activation function: sigmoid
H1 matrix: 
 [[0.0090969  0.0090969  0.0090969  0.0090969 ]
 [0.89296773 0.89296773 0.89296773 0.89296773]
 [0.9763614  0.9763614  0.9763614  0.9763614 ]
 [0.02808473 0.02808473 0.02808473 0.02808473]
 [0.02305594 0.02305594 0.02305594 0.02305594]
 [0.95852275 0.95852275 0.95852275 0.95852275]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.36675856]
 [ 5.37612459]
 [ 5.87683188]
 [-2.38271776]
 [-2.3797816 ]
 [ 5.76962692]]
y_hat:
 [[0.0857429 ]
 [0.99539558]
 [0.99720418]
 [0.08450008]
 [0.0847275 ]
 [0.99688879]]
MSE Loss: 0.0036182591541032275
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22588291 0.22588291 0.22588291 0.22588291]
 [1.66216952 1.66216952 1.66216952 1.66216952]
 [1.67346826 1.67346826 1.67346826 1.67346826]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.61889565e-01]
 [ 1.28633398e-03]
 [ 1.02334962e-04]
 [-1.31688519e+00]
 [-1.12376256e+00]
 [ 2.23181564e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50427955]
 [1.50427955]
 [1.50427955]
 [1.50427955]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.42823028e+00]
 [ 1.76560650e-03]
 [ 5.49730123e-04]
 [-2.55828429e+00]
 [-2.52511565e+00]
 [ 7.09620946e-04]]
Epoch 90
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.69289563 -4.69289563 -4.69289563 -4.69289563]
 [ 2.12268617  2.12268617  2.12268617  2.12268617]
 [ 3.72283845  3.72283845  3.72283845  3.72283845]
 [-3.54659198 -3.54659198 -3.54659198 -3.54659198]
 [-3.7488506  -3.7488506  -3.7488506  -3.7488506 ]
 [ 3.14188812  3.14188812  3.14188812  3.14188812]]
Activation function: sigmoid
H1 matrix: 
 [[0.00907698 0.00907698 0.00907698 0.00907698]
 [0.89308868 0.89308868 0.89308868 0.89308868]
 [0.9764049  0.9764049  0.9764049  0.9764049 ]
 [0.02801523 0.02801523 0.02801523 0.02801523]
 [0.02300319 0.02300319 0.02300319 0.02300319]
 [0.9585879  0.9585879  0.9585879  0.9585879 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.37361303]
 [ 5.37558576]
 [ 5.87569345]
 [-2.38971336]
 [-2.38670275]
 [ 5.76864631]]
y_hat:
 [[0.08520709]
 [0.99539311]
 [0.99720101]
 [0.08396048]
 [0.08419231]
 [0.99688575]]
MSE Loss: 0.003572785350140896
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22528338 0.22528338 0.22528338 0.22528338]
 [1.66266821 1.66266821 1.66266821 1.66266821]
 [1.67397791 1.67397791 1.67397791 1.67397791]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.62249020e-01]
 [ 1.29847111e-03]
 [ 1.03417956e-04]
 [-1.31794324e+00]
 [-1.12464041e+00]
 [ 2.25490976e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50392479]
 [1.50392479]
 [1.50392479]
 [1.50392479]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.43487190e+00]
 [ 1.78673212e-03]
 [ 5.57542545e-04]
 [-2.56474178e+00]
 [-2.53160721e+00]
 [ 7.19289325e-04]]
Epoch 91
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.69507629 -4.69507629 -4.69507629 -4.69507629]
 [ 2.12393416  2.12393416  2.12393416  2.12393416]
 [ 3.7246977   3.7246977   3.7246977   3.7246977 ]
 [-3.54910402 -3.54910402 -3.54910402 -3.54910402]
 [-3.75116117 -3.75116117 -3.75116117 -3.75116117]
 [ 3.14350432  3.14350432  3.14350432  3.14350432]]
Activation function: sigmoid
H1 matrix: 
 [[0.00905738 0.00905738 0.00905738 0.00905738]
 [0.89320778 0.89320778 0.89320778 0.89320778]
 [0.9764477  0.9764477  0.9764477  0.9764477 ]
 [0.0279469  0.0279469  0.0279469  0.0279469 ]
 [0.02295132 0.02295132 0.02295132 0.02295132]
 [0.95865201 0.95865201 0.95865201 0.95865201]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.38038541]
 [ 5.37505604]
 [ 5.87457316]
 [-2.39662162]
 [-2.39353899]
 [ 5.76768139]]
y_hat:
 [[0.08468069]
 [0.99539068]
 [0.99719788]
 [0.08343068]
 [0.08366671]
 [0.99688275]]
MSE Loss: 0.00352840502715406
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22469245 0.22469245 0.22469245 0.22469245]
 [1.66315981 1.66315981 1.66315981 1.66315981]
 [1.67448026 1.67448026 1.67448026 1.67448026]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.62603407e-01]
 [ 1.31060625e-03]
 [ 1.04501192e-04]
 [-1.31898586e+00]
 [-1.12550571e+00]
 [ 2.27800855e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50357565]
 [1.50357565]
 [1.50357565]
 [1.50357565]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.44143549e+00]
 [ 1.80787997e-03]
 [ 5.65372416e-04]
 [-2.57112173e+00]
 [-2.53802165e+00]
 [ 7.28976292e-04]]
Epoch 92
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.69722586 -4.69722586 -4.69722586 -4.69722586]
 [ 2.12516448  2.12516448  2.12516448  2.12516448]
 [ 3.7265304   3.7265304   3.7265304   3.7265304 ]
 [-3.55157982 -3.55157982 -3.55157982 -3.55157982]
 [-3.75343872 -3.75343872 -3.75343872 -3.75343872]
 [ 3.14509745  3.14509745  3.14509745  3.14509745]]
Activation function: sigmoid
H1 matrix: 
 [[0.00903811 0.00903811 0.00903811 0.00903811]
 [0.89332508 0.89332508 0.89332508 0.89332508]
 [0.97648981 0.97648981 0.97648981 0.97648981]
 [0.02787972 0.02787972 0.02787972 0.02787972]
 [0.0229003  0.0229003  0.0229003  0.0229003 ]
 [0.95871511 0.95871511 0.95871511 0.95871511]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.38707756]
 [ 5.37453522]
 [ 5.87347056]
 [-2.40344462]
 [-2.40029232]
 [ 5.76673175]]
y_hat:
 [[0.08416342]
 [0.99538829]
 [0.9971948 ]
 [0.0829104 ]
 [0.08315041]
 [0.9968798 ]]
MSE Loss: 0.0034850798837839842
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22410989 0.22410989 0.22410989 0.22410989]
 [1.66364449 1.66364449 1.66364449 1.66364449]
 [1.67497552 1.67497552 1.67497552 1.67497552]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.62952857e-01]
 [ 1.32273937e-03]
 [ 1.05584663e-04]
 [-1.32001346e+00]
 [-1.12635880e+00]
 [ 2.30111189e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50323196]
 [1.50323196]
 [1.50323196]
 [1.50323196]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.44792280e+00]
 [ 1.82904972e-03]
 [ 5.73219500e-04]
 [-2.57742592e+00]
 [-2.54436074e+00]
 [ 7.38681589e-04]]
Epoch 93
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.69934514 -4.69934514 -4.69934514 -4.69934514]
 [ 2.12637758  2.12637758  2.12637758  2.12637758]
 [ 3.72833722  3.72833722  3.72833722  3.72833722]
 [-3.55402035 -3.55402035 -3.55402035 -3.55402035]
 [-3.7556841  -3.7556841  -3.7556841  -3.7556841 ]
 [ 3.1466681   3.1466681   3.1466681   3.1466681 ]]
Activation function: sigmoid
H1 matrix: 
 [[0.00901915 0.00901915 0.00901915 0.00901915]
 [0.89344063 0.89344063 0.89344063 0.89344063]
 [0.97653125 0.97653125 0.97653125 0.97653125]
 [0.02781366 0.02781366 0.02781366 0.02781366]
 [0.02285011 0.02285011 0.02285011 0.02285011]
 [0.95877723 0.95877723 0.95877723 0.95877723]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.39369131]
 [ 5.3740231 ]
 [ 5.87238521]
 [-2.41018441]
 [-2.40696468]
 [ 5.76579703]]
y_hat:
 [[0.08365503]
 [0.99538594]
 [0.99719176]
 [0.08239937]
 [0.08264314]
 [0.99687689]]
MSE Loss: 0.0034427733674866237
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22353547 0.22353547 0.22353547 0.22353547]
 [1.66412243 1.66412243 1.66412243 1.66412243]
 [1.67546384 1.67546384 1.67546384 1.67546384]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.63297493e-01]
 [ 1.33487049e-03]
 [ 1.06668363e-04]
 [-1.32102643e+00]
 [-1.12719998e+00]
 [ 2.32421965e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50289361]
 [1.50289361]
 [1.50289361]
 [1.50289361]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.45433554e+00]
 [ 1.85024101e-03]
 [ 5.81083564e-04]
 [-2.58365612e+00]
 [-2.55062619e+00]
 [ 7.48404961e-04]]
Epoch 94
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.7014349  -4.7014349  -4.7014349  -4.7014349 ]
 [ 2.12757392  2.12757392  2.12757392  2.12757392]
 [ 3.73011883  3.73011883  3.73011883  3.73011883]
 [-3.5564265  -3.5564265  -3.5564265  -3.5564265 ]
 [-3.75789815 -3.75789815 -3.75789815 -3.75789815]
 [ 3.14821686  3.14821686  3.14821686  3.14821686]]
Activation function: sigmoid
H1 matrix: 
 [[0.00900049 0.00900049 0.00900049 0.00900049]
 [0.89355447 0.89355447 0.89355447 0.89355447]
 [0.97657205 0.97657205 0.97657205 0.97657205]
 [0.02774867 0.02774867 0.02774867 0.02774867]
 [0.02280073 0.02280073 0.02280073 0.02280073]
 [0.9588384  0.9588384  0.9588384  0.9588384 ]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.40022841]
 [ 5.37351947]
 [ 5.87131667]
 [-2.41684293]
 [-2.41355792]
 [ 5.76487685]]
y_hat:
 [[0.08315528]
 [0.99538363]
 [0.99718877]
 [0.08189732]
 [0.08214466]
 [0.99687402]]
MSE Loss: 0.003401450576605143
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22296901 0.22296901 0.22296901 0.22296901]
 [1.66459381 1.66459381 1.66459381 1.66459381]
 [1.67594542 1.67594542 1.67594542 1.67594542]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.63637433e-01]
 [ 1.34699959e-03]
 [ 1.07752285e-04]
 [-1.32202514e+00]
 [-1.12802955e+00]
 [ 2.34733169e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50256045]
 [1.50256045]
 [1.50256045]
 [1.50256045]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.46067533e+00]
 [ 1.87145350e-03]
 [ 5.88964382e-04]
 [-2.58981399e+00]
 [-2.55681964e+00]
 [ 7.58146161e-04]]
Epoch 95
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.7034959  -4.7034959  -4.7034959  -4.7034959 ]
 [ 2.12875391  2.12875391  2.12875391  2.12875391]
 [ 3.73187588  3.73187588  3.73187588  3.73187588]
 [-3.55879915 -3.55879915 -3.55879915 -3.55879915]
 [-3.76008165 -3.76008165 -3.76008165 -3.76008165]
 [ 3.14974428  3.14974428  3.14974428  3.14974428]]
Activation function: sigmoid
H1 matrix: 
 [[0.00898213 0.00898213 0.00898213 0.00898213]
 [0.89366665 0.89366665 0.89366665 0.89366665]
 [0.97661222 0.97661222 0.97661222 0.97661222]
 [0.02768473 0.02768473 0.02768473 0.02768473]
 [0.02275213 0.02275213 0.02275213 0.02275213]
 [0.95889864 0.95889864 0.95889864 0.95889864]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.40669058]
 [ 5.37302415]
 [ 5.87026455]
 [-2.42342207]
 [-2.42007385]
 [ 5.76397087]]
y_hat:
 [[0.08266393]
 [0.99538135]
 [0.99718582]
 [0.08140399]
 [0.08165472]
 [0.9968712 ]]
MSE Loss: 0.0033610781689124253
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22241028 0.22241028 0.22241028 0.22241028]
 [1.66505878 1.66505878 1.66505878 1.66505878]
 [1.67642043 1.67642043 1.67642043 1.67642043]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.63972795e-01]
 [ 1.35912666e-03]
 [ 1.08836423e-04]
 [-1.32300996e+00]
 [-1.12884780e+00]
 [ 2.37044789e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50223236]
 [1.50223236]
 [1.50223236]
 [1.50223236]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.46694379e+00]
 [ 1.89268688e-03]
 [ 5.96861730e-04]
 [-2.59590117e+00]
 [-2.56294270e+00]
 [ 7.67904943e-04]]
Epoch 96
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.70552885 -4.70552885 -4.70552885 -4.70552885]
 [ 2.12991797  2.12991797  2.12991797  2.12991797]
 [ 3.73360897  3.73360897  3.73360897  3.73360897]
 [-3.56113915 -3.56113915 -3.56113915 -3.56113915]
 [-3.76223538 -3.76223538 -3.76223538 -3.76223538]
 [ 3.15125089  3.15125089  3.15125089  3.15125089]]
Activation function: sigmoid
H1 matrix: 
 [[0.00896405 0.00896405 0.00896405 0.00896405]
 [0.89377722 0.89377722 0.89377722 0.89377722]
 [0.97665177 0.97665177 0.97665177 0.97665177]
 [0.02762181 0.02762181 0.02762181 0.02762181]
 [0.02270429 0.02270429 0.02270429 0.02270429]
 [0.95895798 0.95895798 0.95895798 0.95895798]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.41307945]
 [ 5.37253694]
 [ 5.86922844]
 [-2.42992366]
 [-2.42651423]
 [ 5.76307876]]
y_hat:
 [[0.08218074]
 [0.99537911]
 [0.99718291]
 [0.08091914]
 [0.08117307]
 [0.99686841]]
MSE Loss: 0.003321624276132473
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22185912 0.22185912 0.22185912 0.22185912]
 [1.66551751 1.66551751 1.66551751 1.66551751]
 [1.67688902 1.67688902 1.67688902 1.67688902]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.64303688e-01]
 [ 1.37125170e-03]
 [ 1.09920770e-04]
 [-1.32398123e+00]
 [-1.12965501e+00]
 [ 2.39356812e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50190921]
 [1.50190921]
 [1.50190921]
 [1.50190921]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.47314244e+00]
 [ 1.91394081e-03]
 [ 6.04775391e-04]
 [-2.60191922e+00]
 [-2.56899692e+00]
 [ 7.77681072e-04]]
Epoch 97
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.70753444 -4.70753444 -4.70753444 -4.70753444]
 [ 2.13106649  2.13106649  2.13106649  2.13106649]
 [ 3.7353187   3.7353187   3.7353187   3.7353187 ]
 [-3.56344731 -3.56344731 -3.56344731 -3.56344731]
 [-3.76436006 -3.76436006 -3.76436006 -3.76436006]
 [ 3.15273721  3.15273721  3.15273721  3.15273721]]
Activation function: sigmoid
H1 matrix: 
 [[0.00894625 0.00894625 0.00894625 0.00894625]
 [0.89388621 0.89388621 0.89388621 0.89388621]
 [0.97669073 0.97669073 0.97669073 0.97669073]
 [0.02755988 0.02755988 0.02755988 0.02755988]
 [0.02265719 0.02265719 0.02265719 0.02265719]
 [0.95901644 0.95901644 0.95901644 0.95901644]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.41939663]
 [ 5.37205767]
 [ 5.86820796]
 [-2.43634946]
 [-2.43288072]
 [ 5.76220018]]
y_hat:
 [[0.08170551]
 [0.99537691]
 [0.99718004]
 [0.08044254]
 [0.0806995 ]
 [0.99686567]]
MSE Loss: 0.003283058423991661
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.22131531 0.22131531 0.22131531 0.22131531]
 [1.66597014 1.66597014 1.66597014 1.66597014]
 [1.67735135 1.67735135 1.67735135 1.67735135]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.64630221e-01]
 [ 1.38337471e-03]
 [ 1.11005320e-04]
 [-1.32493929e+00]
 [-1.13045146e+00]
 [ 2.41669228e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50159088]
 [1.50159088]
 [1.50159088]
 [1.50159088]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.47927278e+00]
 [ 1.93521498e-03]
 [ 6.12705151e-04]
 [-2.60786968e+00]
 [-2.57498378e+00]
 [ 7.87474313e-04]]
Epoch 98
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.70951334 -4.70951334 -4.70951334 -4.70951334]
 [ 2.13219986  2.13219986  2.13219986  2.13219986]
 [ 3.73700565  3.73700565  3.73700565  3.73700565]
 [-3.56572443 -3.56572443 -3.56572443 -3.56572443]
 [-3.7664564  -3.7664564  -3.7664564  -3.7664564 ]
 [ 3.15420375  3.15420375  3.15420375  3.15420375]]
Activation function: sigmoid
H1 matrix: 
 [[0.00892872 0.00892872 0.00892872 0.00892872]
 [0.89399367 0.89399367 0.89399367 0.89399367]
 [0.9767291  0.9767291  0.9767291  0.9767291 ]
 [0.02749892 0.02749892 0.02749892 0.02749892]
 [0.02261082 0.02261082 0.02261082 0.02261082]
 [0.95907404 0.95907404 0.95907404 0.95907404]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.42564364]
 [ 5.37158617]
 [ 5.86720274]
 [-2.44270117]
 [-2.43917498]
 [ 5.76133481]]
y_hat:
 [[0.08123803]
 [0.99537474]
 [0.99717721]
 [0.07997394]
 [0.08023377]
 [0.99686296]]
MSE Loss: 0.003245351457388751
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.2207787  0.2207787  0.2207787  0.2207787 ]
 [1.66641683 1.66641683 1.66641683 1.66641683]
 [1.67780758 1.67780758 1.67780758 1.67780758]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.64952497e-01]
 [ 1.39549568e-03]
 [ 1.12090066e-04]
 [-1.32588447e+00]
 [-1.13123739e+00]
 [ 2.43982023e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50127726]
 [1.50127726]
 [1.50127726]
 [1.50127726]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.48533626e+00]
 [ 1.95650909e-03]
 [ 6.20650802e-04]
 [-2.61375401e+00]
 [-2.58090473e+00]
 [ 7.97284438e-04]]
Epoch 99
Shape of Z1: (6, 4)
Z1 matrix: 
 [[-4.7114662  -4.7114662  -4.7114662  -4.7114662 ]
 [ 2.13331843  2.13331843  2.13331843  2.13331843]
 [ 3.73867036  3.73867036  3.73867036  3.73867036]
 [-3.56797125 -3.56797125 -3.56797125 -3.56797125]
 [-3.7685251  -3.7685251  -3.7685251  -3.7685251 ]
 [ 3.15565097  3.15565097  3.15565097  3.15565097]]
Activation function: sigmoid
H1 matrix: 
 [[0.00891146 0.00891146 0.00891146 0.00891146]
 [0.89409963 0.89409963 0.89409963 0.89409963]
 [0.97676691 0.97676691 0.97676691 0.97676691]
 [0.0274389  0.0274389  0.0274389  0.0274389 ]
 [0.02256515 0.02256515 0.02256515 0.02256515]
 [0.95913081 0.95913081 0.95913081 0.95913081]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[-2.431822  ]
 [ 5.37112225]
 [ 5.86621242]
 [-2.44898044]
 [-2.44539857]
 [ 5.76048236]]
y_hat:
 [[0.08077808]
 [0.9953726 ]
 [0.99717442]
 [0.07951314]
 [0.07977569]
 [0.9968603 ]]
MSE Loss: 0.0032084754703070387
Updated W1 has shape: (3, 4)
Updated W1 matrix: 
 [[0.2202491  0.2202491  0.2202491  0.2202491 ]
 [1.66685772 1.66685772 1.66685772 1.66685772]
 [1.67825785 1.67825785 1.67825785 1.67825785]]
Shape of updated B: (6, 1)
Updated B (bias vector for Z1): 
 [[-5.65270615e-01]
 [ 1.40761460e-03]
 [ 1.13175004e-04]
 [-1.32681708e+00]
 [-1.13201307e+00]
 [ 2.46295186e-04]]
Shape of updated W2: (4, 1)
Updated W2 matrix: 
 [[1.50096823]
 [1.50096823]
 [1.50096823]
 [1.50096823]]
Shape of updated  C : (6, 1)
Updated C (bias vector for Z2): 
 [[-2.49133427e+00]
 [ 1.97782282e-03]
 [ 6.28612139e-04]
 [-2.61957364e+00]
 [-2.58676119e+00]
 [ 8.07111224e-04]]
Finished running all epochs
[[3 0]
 [0 3]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="A2_Part1_JasmineKobayashi_files/figure-html/cell-19-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="A2_Part1_JasmineKobayashi_files/figure-html/cell-19-output-3.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="test-model" class="level1">
<h1>6) Test model</h1>
<p>Finally, create a test dataset and use your model to predict the labels of that test dataset. Then create a confusion matrix to show the prediction accuracy. Remember, to do this you will need labeled data, BUT you will remove the labels from the data before trying to predict it. Once the model makes predictions, you can then compare the predictions to the actual labels.</p>
<ol type="1">
<li><p>EXPLAIN in words what you plan to do</p></li>
<li><p>Code it</p></li>
<li><p>Give the results as a confusion matrix</p></li>
<li><p>Include your test dataset with your submission.</p></li>
</ol>
<p><strong><em>JK answer:</em></strong></p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This code defined in the class object code written in Q5</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>NN.test_model(test_data<span class="op">=</span><span class="st">'A2_Test_Data_JasmineKobayashi.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X is now input from test data
Test input X was normalized using same normalizer as training (StandardScaler())
Shape of X: (6, 3)
X matrix: 
 [[-0.89126852  0.78086881  0.69985421]
 [ 0.95982764  0.03123475 -0.61237244]
 [-1.19978455  1.9053199   0.87481777]
 [ 1.57685969 -0.53099079 -1.13726309]
 [-1.09694587  1.34309435  1.13726309]
 [ 1.37118234 -0.34358228 -0.78733599]]
Shape of y: (6, 1)
y vector: 
 [[1]
 [0]
 [1]
 [0]
 [1]
 [0]]
Testing model with test data
Shape of Z1: (6, 4)
Z1 matrix: 
 [[ 1.71456132  1.71456132  1.71456132  1.71456132]
 [-0.76284617 -0.76284617 -0.76284617 -0.76284617]
 [ 4.37992865  4.37992865  4.37992865  4.37992865]
 [-3.77322196 -3.77322196 -3.77322196 -3.77322196]
 [ 2.77375348  2.77375348  2.77375348  2.77375348]
 [-1.59180759 -1.59180759 -1.59180759 -1.59180759]]
Activation function: sigmoid
H1 matrix: 
 [[0.84742697 0.84742697 0.84742697 0.84742697]
 [0.31802865 0.31802865 0.31802865 0.31802865]
 [0.98762871 0.98762871 0.98762871 0.98762871]
 [0.02246179 0.02246179 0.02246179 0.02246179]
 [0.94124092 0.94124092 0.94124092 0.94124092]
 [0.16912973 0.16912973 0.16912973 0.16912973]]
Shape of Z2: (6, 1)
Z2 matrix: 
 [[ 2.59650957]
 [ 1.91138143]
 [ 5.93022589]
 [-2.48471594]
 [ 3.06432969]
 [ 1.01624053]]
y_hat:
 [[0.9306366 ]
 [0.87117426]
 [0.99734916]
 [0.07693662]
 [0.95539716]
 [0.73423965]]
Finished testing model
[[1 2]
 [0 3]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="A2_Part1_JasmineKobayashi_files/figure-html/cell-20-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>