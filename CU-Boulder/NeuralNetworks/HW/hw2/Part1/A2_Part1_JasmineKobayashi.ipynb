{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Module 2 Assignment - Part 1: One Layer NN with One Output\"\n",
    "author: \"Jasmine Kobayashi\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "execute:\n",
    "    output: true\n",
    "    warning: false\n",
    "toc: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2 Assignment - Part 1: One Layer NN with One Output\n",
    "---\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "This assignment has a two large parts with many sub-parts. Each part will enable you to practice with a neural networks and to practice for Exam 2.\n",
    "\n",
    "This Assignment will TAKE TIME so use all of the time you have to work on it. Please avoid waiting until the last few days as this will not be enough time. You need weeks - not days :)\n",
    "\n",
    "Be sure to show all work and (when requested) to code using Python (and no NN/TF/Keras packages). Do not worry, we will use packages in coming modules but first it is best to learn about what is going on inside the model. \n",
    "\n",
    "You may use examples and code that I have shared as a reference. Using my code will not be considered cheating although I strongly recommend that you write as much (if not all) of your own code so that you learn the concepts more robustly. \n",
    "\n",
    "This is not a team assignment. Please work and code alone. You may discuss concepts, but you cannot share code or work with others. Papers that look too similar with split the grade (first offense) and can suffer less pleasant outcomes for further offenses. Keep it simple and smart - do your own work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NN_architecture](network.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Fill out this network by hand and create all the needed matrices, etc. Show all multiplications and shapes.\n",
    "\n",
    "In other words, illustrate the $X$, $y$, $W1$, $B$, $Z_1$, $H_1$, $W2$, $Z_2$, $C$, $\\hat{y}$, $\\hat{y}-y$, and $L$. Assume that $H_1$ uses the Sigmoid Function. \n",
    "\n",
    "As you do this - ask yourself:\n",
    "- How many columns does $X$ have?\n",
    "- How many hidden layers are there in this architecture?\n",
    "- How many hidden units are there in teh hidden layer?\n",
    "- How many outputs are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JK's answer:\n",
    "\n",
    "### Input Matrix $X$\n",
    "\n",
    "\\begin{equation} \n",
    "X = \n",
    "\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} \\\\\n",
    "\\vdots  & \\vdots  & \\vdots  \\\\\n",
    "x_{n1} & x_{n2} & x_{n3} \\\\\n",
    "\\end{bmatrix}\n",
    "\\nonumber\n",
    "\\end{equation}\n",
    "\n",
    "Where $n$ is any integer.\n",
    "\n",
    "In any case, the point being: this architecture implies $X$ has 3 columns (but gives no restriction/information about the number of rows of $X$.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets $y$ \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix} \n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight matrix $W1$\n",
    "\n",
    "The weight matrix connecting inputs $X$ with the first hidden layer (or in this case, the only hidden layer).\n",
    "\n",
    "I will use both notations $W1 = W^{(1)}$, to be clear and be able to distinct weights $w$ in $W1$ and $W2$\n",
    "\n",
    "\\begin{align*}\n",
    "W1 = W^{(1)} = \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} & w_{14} \\\\\n",
    "w_{21} & w_{22} & w_{23} & w_{24} \\\\\n",
    "w_{31} & w_{32} & w_{33} & w_{34}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "When matching the notation that the first number in the subscript of $w$ is associated with the connected $x$ value and the second number is associated with the hidden unit $h$ (i.e. $w_{12}$ is the weight between $x_1$ and $h_2$), then the $W_1$ matrix is an $m \\times p$ matrix, where $m$ is the number of columns of $X$ and $p$ is the number of units in the first hidden layer (which is also the number of rows of $H_1$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias $B$\n",
    "\n",
    "The \"bias\". Column vector with length that matches the number of rows in $X$.\n",
    "\n",
    "$$\\mathbf{B} = [b_1,\\cdots, b_n]^\\top$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Z_1$\n",
    "\n",
    "\\begin{align*} \n",
    "Z_1 & =  X\\cdot W_1 + B\n",
    "\n",
    "\\\\\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} \\\\\n",
    "\\vdots  & \\vdots  & \\vdots  \\\\\n",
    "x_{n1} & x_{n2} & x_{n3} \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} & w_{14} \\\\\n",
    "w_{21} & w_{22} & w_{23} & w_{24} \\\\\n",
    "w_{31} & w_{32} & w_{33} & w_{34}\n",
    "\\end{bmatrix}\n",
    "\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\\\\n",
    "\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "z_{11} & z_{12} & z_{13} & z_{14} \\\\\n",
    "z_{21} & z_{22} & z_{23} & z_{24} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1} & z_{n2} & z_{n3} & z_{n4}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Where we have:\n",
    "\n",
    "\\begin{align*}\n",
    "& z_{11} = x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + b_1 & & \\\\\n",
    "& z_{12} = x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + b_1 & &\\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{n4} = x_{n1}w_{14} + x_{n2}w_{24} + x_{n3}w_{34} + b_n \n",
    "\\end{align*}\n",
    "\n",
    "In other words, I guess any $Z$ element can be summarized as,\n",
    "\n",
    "$$z_{j,k} = \\sum_i^3 x_{j,i}w_{i,k} + b_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_1$\n",
    "\n",
    "We're assuming the first hidden layer uses the Simoid activation function. Thus $S(z)$ is the Sigmoid of $z$. \n",
    "\n",
    "(Very) Generically we have,\n",
    "$$h = S(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Thus the matrix is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "H_1 & = \n",
    "\\begin{bmatrix}\n",
    "S(z_{11}) & S(z_{12}) & S(z_{13}) & S(z_{14}) \\\\\n",
    "\\vdots    &   \\vdots  &   \\vdots  &   \\vdots  \\\\\n",
    "S(z_{n1}) & S(z_{n2}) & S(z_{n3}) & S(z_{n4}) \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\\\\n",
    "\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12} & h_{13} & h_{14} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "h_{n1} & h_{n2} & h_{n3} & h_{n4} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "The number of columns in $H_1$ is the number of hidden units in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $W2$\n",
    "\n",
    "The weight matrix connecting the hidden layer and the last node.\n",
    "\n",
    "Again, I will use both notations $W1 = W^{(1)}$ and $W2 = W^{(2)}$, to be able to distinguish weights from each weight matrix.\n",
    "\n",
    "\\begin{align*}\n",
    "W2 = W^{(2)} =\n",
    "\\begin{bmatrix}\n",
    "w_1^{(2)} \\\\[6pt]\n",
    "w_2^{(2)} \\\\[6pt]\n",
    "w_3^{(2)} \\\\[6pt]\n",
    "w_4^{(2)} \\\\[6pt]\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $C$ \n",
    "\n",
    "I believe this is the \"bias\" associated to calculate $Z_2$. So much like $B$ it's going to be a column vector with length that matches the number of rows in $X$.\n",
    "\n",
    "\\begin{equation*}\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "\\vdots \\\\\n",
    "c_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Z_2$\n",
    "\n",
    "\\begin{align*}\n",
    "Z_2 &= H_1 W^{(2)} + C \\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12} & h_{13} & h_{14} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "h_{n1} & h_{n2} & h_{n3} & h_{n4} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_1^{(2)} \\\\[6pt]\n",
    "w_2^{(2)} \\\\[6pt]\n",
    "w_3^{(2)} \\\\[6pt]\n",
    "w_4^{(2)} \\\\[6pt]\n",
    "\\end{bmatrix}\n",
    "\n",
    "+\n",
    "\n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "\\vdots \\\\\n",
    "c_n\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "h_{11}w_2^{(2)} + h_{12}w_2^{(2)} + h_{13}w_3^{(2)} + h_{14}w_4^{(2)} + c_1\\\\\n",
    "\\vdots \\\\\n",
    "h_{n1}w_2^{(2)} + h_{n2}w_2^{(2)} + h_{n3}w_3^{(2)} + h_{n4}w_4^{(2)} + c_n\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "z_1^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "z_n^{(2)}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathbf{\\hat{y}}$\n",
    "\n",
    "In terms of notation,\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{y}} = \n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "(Should have the same shape as $\\mathbf{y}$)\n",
    "\n",
    "In this case, since there's no assumed activation function between $Z_2$ and $\\mathbf{\\hat{y}}$, I'm guessing $\\hat{y} = Z_2$?\n",
    "\n",
    "\\begin{align*}\n",
    "\\Rightarrow\n",
    "\\mathbf{\\hat{y}} = \n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_1^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "z_n^{(2)}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathbf{\\hat{y}} - \\mathbf{y}$\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{y}} - \\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "-\n",
    "\n",
    "\\begin{bmatrix} \n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 - y_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n - y_n \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss $L$\n",
    "\n",
    "There's really no limit of what Loss function $L$ to use. (A NN architecture doesn't define this, the NN model builder does :)) It could be LCE or a simple one.\n",
    "\n",
    "For the purpose of this assignment I'll use a simple MSE (that's supposedly pretty commonly used as well), since it uses $\\mathbf{\\hat{y}} - \\mathbf{y}$.\n",
    "\n",
    "\\begin{align*}\n",
    "Loss = L &= \\frac{1}{2} (\\mathbf{y} - \\mathbf{\\hat{y}})^2 \\\\\n",
    "&= \\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 - y_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n - y_n\n",
    "\\end{bmatrix}^2\n",
    "\\\\\n",
    "&=\\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 - y_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_n - y_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1 - y_1, & \\cdots, & \\hat{y}_1 - y_1\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "&= \\frac{1}{2} \\sum_i^n (\\hat{y}_i - y_i)^2\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Use Python to code the **Feed-Forward** portion of this NN. \n",
    "\n",
    "Print out $X$, $y$, $W1$, $B$, $Z_1$, $H_1$, $W_2$, $Z_2$, $C$, $\\hat{y}$, $\\hat{y}-y$, and $L$.\n",
    "\n",
    "**Assumptions and Notes**:\n",
    "\n",
    "(a) Create your own small labeled dataset. Have the right number of columns and have a column called \"LABEL\" which is 0 or 1. \n",
    "\n",
    "(b) Read in the data and create $X$ and $y$\n",
    "\n",
    "(c) YOU create the dataset so that everyone will have a unique dataset. Have between 5 and 7 rows (no more), assure that your labels \"make sense\" for the data, and have a balance of labels (so nearish 50% $0$ and 50% $1$). You want your NN to \"work\" so again make sure your labeled data has a predictable pattern. *INVENT* the data yourself - type it into a `.csv` file - save the file as **A2_Data_YourName.csv**. You will submit this dataset with your Assignment submission.\n",
    "\n",
    "(d) Create $H_1$ using Sigmoid. You will need to **code** a function for the Sigmoid (and its derivative) into your code. Do this using `def`.\n",
    "\n",
    "(e) Use $L = \\frac{1}{n} \\displaystyle \\sum^n (\\hat{y} - y)^2$ as the Loss Function when $n$ is the number of rows in your dataset. Do not \"hard code\". The TAs or I should be able to use your code to read ANY dataset that has 3 columns of data, one label column called \"LABEL\" (of 0 or 1), and any number of rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK answer:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayer_OneOutput_FF():\n",
    "    def __init__(self,\n",
    "                 data_filename = \"A2_Data_JasmineKobayashi.csv\", \n",
    "                 hidden_units = 4, \n",
    "                 activation=\"sigmoid\"):\n",
    "        self.df = pd.read_csv(data_filename)\n",
    "\n",
    "        # create X and y, assuming data has column \"LABEL\" as column with labels\n",
    "        ## X matrix\n",
    "        if scale_data:\n",
    "            mm_scaler = MinMaxScaler()\n",
    "            X = mm_scaler.fit_transform(self.df.drop(columns=\"LABEL\",axis=1))\n",
    "        else:\n",
    "            X = np.array(self.df.drop(columns=['LABEL'],axis=1))\n",
    "        self.X = X\n",
    "        ## y\n",
    "        self.y = df[['LABEL']]\n",
    "        # create H1\n",
    "        pass\n",
    "\n",
    "    def MSE_loss(self):\n",
    "        # L = mean((y_hat - y)^2)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Compare *by-hand* and code\n",
    "\n",
    "Here, will compare your by-hand work in (1) with your code in (2). \n",
    "\n",
    "To do this, use your dataset values (just the first row) and your label (for the first row) to FF *by hand on paper* through the network. Show numeric and clear results for $X$, $y$, $W_1$, $B$, $Z_1$, $H_1$, $W_2$, $Z_2$, $C$, $\\hat{y}$, $\\hat{y}-y$, and $L$.\n",
    "\n",
    "Then, using your code and the same $X$ (first row) and $y$ (first label), print out $X$, $y$, $W_1$, $B$, $Z_1$, $H_1$, $W_2$, $Z_2$, $C$, $\\hat{y}$, $\\hat{y}-y$, and $L$.\n",
    "\n",
    "Both the \"by hand on paper\" and the \"by code\" results should be the same. \n",
    "\n",
    "If they are not, find and fix your bugs until they are the same.\n",
    "\n",
    "**Notes**: $\\mathbf{W_1}$, $\\mathbf{W_2}$, $\\mathbf{B}$ (which is $b_1$, $b_2$, $b_3$, $b_4$), and $C$ (which is $c_1$) would normally be randomly initialized. However, to make your code and \"by hand\" comparison easier, let all the values in $W_1$ be $1$, let all the values in $W_2$ be 2, let all the $\\mathbf{B}$ values be $0$, and let $c$ be $-1$. You will code this in and will use this by hand so that your code and by-hand results will be the same. \n",
    "\n",
    "Print out all key matrices and results. \n",
    "\n",
    "Illustrate and compare your \"by-hand\" results with your code print outs to show that they are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK answer:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Writing out the derivatives by hand.\n",
    "\n",
    "For this part and in order to help you to code the back propagation, write out the derivatives for updating $\\mathbf{W_1}$, $\\mathbf{W_2}$, $\\mathbf{B}$, and $C$.\n",
    "\n",
    "Please write them clearly :)\n",
    "\n",
    "You can do this \"matrix style\" - so for example, $\\frac{dL}{d\\mathbf{W_1}}$, or you can write them out individually, such as $\\frac{dL}{dw_{11}}$, $\\frac{dL}{dw_{12}}$, etc...\n",
    "\n",
    "Either way, show all your work and illustrate how the matrices (such as $\\mathbf{X}$, $\\mathbf{W_1}$, $\\mathbf{W_2}$, etc. etc.) will all fit together to create the final derivative.\n",
    "\n",
    "**Hints:** There are many examples on the PowerPoints. We reviewed this in class. You can also see examples of this in my code examples which are all here: [Gates Bolton Analytics - Neural Networks Page](https://gatesboltonanalytics.com/?page_id=680)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK answer:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Adding Back Propagation to you code so that $\\mathbf{W_1}$, $\\mathbf{B}$, and $C$ are updated.\n",
    "\n",
    "For this step, you will add back propagation to your code. Specifically, you already have code **(2)** above. In your code (so far) you have read in your dataset, have created $X$ and $y$, and have function (or class if you OO programming) for Feed Forward.\n",
    "\n",
    "In this next step, you will add a function for Back Propagation that will update your parameters. Recall that the parameters for this NN architecture are $\\mathbf{W_1}$, $\\mathbf{W_2}$, $\\mathbf{B}$, and $C$. Each must be updated (using a learning rate) and the derivatives you calculated in **(4)**.\n",
    "\n",
    "Once you create code for the Back Propagation, add further code for epochs so that your code will \"update\" (FF and BP and calculate the Loss each time) for as many iterations (epochs) as you wish.\n",
    "\n",
    "Be sure to have a visualization of the change in the average Loss over epochs. \n",
    "\n",
    "Be sure to have a final visualization that is a confusion matrix that shows the label predictions.\n",
    "\n",
    "Be sure to **print out** some of your matrices so that a viewer can see what you are doing. While there are many ways to do this, you can consider printing $\\mathbf{W_1}$, the updates for $\\mathbf{W_1}$, the new $\\mathbf{W_1}$ (which will be the derivative updates times the learning rate added to $\\mathbf{W_1}$). In other words, **make your code verbose (shows/tells what its doing)** so you can print out the last epoch steps. (An example on Canvas) \n",
    "\n",
    "\n",
    "**NOTE:** At this point, you should have code that will read in any dataset with 3 columns of numeric data and one column called \"LABEL\" (of $0$ or $1$) and will perform NN modeling and a prediction result on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK answer:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Test model\n",
    "\n",
    "Finally, create a test dataset and use your model to predict the labels of that test dataset. Then create a confusion matrix to show the prediction accuracy. Remember, to do this you will need labeled data, BUT you will remove the labels from the data before trying to predict it. Once the model makes predictions, you can then compare the predictions to the actual labels. \n",
    "\n",
    "(1) EXPLAIN in words what you plan to do\n",
    "\n",
    "(2) Code it\n",
    "\n",
    "(3) Give the results as a confusion matrix\n",
    "\n",
    "(4) Include your test dataset with your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK answer:***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
