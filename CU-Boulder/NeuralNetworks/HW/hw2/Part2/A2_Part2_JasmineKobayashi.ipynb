{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Module 2 Assignment - Part 2: Multinomial NN with Softmax, Categorical Cross Entropy, and One-Hot Encoding\"\n",
    "author: \"Jasmine Kobayashi\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "execute:\n",
    "    output: true\n",
    "    warning: false\n",
    "toc: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 2 Assignment - Part 2: Multinomial NN with Softmax, Categorical Cross Entropy, and One-Hot Encoding\n",
    "---\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "This assignment has a two large parts with many sub-parts. Each part will enable you to practice with a neural networks and to practice for Exam 2.\n",
    "\n",
    "This Assignment will TAKE TIME so use all of the time you have to work on it. Please avoid waiting until the last few days as this will not be enough time. You need weeks - not days :)\n",
    "\n",
    "Be sure to show all work and (when requested) to code using Python (and no NN/TF/Keras packages). Do not worry, we will use packages in coming modules but first it is best to learn about what is going on inside the model. \n",
    "\n",
    "You may use examples and code that I have shared as a reference. Using my code will not be considered cheating although I strongly recommend that you write as much (if not all) of your own code so that you learn the concepts more robustly. \n",
    "\n",
    "This is not a team assignment. Please work and code alone. You may discuss concepts, but you cannot share code or work with others. Papers that look too similar with split the grade (first offense) and can suffer less pleasant outcomes for further offenses. Keep it simple and smart - do your own work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Draw NN architecture\n",
    "In Part 1 above, I created (with an illustration) the NN architecture for you. In this part, you will illustrate (draw) the architecture. \n",
    "\n",
    "(a) Your NN architecture (draw this) will expect input vectors of three values (3D data). It will have one hidden layer with two units. It will create four outputs (for four categories), it will use softmax to convert those 4 outputs into a probability distribution, and it will choose the max as the prediction. \n",
    "\n",
    "(b) The hidden layer (H1) will be activated with reLU. \n",
    "\n",
    "Draw the NN.\n",
    "\n",
    "Use my slides and what we did during class lecture to help you. Label everything - including the x's, the W1's, the B, the C, the H1 values, the Z2 values, the y^ values (after softmax), and the final output. Again, the class slides have an exact example of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK:*** *Check Word Document*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Write out all the Feed Forward equations\n",
    "\n",
    "You will have equations for $Z_1$, $H_1$, $Z_2$, $\\hat{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JK's answer\n",
    "\n",
    "### $Z_1$\n",
    "\n",
    "\\begin{align*} \n",
    "Z_1 & =  X\\cdot W_1 + B\n",
    "\n",
    "\\\\\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} \\\\\n",
    "\\vdots  & \\vdots  & \\vdots  \\\\\n",
    "x_{n1} & x_{n2} & x_{n3} \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}  \\\\\n",
    "w_{21} & w_{22}  \\\\\n",
    "w_{31} & w_{32} \n",
    "\\end{bmatrix}\n",
    "\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\\\\n",
    "\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "z_{11} & z_{12}  \\\\\n",
    "z_{21} & z_{22}  \\\\\n",
    "\\vdots & \\vdots  \\\\\n",
    "z_{n1} & z_{n2} \n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Where we have:\n",
    "\n",
    "\\begin{align*}\n",
    "& z_{11} = x_{11}w_{11} + x_{12}w_{21} + x_{13}w_{31} + b_1 & & \\\\\n",
    "& z_{12} = x_{11}w_{12} + x_{12}w_{22} + x_{13}w_{32} + b_1 & &\\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{n2} = x_{n1}w_{12} + x_{n2}w_{22} + x_{n3}w_{32} + b_n \n",
    "\\end{align*}\n",
    "\n",
    "In other words, any $Z$ element can be summarized as,\n",
    "\n",
    "$$z_{i,k} = \\sum_j^3 x_{i,j}w_{j,k} + b_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_1$\n",
    "\n",
    "We're assuming the first hidden layer uses the reLU activation function.  \n",
    "\n",
    "reLU function:\n",
    "\n",
    "\\begin{equation*}\n",
    "f = \n",
    "\\begin{cases}\n",
    "x   &\\text{if } x > 0 \\\\\n",
    "0   &\\text{else}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "$h$ is the same value as $x$ if it's positive and 0 otherwise. \n",
    "\n",
    "The $H1$ matrix is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "H_1 & = \n",
    "\\begin{bmatrix}\n",
    "f(z_{11}) & f(z_{12}) \\\\\n",
    "\\vdots    &   \\vdots  \\\\\n",
    "f(z_{n1}) & f(z_{n2}) \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\\\\n",
    "\n",
    "& = \n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12}  \\\\\n",
    "\\vdots & \\vdots  \\\\\n",
    "h_{n1} & h_{n2}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "The number of columns in $H_1$ is the number of hidden units in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Z_2$\n",
    "\n",
    "\\begin{align*}\n",
    "Z^{(2)} &= H_1 W^{(2)} + C \\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "h_{n1} & h_{n2} \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} & w_{14}^{(2)}  \\\\[6pt]\n",
    "w_{21}^{(2)} & w_{22}^{(2)} & w_{23}^{(2)} & w_{24}^{(2)}  \\\\[6pt]\n",
    "\\end{bmatrix}\n",
    "\n",
    "+\n",
    "\n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "\\vdots \\\\\n",
    "c_n\n",
    "\\end{bmatrix}\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "z_{11}^{(2)} & z_{12}^{(2)} & z_{13}^{(2)} & z_{14}^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1}^{(2)} & z_{n2}^{(2)} & z_{n3}^{(2)} & z_{n4}^{(2)}  \n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where,\n",
    "\n",
    "\\begin{align*}\n",
    "& z_{11}^{(2)} = h_{11}w_{11}^{(2)} + h_{12}w_{21}^{(2)} + c_1 & & \\\\\n",
    "& z_{12}^{(2)} = h_{11}w_{12}^{(2)} + h_{12}w_{22}^{(2)} + c_1 & &\\\\\n",
    "\\end{align*}\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{n4}^{(2)} = h_{n1}w_{14}^{(2)} + x_{n2}w_{24}^{(2)} + c_n \n",
    "\\end{align*}\n",
    "\n",
    "Or in other words, each $Z^{(2)}$ element can be summarized as,\n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,l}^{(2)} = \\sum_k^2 h_{i,k}w_{k,l}^{(2)} + c_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathbf{\\hat{y}}$\n",
    "\n",
    "And lastly we have the predicted output $\\mathbf{\\hat{y}}$.\n",
    "\n",
    "In the case of this architecture, we're expecting 4 outputs. \n",
    "\n",
    "And for this assignment, we said we would use the Softmax function, which is defined as follows.\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{y}_{i,l} = \\text{softmax}(z_{i,l}^{(2)}) = \\frac{\\text{exp}(z_{i,l}^{(2)})}{\\displaystyle \\sum_l^4 \\text{exp}(z_{i,l}^{(2)})}\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\text{exp}(x) = e^x$ (I just used that notation to make the variables easier to see in the fraction.)\n",
    "\n",
    "The summation from $l=1$ to $l=4$ is due to the fact that we have four possible classes/outcomes for this architecture. (So the formula above is specific to this assignment.)\n",
    "\n",
    "The softmax function gives the probability distributions of the possible outcomes. So in this case we would have 4 probabilities of the 4 labels from the softmax. (The probabilities are pdfs too, so the probabilities for each instance are non-negative and all sum up to one.)\n",
    "\n",
    "\\begin{align*}\n",
    "\\Rightarrow\n",
    "\\mathbf{\\hat{y}} &= \n",
    "\\begin{bmatrix}\n",
    "[\\hat{y}_{11} & \\hat{y}_{12} & \\hat{y}_{13} & \\hat{y}_{14}] \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "[\\hat{y}_{n1} & \\hat{y}_{n2} & \\hat{y}_{n3} & \\hat{y}_{n4}] \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "[\\text{softmax}(z_{11}^{(2)}) & \\text{softmax}(z_{12}^{(2)}) & \\text{softmax}(z_{13}^{(2)}) & \\text{softmax}(z_{14}^{(2)})] \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "[\\text{softmax}(z_{n1}^{(2)}) & \\text{softmax}(z_{n2}^{(2)}) & \\text{softmax}(z_{n3}^{(2)}) & \\text{softmax}(z_{n4}^{(2)})]\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) What are the following derivatives\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W1} = ?$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W2} = ?$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B} = ?$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial C} = ?$ \n",
    "\n",
    "(using reLU to activate $Z_1$ to $H_1$, and using Softmax to activate $Z_2$ to $\\hat{Y}$)\n",
    "\n",
    "**Hint:** The slides show a very similar example. The only difference is that the slides use Sigmoid and not reLU. So you will need to update this part. Start by determining the derivative of the reLU.\n",
    "\n",
    "Use the Categorical Cross Entropy Loss function.\n",
    "\n",
    "Use One-Hot Encoding for $\\mathbf{y}$ (your label)\n",
    "\n",
    "Show all your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JK's answer:\n",
    "\n",
    "Parameters we want to update via back propagation (and gradient descent):\n",
    "\n",
    "\\begin{aligned}\n",
    "\\begin{array}{ccc}\n",
    "\\hline\n",
    "\\text{Parameter} & \\text{Matrix/Vector form} & \\text{Shape} \\\\\n",
    "\\hline \n",
    "\\\\\n",
    "\n",
    "W^{(1)} & \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}  \\\\\n",
    "w_{21} & w_{22}  \\\\\n",
    "w_{31} & w_{32} \n",
    "\\end{bmatrix}\n",
    "&\n",
    "[3 \\times 2]\\\\\n",
    "\n",
    "\\\\\n",
    "\\hline \n",
    "\\\\\n",
    "\n",
    "\\mathbf{B} &\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 1]\\\\\n",
    "\n",
    "\\\\\n",
    "\\hline \n",
    "\\\\\n",
    "\n",
    "W^{(2)} & \n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} & w_{14}^{(2)}  \\\\[6pt]\n",
    "w_{21}^{(2)} & w_{22}^{(2)} & w_{23}^{(2)} & w_{24}^{(2)}  \\\\[6pt]\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[2 \\times 4]\\\\\n",
    "\n",
    "\\\\\n",
    "\\hline \n",
    "\\\\\n",
    "\n",
    "\\mathbf{C} &\n",
    "\\begin{bmatrix}\n",
    "c_1 \\\\\n",
    "\\vdots \\\\\n",
    "c_n\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 1]\n",
    "\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "\n",
    "And I believe for gradient descent to work properly, I think the (final matrix/vector form of the) partial derivatives of each parameter needs to match the shape of the original parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other relevant formulas:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\begin{array}{c|c|c|c}\n",
    "\\hline\n",
    "\\text{Variable (matrix/vector form)}& \\text{Shape} & \\text{Vector/Matrix Formula} & \\text{Element-wise formula} \\\\\n",
    "\\hline \\\\\n",
    "\n",
    "L_{CCE} & \\text{(scalar)} & -log(\\mathbf{\\hat{y}}) & L = -log(\\hat{y_i}) \\\\\n",
    "\\\\\n",
    "\\hline \\\\\n",
    "\n",
    "\\mathbf{\\hat{y}} = \n",
    "\\begin{bmatrix}\n",
    "[\\hat{y}_{11} & \\hat{y}_{12} & \\hat{y}_{13} & \\hat{y}_{14}] \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "[\\hat{y}_{n1} & \\hat{y}_{n2} & \\hat{y}_{n3} & \\hat{y}_{n4}] \\\\\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 4]\n",
    "&\n",
    "\\mathbf{\\hat{y}} = \\text{softmax}(Z^{(2)})\n",
    "& \\hat{y}_{i,l} =  \\frac{\\textstyle{\\text{exp}}(z_{i,l}^{(2)})}{\\displaystyle \\sum_l^4 \\text{exp}(z_{i,l}^{(2)})}\\\\\n",
    "\\\\\n",
    "\\hline \n",
    "\\\\\n",
    "\n",
    "Z^{(2)} = \n",
    "\\begin{bmatrix}\n",
    "z_{11}^{(2)} & z_{12}^{(2)} & z_{13}^{(2)} & z_{14}^{(2)} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1}^{(2)} & z_{n2}^{(2)} & z_{n3}^{(2)} & z_{n4}^{(2)}  \n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 4]\n",
    "&\n",
    "Z^{(2)} = H_1 W^{(2)} + C \n",
    "& z_{i,l}^{(2)} = \\displaystyle \\sum_k^2 h_{i,k}w_{k,l}^{(2)} + c_i \\\\\n",
    "\n",
    "\\\\\n",
    "\\hline\n",
    "\\\\\n",
    "\n",
    "H_1 = \n",
    "\\begin{bmatrix}\n",
    "h_{11} & h_{12}  \\\\\n",
    "\\vdots & \\vdots  \\\\\n",
    "h_{n1} & h_{n2}  \\\\\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 2]\n",
    "&\n",
    "H_1 = \\text{reLU}(Z^{(1)})\n",
    "&\n",
    "h_{i,k} = \n",
    "\\begin{cases}\n",
    "z_{i,k}^{(1)}   &\\text{if } z > 0 \\\\\n",
    "0   &\\text{else}\n",
    "\\end{cases} \\\\\n",
    "\n",
    "\\\\\n",
    "\\hline\n",
    "\\\\\n",
    "\n",
    "Z^{(1)} =\n",
    "\\begin{bmatrix}\n",
    "z_{11} & z_{12} & z_{13} & z_{14} \\\\\n",
    "z_{21} & z_{22} & z_{23} & z_{24} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "z_{n1} & z_{n2} & z_{n3} & z_{n4}\n",
    "\\end{bmatrix}\n",
    "&\n",
    "[n \\times 4]\n",
    "& \n",
    "Z^{(1)} =  X\\cdot W_1 + B\n",
    "&\n",
    "z_{i,k}^{(1)} = \\displaystyle \\sum_j^3 x_{i,j}w_{j,k}^{(1)} + b_i \\\\\n",
    "\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "\n",
    "Reminder (to self) the following are specific to the architecture of this assignment: \n",
    "\n",
    "- $2$ comes from the number of units in the hidden layer\n",
    "- $3$ comes from the number of inputs/columns in $X$\n",
    "- $4$ comes from the number of possible labels/outputs in $y$ and $\\hat{y}$\n",
    "- ($n$ in this is supposed to be 6 for the dataset I created)\n",
    "\n",
    "**Other potentially useful multiplication notation to match with python.**\n",
    "\n",
    "I will try my best to match the multiplication notation as done in Professor Gates' lecture slides.\n",
    "\n",
    "Thus, I will use an \"o-dot\" ($\\odot$) to represent matrix multiplcation, (equivalent to `@` in Python) i.e.:\n",
    "\n",
    "\\begin{align*}\n",
    "A \\odot B = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\\\\\n",
    "\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\\n",
    "a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "And I will use an asterisk ($\\ast$) for element-wise (\"regular\") multiplication, (equivalent to `*` in Python) i.e.:\n",
    "\n",
    "\\begin{align*}\n",
    "A \\ast B = \n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\\\\\n",
    "\\end{bmatrix}\n",
    "\\ast\n",
    "\\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11}b_{11} & a_{12}b_{12} \\\\\n",
    "a_{21}b_{21} & a_{22}b_{22}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial L}{\\partial C}$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial C} = \\frac{\\partial L}{\\partial \\mathbf{\\hat{y}_i}} \\cdot \\frac{\\partial \\mathbf{\\hat{y}_i}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial C}\n",
    "\\end{align*}\n",
    "\n",
    "We find the derivative of the softmax in question 5, and in question 6 we remind ourselves from the lectures that when we use a combination of Softmax, Categorical Cross entropy, and One-Hot Encoding, then $\\frac{\\partial L}{\\partial Z^{(2)}} = \\hat{y} - y$ (aka \"error\" in the lecture slides). So I'm going to skip those parts and just find the rest of the relevant partial derivatives. \n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,l}^{(2)} &= \\sum_k^2 h_{i,k}w_{k,l}^{(2)} + c_i \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial z_{i,l}^{(2)}}{\\partial c_i} &= 0 + (1)\\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial Z^{(2)}}{\\partial C} &= \n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\vec{1}_n\n",
    "\\end{align*}\n",
    "\n",
    "So in matrix form\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial C} &= \\frac{\\partial L}{\\partial \\mathbf{\\hat{y}_i}} \\cdot \\frac{\\partial \\mathbf{\\hat{y}_i}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial C}\\\\\n",
    "&= [\\mathbf{\\hat{y}} - \\mathbf{y}] \\ast \\vec{1}_n\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial L}{\\partial W^{(2)}}$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W^{(2)}} &= \\underbrace{\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}_i}} \\cdot \\frac{\\partial \\mathbf{\\hat{y}_i}}{\\partial Z^{(2)}}}_{\\frac{\\partial L}{\\partial Z^{(2)}}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial W^{(2)}}\\\\\n",
    "&= \\frac{\\partial L}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial W^{(2)}}\n",
    "\\end{align*}\n",
    "\n",
    "Again, focusing on the other derivatives:\n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,l}^{(2)} &= \\sum_k^2 h_{i,k}w_{k,l}^{(2)} + c_i \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial z_{i,l}^{(2)}}{\\partial w_{kl}} &= h_{i,k}(1) + 0\\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial Z^{(2)}}{\\partial W^{(2)}} &= H_1\n",
    "\\end{align*}\n",
    "\n",
    "Matrix form:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W^{(2)}} &= \\frac{\\partial L}{\\partial \\mathbf{\\hat{y}_i}} \\cdot \\frac{\\partial \\mathbf{\\hat{y}_i}}{\\partial Z^{(2)}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial W^{(2)}}\\\\\n",
    "&= [\\mathbf{\\hat{y}} - \\mathbf{y}] \\odot H_1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial L}{\\partial B}$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial B} &= \\underbrace{\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} \\cdot \\frac{\\partial \\mathbf{\\hat{y}}}{\\partial Z^{(2)}}}_{\\frac{\\partial L}{\\partial Z^{(2)}}} \\cdot \\frac{\\partial Z^{(2)}}{\\partial H_1} \\cdot \\frac{\\partial H_1}{\\partial Z^{(1)}} \\cdot \\frac{\\partial Z^{(1)}}{\\partial B} \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with $\\frac{\\partial Z^{(2)}}{\\partial H_1}$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,l}^{(2)} &= \\displaystyle \\sum_k^2 h_{i,k}w_{k,l}^{(2)} + c_i \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial z_{i,l}^{(2)}}{\\partial h_{i,k}} &= (1)w_{k,l}^{(2)} + 0 \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial Z^{(2)}}{\\partial H_1} &= W^{(2)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for $\\frac{\\partial H_1}{\\partial Z^{(1)}}$\n",
    "\n",
    "\\begin{align*}\n",
    "h_{i,k} = \\text{reLU}(z_{i,k}^{(1)}) =\n",
    "\\begin{cases}\n",
    "z_{i,k}^{(1)}   &\\text{if } z > 0 \\\\\n",
    "0   &\\text{else}\n",
    "\\end{cases} \n",
    "\\end{align*}\n",
    "\n",
    "We need to start with finding the derivative of the reLU function.\n",
    "\n",
    "Generically,\n",
    "\n",
    "\\begin{align*}\n",
    "f(z) =\n",
    "\\begin{cases}\n",
    "z   &\\text{if } z > 0 \\\\\n",
    "0   &\\text{else}\n",
    "\\end{cases} \\\\\n",
    "\\Rightarrow\n",
    "f'(z) =\n",
    "\\begin{cases}\n",
    "1   &\\text{if } z > 0 \\\\\n",
    "0   &\\text{else}\n",
    "\\end{cases} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So I can summarize this with a matrix, and I can call this matrix, $\\Gamma$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial H_1}{\\partial Z^{(1)}} = \n",
    "\\begin{bmatrix}\n",
    "f'(z_{11}^{(1)}) & f'(z_{12}^{(1)}) & f'(z_{13}^{(1)}) & f'(z_{14}^{(1)}) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "f'(z_{n1}^{(1)}) & f'(z_{n2}^{(1)}) & f'(z_{n3}^{(1)}) & f'(z_{n4}^{(1)})\n",
    "\\end{bmatrix} \n",
    "= \\Gamma\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lastly for $\\frac{\\partial Z^{(1)}}{\\partial B}$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,k}^{(1)} &= \\displaystyle \\sum_j^3 x_{i,j}w_{j,k}^{(1)} + b_i \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial z_{i,k}^{(1)}}{\\partial b_i} &= 0 + (1) \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial Z^{(1)}}{\\partial B} &=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1\n",
    "\\end{bmatrix} \n",
    "= \\vec{1}_n\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial B} &= \n",
    "\\underbrace{\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} \n",
    "\\cdot \n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial Z^{(2)}}}_{\\frac{\\partial L}{\\partial Z^{(2)}}} \n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial Z^{(2)}}{\\partial H_1}}_{W^{(2)}}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial H_1}{\\partial Z^{(1)}}}_{\\Gamma}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial Z^{(1)}}{\\partial B}}_{\\vec{1}_n} \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{\\partial L}{\\partial W^{(1)}}$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W^{(1)}} &= \n",
    "\\underbrace{\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} \n",
    "\\cdot \n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial Z^{(2)}}}_{\\frac{\\partial L}{\\partial Z^{(2)}}} \n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial Z^{(2)}}{\\partial H_1}}_{W^{(2)}}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial H_1}{\\partial Z^{(1)}}}_{\\Gamma}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\frac{\\partial Z^{(1)}}{\\partial W^{(1)}} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The only derivative I need to find for $\\frac{\\partial Z^{(1)}}{\\partial W^{(1)}}$\n",
    "\n",
    "\\begin{align*}\n",
    "z_{i,k}^{(1)} &= \\displaystyle \\sum_j^3 x_{i,j}w_{j,k}^{(1)} + b_i \\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial z_{i,k}^{(1)}}{\\partial w_{j,k}^{(1)}} &= x_{i,j}(1) + 0 = x_{i,j}\\\\\n",
    "\\Rightarrow\n",
    "\\frac{\\partial Z^{(1)}}{\\partial W^{(1)}} &=\n",
    "X\n",
    "\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial W^{(1)}} &= \n",
    "\\underbrace{\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} \n",
    "\\cdot \n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial Z^{(2)}}}_{\\frac{\\partial L}{\\partial Z^{(2)}}} \n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial Z^{(2)}}{\\partial H_1}}_{W^{(2)}}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial H_1}{\\partial Z^{(1)}}}_{\\Gamma}\n",
    "\n",
    "\\cdot \n",
    "\n",
    "\\underbrace{\\frac{\\partial Z^{(1)}}{\\partial W^{(1)}}}_{X} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Calculate Softmax results\n",
    "\n",
    "If your four $Z_2$ values are $1.1, 2.2, 0.2$ and $-1.7$, calculate (by hand and show your work) the four softmax results.\n",
    "\n",
    "(Yes you can use a calculator or Google for the math - but SHOW THE WORK and steps) If you show just the answer, you will get -50%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JK's answer\n",
    "\n",
    "Softmax formula:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{softmax}(z) = \\frac{\\text{exp}(z)}{\\displaystyle \\sum_i \\text{exp}(z_i)}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "$Z2 = [1.1,2.2,0.2,-1.7]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{softmax}(1.1)$\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{softmax}(1.1) &= \\frac{e^{1.1}}{e^{1.1} + e^{2.2} + e^{0.2} + e^{-1.7}} \\\\\n",
    "& \\approx \\frac{3.0042}{13.43327} \\\\\n",
    "& \\approx 0.2236\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{softmax}(2.2)$\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{softmax}(2.2) &= \\frac{e^{2.2}}{e^{1.1} + e^{2.2} + e^{0.2} + e^{-1.7}} \\\\\n",
    "& \\approx \\frac{9.025}{13.43327} \\\\\n",
    "& \\approx 0.6718\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{softmax}(0.2)$\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{softmax}(0.2) &= \\frac{e^{0.2}}{e^{1.1} + e^{2.2} + e^{0.2} + e^{-1.7}} \\\\\n",
    "& \\approx \\frac{1.2214}{13.43327} \\\\\n",
    "& \\approx 0.0909\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{softmax}(-1.7)$\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{softmax}(-1.7) &= \\frac{e^{-1.7}}{e^{1.1} + e^{2.2} + e^{0.2} + e^{-1.7}} \\\\\n",
    "& \\approx \\frac{0.18268}{13.43327} \\\\\n",
    "& \\approx 0.0136\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Derivative of Softmax\n",
    "\n",
    "Write out the derivative of the Softmax for the case where $i=j$ and for the case $i$ does not equal $j$. Show all work and steps.\n",
    "\n",
    "Find and paste in the Jacobian for the derivative of the Softmax and assure that your results (for $i=j$ and $i\\neq j$) match the Jacobian values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JK's answer:\n",
    "\n",
    "Reminder:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{y}_i = \\text{softmax}(z_i) = \\frac{\\text{exp}(z_i)}{\\displaystyle \\sum_{j=1}^k \\text{exp}(z_j)}\n",
    "\\end{align*}\n",
    "\n",
    "where $i$ and $j$ go from 1 to $k$, and $k$ is the number of categories.\n",
    "\n",
    "Thus, we need *two derivatives*, for $\\frac{\\partial \\hat{y}_i}{\\partial z_j}$. Cases for when $i=j$ **AND** when $i \\neq j$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Case 1:* $i=j$\n",
    "\n",
    "For simpler notation I'm going to state that all summations are $\\displaystyle \\sum_{j=1}^k$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} &= \\frac{(e^{z_i})(\\sum e^{z_j}) - (e^{z_i})(e^{z_i})}{(\\sum e^{z_j})^2}\\\\[6pt]\n",
    "&= \n",
    "\\frac{e^{z_i}}{\\sum e^{z_j}} \\cdot \\left(1 - \\frac{e^{z_i}}{\\sum e^{z_j}}\\right) \\\\[8pt]\n",
    "\n",
    "\\Rightarrow\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} &= \\hat{y}_i(1 - \\hat{y}_i)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Case 2:* $i \\neq j$\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} &= \\frac{(0)(\\sum e^{z_j}) - (e^{z_j})(e^{z_i})}{(\\sum e^{z_j})^2}\\\\[6pt]\n",
    "&=\n",
    "\\frac{-e^{z_j}e^{z_i}}{(\\sum e^{z_j})^2}\\\\[6pt]\n",
    "\n",
    "&= \n",
    "\\frac{e^{z_i}}{\\sum e^{z_j}} \\cdot \\left(- \\frac{e^{z_j}}{\\sum e^{z_j}}\\right) \\\\[8pt]\n",
    "\n",
    "\\Rightarrow\n",
    "\\frac{\\partial \\hat{y}_i}{\\partial z_j} &= \\hat{y}_i(- \\hat{y}_j) = -\\hat{y}_i\\hat{y}_j\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian\n",
    "\n",
    "(For the case in this assignment)\n",
    "\n",
    "\\begin{align*}\n",
    "J &= \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial \\hat{y}_1}{\\partial z_1} & \\frac{\\partial \\hat{y}_1}{\\partial z_2} & \\frac{\\partial \\hat{y}_1}{\\partial z_3} & \\frac{\\partial \\hat{y}_1}{\\partial z_4} \\\\[6pt]\n",
    "\n",
    "\\frac{\\partial \\hat{y}_2}{\\partial z_1} & \\frac{\\partial \\hat{y}_2}{\\partial z_2} & \\frac{\\partial \\hat{y}_2}{\\partial z_3} & \\frac{\\partial \\hat{y}_2}{\\partial z_4} \\\\[6pt]\n",
    "\n",
    "\\frac{\\partial \\hat{y}_3}{\\partial z_1} & \\frac{\\partial \\hat{y}_3}{\\partial z_2} & \\frac{\\partial \\hat{y}_3}{\\partial z_3} & \\frac{\\partial \\hat{y}_3}{\\partial z_4} \\\\[6pt]\n",
    "\n",
    "\\frac{\\partial \\hat{y}_4}{\\partial z_1} & \\frac{\\partial \\hat{y}_4}{\\partial z_2} & \\frac{\\partial \\hat{y}_4}{\\partial z_3} & \\frac{\\partial \\hat{y}_4}{\\partial z_4} \\\\[6pt]\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}_1(1-\\hat{y}_1) & -\\hat{y}_1\\hat{y}_2 & -\\hat{y}_1\\hat{y}_3 & -\\hat{y}_1\\hat{y}_4 \\\\[4pt]\n",
    "\n",
    "-\\hat{y}_2\\hat{y}_1 & \\hat{y}_2(1-\\hat{y}_2) & -\\hat{y}_2\\hat{y}_3 & -\\hat{y}_2\\hat{y}_4 \\\\[4pt]\n",
    "\n",
    "-\\hat{y}_3\\hat{y}_1 & -\\hat{y}_3\\hat{y}_2 & \\hat{y}_3(1-\\hat{y}_3) & -\\hat{y}_3\\hat{y}_4 \\\\[4pt]\n",
    "\n",
    "-\\hat{y}_4\\hat{y}_1 & -\\hat{y}_4\\hat{y}_2 & -\\hat{y}_4\\hat{y}_3 & \\hat{y}_4(1-\\hat{y}_4) \\\\[4pt]\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture slide on Jacobians is as follows:\n",
    "<div>\n",
    "<img src=\"j_lecture.PNG\" width=\"800\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jacobian matrix matches the above calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Combination\n",
    "\n",
    "When using the combination of Softmax, Categorical Cross Entropy, and One-Hot Encoding, what is $\\frac{\\partial L}{\\partial Z_2}$ (sometimes written as $\\frac{dL}{dz}$ or as \"Error\" on the slides)?\n",
    "\n",
    "(Just give the final answer here. You are not required to show work for this part.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JK:***\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2} = \\hat{y} - y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Code\n",
    "\n",
    "In **(1)** above, you created a NN architecture for 3D data, a 4-category label (0,1,2,3), one hidden layer (with two units). Write code for this NN without using any NN packages (so by hand)\n",
    "\n",
    "- Use One-hot Encoding for the label.\n",
    "- For the Loss Fucntion, use Categorical Cross Entropy.\n",
    "- For the activation from $Z_1$ to $H_1$, use reLU.\n",
    "- Run it for 1000 epochs and include the same visualizations as were required in **Part 1 *(5)*** above.\n",
    "- **YOU** create the dataset and also submit the dataset with your submission.\n",
    "- Be sure to illustrate some of your results so that the viewer can see what you did.\n",
    "\n",
    "This code will help (a lot). Here again, I suggest that you try not to use my code :) Try to write this yourself and only use my code as a reference or if you must. ([Prof Gates' Code Example](https://gatesboltonanalytics.com/?page_id=707))\n",
    "\n",
    "(Note - my code uses Sigmoid - not reLU - so you will need to make some updates anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# %%\n",
    "class OneLayer_MultiOutput():\n",
    "    def __init__(self,\n",
    "                 data_filename = \"A2_Part2_Data_JasmineKobayashi.csv\", \n",
    "                 data_normalizer = StandardScaler(),\n",
    "                 hidden_units= 2,\n",
    "                 randomize_initial_parameters = False,\n",
    "                 verbose = True):\n",
    "        # Read Data\n",
    "        self.df = pd.read_csv(data_filename)\n",
    "        \n",
    "        # create X and y, assuming data has column \"LABEL\" as column with labels\n",
    "        ## X matrix\n",
    "        if data_normalizer is not None:\n",
    "            self.data_scaler = data_normalizer\n",
    "            X = self.data_scaler.fit_transform(self.df.drop(columns=\"LABEL\",axis=1))\n",
    "            print(\"X was normalized using {}\".format(data_normalizer))\n",
    "        else:\n",
    "            self.data_scaler = None\n",
    "            X = np.array(self.df.drop(columns=['LABEL'],axis=1))\n",
    "            print(\"X was not normalized\")\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        ## y\n",
    "        self.OHE = OneHotEncoder()\n",
    "        self.y = self.OHE.fit_transform(self.df[['LABEL']]).toarray()\n",
    "        \n",
    "\n",
    "        if verbose:\n",
    "            print(\"Shape of X:\", self.X.shape)\n",
    "            print(\"X matrix: \\n\", self.X)\n",
    "            print(\"Shape of y:\", self.y.shape)\n",
    "            print(\"y vector: \\n\", self.y)\n",
    "\n",
    "        # Shape of W1\n",
    "        w1_ncol = hidden_units        # Number of W1 cols should be number of hidden units in H1\n",
    "        w1_nrow = self.X.shape[1]     # Number of W1 rows should be number of X columns (dim of X)\n",
    "        # Shape of B (column vector)\n",
    "        b_length = self.X.shape[0]    # length of X rows\n",
    "        # Shape of W2:\n",
    "        w2_ncol = self.y.shape[1]                 # Number of W2 cols should be number of outputs (in this case, only one output)\n",
    "        w2_nrow = hidden_units        # Number of W2 rows should be number of hidden units in H1\n",
    "        # Shape of C (column vector)\n",
    "        c_length = self.X.shape[0]    # length of X rows\n",
    "        \n",
    "        if randomize_initial_parameters: \n",
    "            # TODO: Finish potential code of randomized parameters\n",
    "            # # bounds of randomized weights\n",
    "            # bound = 1/np.sqrt(w1_nrow)   # I found online that supposedly this is a standard range for randomized weights\n",
    "            # rand_w = [np.random.uniform(-bound,bound) for i in range(w1_ncol)]\n",
    "            # self.W1 = np.array([rand_w]*w1_nrow)\n",
    "\n",
    "            # self.W2 = np.array([]*w2_nrow)\n",
    "            # print('All parameters were randomized')\n",
    "            pass\n",
    "        else:   # These are the parameters defined by the question 2 in Assignment2\n",
    "            self.W1 = np.array([[1]*w1_ncol]*w1_nrow) # otherwise, all weights of W1 = 1\n",
    "            self.B = np.array([[0]]*b_length)         # otherwise, all bias (B) = 0\n",
    "            self.W2 = np.array([[2]*w2_ncol]*w2_nrow) # otherwise, all weights of W2 = 2\n",
    "            self.C = np.array([[0]]*c_length)\n",
    "            print(\"Parameters built for simple calculation (not randomized)\")\n",
    "        \n",
    "        if verbose:\n",
    "            # print(\"# of X cols (should be # of W1 rows):\", self.X.shape[1])\n",
    "            # print(\"# of hidden units (should be # of W1 cols):\", hidden_units)\n",
    "            print(\"W1 has shape:\", self.W1.shape)\n",
    "            print(\"W1 matrix: \\n\", self.W1)\n",
    "            print(\"Shape of B:\", self.B.shape)\n",
    "            print(\"B (bias vector for Z1): \\n\", self.B)\n",
    "            print(\"Shape of W2:\",self.W2.shape)\n",
    "            print(\"W2 matrix: \\n\", self.W2)\n",
    "            print(\"Shape of C :\", self.C.shape)\n",
    "            print(\"C (bias vector for Z2): \\n\",self.C)\n",
    "\n",
    "\n",
    "    def MSE_loss(self,y_hat,y):\n",
    "        # L = mean((y_hat - y)^2)\n",
    "        return np.mean((y_hat - y)**2)\n",
    "        \n",
    "    def CCE_loss(self,y_hat,y):\n",
    "        # each row of y and y^ have to be passed individually\n",
    "        # loss=[]\n",
    "        # for j in range(y.shape[0]):\n",
    "        #     loss.append(-y[j]*np.log(y_hat[j]))\n",
    "        return np.mean(-y * np.log(y_hat))\n",
    "\n",
    "    def lin_eq(self,X,W,B):\n",
    "        assert X.shape[1] == W.shape[0], \"Linear eq: z = X @ W + B. Shape of X: {}; Shape of W: {}\".format(X.shape,W.shape)\n",
    "        assert B.shape[0] == X.shape[0], \"Linear eq: z = X @ W + B. Length of B should match X rows; Length B = {}; Shape of X = {}\".format(B.shape[0],X.shape)\n",
    "        return X @ W + B\n",
    "    \n",
    "    def Sigmoid(self,z,\n",
    "                derivative = False):\n",
    "        if derivative:\n",
    "            return self.Sigmoid(z) * (1 - self.Sigmoid(z)) # dS/dz = S(z)(1-S(z))\n",
    "        # Sigmoid\n",
    "        return 1/(1 + math.e**(-z)) # S(z) = 1/(1 + e^(-z))\n",
    "    \n",
    "    def reLU(self,z,\n",
    "             derivative = False):\n",
    "        \n",
    "        relulist = []\n",
    "        for row in z:\n",
    "            if derivative:\n",
    "                relulist.append([1 if value > 0 else 0 for value in row])\n",
    "            else:\n",
    "                relulist.append([max(0.0,value) for value in row])\n",
    "        return np.array(relulist)\n",
    "        \n",
    "    def softmax(self,Z2):\n",
    "        # SMlist = []\n",
    "        # for k in range(Z2.shape[0]):\n",
    "        #     z2_row = Z2[k]\n",
    "        #     smrow = []\n",
    "        #     for l in range(Z2.shape[1]):\n",
    "        #         denominator = np.sum(math.e**(z2_row))\n",
    "        #         SMz2 = (math.e**z2_row[l])/denominator\n",
    "        #         smrow.append(SMz2)\n",
    "        #     SMlist.append(smrow)\n",
    "        # return np.array(SMlist)\n",
    "        \n",
    "        expZ = np.exp(Z2)\n",
    "        \n",
    "        SM=expZ/np.sum(expZ, axis=1)[:,None]\n",
    "        \n",
    "        return SM \n",
    "\n",
    "    def FeedForward(self,\n",
    "                    activation = \"reLU\",\n",
    "                    verbose = True):\n",
    "        # Create H1\n",
    "        # Z1 = X @ W1 + B\n",
    "        self.Z1 = self.lin_eq(self.X,self.W1,self.B)\n",
    "        if verbose:\n",
    "            print(\"Shape of Z1:\",self.Z1.shape)\n",
    "            print(\"Z1 matrix: \\n\",self.Z1)\n",
    "        self.H1 = self.reLU(self.Z1)\n",
    "        # TODO: Add flexibility with other activation functions\n",
    "        if verbose: \n",
    "            print(\"Activation function:\",activation)\n",
    "            print(\"H1 matrix: \\n\", self.H1)\n",
    "\n",
    "        # Z2 and y-hat\n",
    "        # Z2 = H1 @ W2 + C\n",
    "        self.Z2 = self.lin_eq(self.H1,self.W2,self.C)\n",
    "        self.y_hat = self.softmax(self.Z2)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Shape of Z2:\", self.Z2.shape)\n",
    "            print(\"Z2 matrix: \\n\", self.Z2)\n",
    "            print(\"y_hat:\\n\",self.y_hat)\n",
    "        \n",
    "    \n",
    "    # Gradient descent----------------------------------------------\n",
    "    def grad_desc(self,y_hat,y,LR,\n",
    "                  verbose = True):\n",
    "        \n",
    "        # dL/dZ2  = [y^-y]\n",
    "        self.dL_dZ2 = y_hat - y                                   # shape =  [n x 1]\n",
    "\n",
    "        self.dH_dZ1 = self.reLU(self.Z1,derivative=True)\n",
    "\n",
    "        # dL/dC = [dL/dy^][dy^/dZ2][dZ2/C] \n",
    "        #       = [y^-y][S(Z2)(1 - S(Z2))][1]\n",
    "        self.dZ2_dC = np.array([[1]]*self.C.shape[0])           # vector of 1s with same shape of C\n",
    "        self.dL_dC = self.dL_dZ2 * self.dZ2_dC                            # should match shape of C (n x 1)\n",
    "        # I don't see a good way to make these matrices match the shape of C, \n",
    "        #  so instead I'm going to redefine dL/dC to be a single column vector with the averages \n",
    "        #  of each row from the above calculation\n",
    "        self.dL_dC = np.array([[np.mean(self.dL_dC)]]*self.C.shape[0])\n",
    "\n",
    "        # dL/dW2 = [dL/dy^][dy^/dZ2][dZ2/W2] \n",
    "        #        = [y^-y][S(Z2)(1 - S(Z2))][H1]\n",
    "        self.dL_dW2 =  self.H1.T @ self.dL_dZ2                         # should match shape of W2 \n",
    "\n",
    "        # dL/dB = [dL/dy^][dy^/dZ2][dZ2/dH1][dH1/dZ1][dZ1/dB] \n",
    "        #       = [dL/dZ2][gamma][W2][1]\n",
    "        #       = [y^-y] * ([gamma] @ [W2]) * [1] \n",
    "        \n",
    "        self.Gamma = self.reLU(self.Z1,derivative = True)      # should match shape of Z1 (n x 2)\n",
    "        self.dZ1_dB = np.array([[1]]*self.B.shape[0])           # vector of 1s with same shape of B\n",
    "        \n",
    "        self.dL_dB = self.dL_dZ2 * (self.Gamma @ self.W2)  * self.dZ1_dB        # should match shape of B (n x 1)\n",
    "        # I have the same problem with dL/dB as with dL/dC, so I will do the same thing as did there\n",
    "        #self.dL_dB = np.array([[np.mean(row)] for row in self.dL_dB])\n",
    "        self.dL_dB = np.array([[np.mean(self.dL_dB)]]*self.B.shape[0])\n",
    "        # dL/dW1 = [dL/dy^][dy^/dZ2][dZ2/dH1][dH1/dZ1][dZ1/dW1] \n",
    "        #        = [y^-y][S(Z2)(1 - S(Z2))][W2][S(Z1)(1-S(Z1))][X] \n",
    "        #        = [X]^T @ [([[y^-y] * [S(Z2)(1 - S(Z2))]] @ [W2]) * [S(Z1)(1-S(Z1))]] \n",
    "        #        = [X]^T @ [([E * Phi] * [W2]^T) * Omega]\n",
    "        self.dL_W1 = self.X.T @ (( (self.dL_dZ2) @ self.W2.T) * self.Gamma)    # should match shape of W1 (3 x 2)\n",
    "\n",
    "        # Gradient descent\n",
    "        self.C = self.C - (LR*self.dL_dC)\n",
    "        self.W2 = self.W2 - (LR*self.dL_dW2)\n",
    "        self.B = self.B - (LR*self.dL_dB)\n",
    "        self.W1 = self.W1 - (LR*self.dL_W1)\n",
    "\n",
    "        if verbose:\n",
    "            # print(\"# of X cols (should be # of W1 rows):\", self.X.shape[1])\n",
    "            # print(\"# of hidden units (should be # of W1 cols):\", hidden_units)\n",
    "            print(\"Updated W1 has shape:\", self.W1.shape)\n",
    "            print(\"Updated W1 matrix: \\n\", self.W1)\n",
    "            print(\"Shape of updated B:\", self.B.shape)\n",
    "            print(\"Updated B (bias vector for Z1): \\n\", self.B)\n",
    "            print(\"Shape of updated W2:\",self.W2.shape)\n",
    "            print(\"Updated W2 matrix: \\n\", self.W2)\n",
    "            print(\"Shape of updated  C :\", self.C.shape)\n",
    "            print(\"Updated C (bias vector for Z2): \\n\",self.C)\n",
    "\n",
    "    # Visualizations (confusion matrix & Lce plot)==================\n",
    "    # Confusion matrix-------------------------------------------------------------\n",
    "    def ConfusionMatrix(self, y_hat,y):\n",
    "        self.prediction = y_hat\n",
    "        # self.prediction[y_hat >= .5] = 1\n",
    "        # self.prediction[y_hat < .5] = 0\n",
    "\n",
    "        self.labels = y\n",
    "        \n",
    "        \n",
    "        self.cm = confusion_matrix(self.labels, self.prediction)\n",
    "        print(self.cm)\n",
    "        plt.figure()\n",
    "        ax= plt.subplot()\n",
    "        sns.heatmap(self.cm, annot=True, fmt='g', ax=ax, cmap='Blues')  \n",
    "        #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "        # labels, title and ticks\n",
    "        ax.set_xlabel(\"Predicted labels\")\n",
    "        ax.set_ylabel(\"True labels\")\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "        ax.xaxis.set_ticklabels([\"0\", \"1\"])\n",
    "        ax.yaxis.set_ticklabels([\"0\", \"1\"])\n",
    "    \n",
    "    # Plot of Lce vs. Epochs--------------------------------------------------------\n",
    "    def plot_LCE(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(0,len(self.loss_record)),self.loss_record,'-',label=\"LR = {}\".format(self.LR))\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Loss over epochs\")\n",
    "        plt.legend()\n",
    "\n",
    "    # Run multiple iterations (with specified epochs, etc.)========================================================\n",
    "    def run_model(self, \n",
    "                  epochs,\n",
    "                  LR= 1,\n",
    "                  hidden_units= 4,\n",
    "                  randomize_parameters = False,\n",
    "                  activation = \"sigmoid\", \n",
    "                  verbose = True):\n",
    "        \n",
    "        # Save LCE values (for plotting)------------------------------------\n",
    "        self.loss_record = []\n",
    "        #-------------------------------------------------------------------\n",
    "        self.LR = LR\n",
    "        print(\"Running model for {} epochs...\".format(epochs))\n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch\",i)\n",
    "            self.FeedForward(activation= activation,\n",
    "                             verbose=verbose)\n",
    "            \n",
    "            \n",
    "            self.loss_record.append(self.CCE_loss(y_hat=self.y_hat,\n",
    "                                                  y=self.y))\n",
    "            if verbose:\n",
    "                print(\"Loss:\",self.loss_record[i])\n",
    "\n",
    "            # Update params with gradient descent---------------------------\n",
    "            self.grad_desc(y_hat=self.y_hat,\n",
    "                           y=self.y,\n",
    "                           LR=self.LR,\n",
    "                           verbose=verbose)\n",
    "        print(\"Finished running all epochs\")\n",
    "\n",
    "        # Visualizations\n",
    "        self.ConfusionMatrix(y_hat=self.y_hat,y=self.y)\n",
    "        self.plot_LCE()\n",
    "\n",
    "    def test_model(self,\n",
    "                   test_data,\n",
    "                   verbose = True):\n",
    "        self.test_df = pd.read_csv(test_data)\n",
    "\n",
    "        print(\"X is now input from test data\")\n",
    "        if self.data_scaler is not None:\n",
    "            self.X = self.data_scaler.transform(self.test_df.drop(columns=\"LABEL\",axis=1))\n",
    "            print(\"Test input X was normalized using same normalizer as training ({})\".format(self.data_scaler))\n",
    "        else:\n",
    "            self.X = self.test_df.drop(columns=\"LABEL\",axis=1)\n",
    "\n",
    "        self.y = np.array(self.test_df[['LABEL']])\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Shape of X:\", self.X.shape)\n",
    "            print(\"X matrix: \\n\", self.X)\n",
    "            print(\"Shape of y:\", self.y.shape)\n",
    "            print(\"y vector: \\n\", self.y)\n",
    "\n",
    "        print(\"Testing model with test data\")\n",
    "        self.FeedForward()\n",
    "        print(\"Finished testing model\")\n",
    "\n",
    "        self.ConfusionMatrix(y_hat=self.y_hat,\n",
    "                             y=self.y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X was normalized using StandardScaler()\n",
      "Shape of X: (16, 3)\n",
      "X matrix: \n",
      " [[ 0.92819243 -1.27475541  1.61048338]\n",
      " [ 0.30643674 -0.63663915 -0.75580778]\n",
      " [ 0.46631677  0.56869158 -0.2328705 ]\n",
      " [-1.87859043  1.25407572 -0.88218428]\n",
      " [ 0.87489909 -1.20385361  1.48410687]\n",
      " [ 0.27090784 -0.61300521 -0.55099068]\n",
      " [ 0.50184567  0.68686126  0.06781843]\n",
      " [ 0.96372133 -1.22748754  1.66713492]\n",
      " [ 0.43078788  0.49778977 -0.17186116]\n",
      " [-1.6121237   1.39587933 -0.98677174]\n",
      " [-1.48777256  1.23044178 -0.97369831]\n",
      " [ 0.94595688 -1.34565722  1.78479581]\n",
      " [-1.73647484  1.20680785 -1.03470766]\n",
      " [ 0.32420118 -0.68390702 -0.46383447]\n",
      " [ 0.44855232  0.7104952  -0.0236956 ]\n",
      " [ 0.25314339 -0.56573734 -0.53791725]]\n",
      "Shape of y: (16, 4)\n",
      "y vector: \n",
      " [[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Parameters built for simple calculation (not randomized)\n",
      "W1 has shape: (3, 2)\n",
      "W1 matrix: \n",
      " [[1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "Shape of B: (16, 1)\n",
      "B (bias vector for Z1): \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Shape of W2: (2, 4)\n",
      "W2 matrix: \n",
      " [[2 2 2 2]\n",
      " [2 2 2 2]]\n",
      "Shape of C : (16, 1)\n",
      "C (bias vector for Z2): \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[ 1.2639204   1.2639204 ]\n",
      " [-1.08601019 -1.08601019]\n",
      " [ 0.80213785  0.80213785]\n",
      " [-1.50669899 -1.50669899]\n",
      " [ 1.15515236  1.15515236]\n",
      " [-0.89308805 -0.89308805]\n",
      " [ 1.25652536  1.25652536]\n",
      " [ 1.40336871  1.40336871]\n",
      " [ 0.75671649  0.75671649]\n",
      " [-1.2030161  -1.2030161 ]\n",
      " [-1.23102908 -1.23102908]\n",
      " [ 1.38509547  1.38509547]\n",
      " [-1.56437465 -1.56437465]\n",
      " [-0.8235403  -0.8235403 ]\n",
      " [ 1.13535192  1.13535192]\n",
      " [-0.85051119 -0.85051119]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[1.2639204  1.2639204 ]\n",
      " [0.         0.        ]\n",
      " [0.80213785 0.80213785]\n",
      " [0.         0.        ]\n",
      " [1.15515236 1.15515236]\n",
      " [0.         0.        ]\n",
      " [1.25652536 1.25652536]\n",
      " [1.40336871 1.40336871]\n",
      " [0.75671649 0.75671649]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [1.38509547 1.38509547]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [1.13535192 1.13535192]\n",
      " [0.         0.        ]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[5.05568161 5.05568161 5.05568161 5.05568161]\n",
      " [0.         0.         0.         0.        ]\n",
      " [3.2085514  3.2085514  3.2085514  3.2085514 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [4.62060942 4.62060942 4.62060942 4.62060942]\n",
      " [0.         0.         0.         0.        ]\n",
      " [5.02610143 5.02610143 5.02610143 5.02610143]\n",
      " [5.61347483 5.61347483 5.61347483 5.61347483]\n",
      " [3.02686597 3.02686597 3.02686597 3.02686597]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [5.54038187 5.54038187 5.54038187 5.54038187]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [4.5414077  4.5414077  4.5414077  4.5414077 ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "y_hat:\n",
      " [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[ 3.66116448  4.91796979 -0.28956714 -0.28956714]\n",
      " [ 3.66116448  4.91796979 -0.28956714 -0.28956714]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "NN = OneLayer_MultiOutput()\n",
    "NN.FeedForward()\n",
    "NN.grad_desc(y_hat=NN.y_hat,y=NN.y,LR=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[ 1.2639204   1.2639204 ]\n",
      " [-1.08601019 -1.08601019]\n",
      " [ 0.80213785  0.80213785]\n",
      " [-1.50669899 -1.50669899]\n",
      " [ 1.15515236  1.15515236]\n",
      " [-0.89308805 -0.89308805]\n",
      " [ 1.25652536  1.25652536]\n",
      " [ 1.40336871  1.40336871]\n",
      " [ 0.75671649  0.75671649]\n",
      " [-1.2030161  -1.2030161 ]\n",
      " [-1.23102908 -1.23102908]\n",
      " [ 1.38509547  1.38509547]\n",
      " [-1.56437465 -1.56437465]\n",
      " [-0.8235403  -0.8235403 ]\n",
      " [ 1.13535192  1.13535192]\n",
      " [-0.85051119 -0.85051119]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[1.2639204  1.2639204 ]\n",
      " [0.         0.        ]\n",
      " [0.80213785 0.80213785]\n",
      " [0.         0.        ]\n",
      " [1.15515236 1.15515236]\n",
      " [0.         0.        ]\n",
      " [1.25652536 1.25652536]\n",
      " [1.40336871 1.40336871]\n",
      " [0.75671649 0.75671649]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [1.38509547 1.38509547]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [1.13535192 1.13535192]\n",
      " [0.         0.        ]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[ 9.25484097 12.43184471 -0.73197963 -0.73197963]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 5.87351721  7.88977942 -0.46454552 -0.46454552]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 8.45840556 11.36200879 -0.66898833 -0.66898833]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 9.20069202 12.3591075  -0.7276969  -0.7276969 ]\n",
      " [10.27592734 13.80344983 -0.81273892 -0.81273892]\n",
      " [ 5.5409271   7.44301771 -0.43824046 -0.43824046]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [10.14212466 13.62371533 -0.80215626 -0.80215626]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 8.31342029 11.16725294 -0.65752122 -0.65752122]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "y_hat:\n",
      " [[4.00401954e-02 9.59956121e-01 1.84193843e-06 1.84193843e-06]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [1.17457243e-01 8.82127493e-01 2.07631926e-04 2.07631926e-04]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [5.19751428e-02 9.48013563e-01 5.64701437e-06 5.64701437e-06]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [4.07608004e-02 9.59235224e-01 1.98791669e-06 1.98791669e-06]\n",
      " [2.85391710e-02 9.71459957e-01 4.36209161e-07 4.36209161e-07]\n",
      " [1.29786720e-01 8.69556317e-01 3.28481399e-04 3.28481399e-04]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.98405637e-02 9.70158382e-01 5.26946118e-07 5.26946118e-07]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [5.44827860e-02 9.45503370e-01 6.92195730e-06 6.92195730e-06]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[-0.94991379 -0.94991379]\n",
      " [-2.08197147 -2.08197147]\n",
      " [ 1.69642389  1.69642389]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]\n",
      " [-0.13756248]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[ 7.1143635   1.46564211 -0.29000281 -0.29000281]\n",
      " [ 7.1143635   1.46564211 -0.29000281 -0.29000281]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[ 4.36680162  4.36680162]\n",
      " [-0.38535679 -0.38535679]\n",
      " [-2.15956994 -2.15956994]\n",
      " [-2.4605719  -2.4605719 ]\n",
      " [ 4.05542204  4.05542204]\n",
      " [-0.05335596 -0.05335596]\n",
      " [-1.92924934 -1.92924934]\n",
      " [ 4.3307469   4.3307469 ]\n",
      " [-1.87470729 -1.87470729]\n",
      " [-3.18634805 -3.18634805]\n",
      " [-2.93785657 -2.93785657]\n",
      " [ 4.79325023  4.79325023]\n",
      " [-2.75590338 -2.75590338]\n",
      " [ 0.19148937  0.19148937]\n",
      " [-2.08307701 -2.08307701]\n",
      " [-0.11271355 -0.11271355]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[4.36680162 4.36680162]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [4.05542204 4.05542204]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [4.3307469  4.3307469 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [4.79325023 4.79325023]\n",
      " [0.         0.        ]\n",
      " [0.19148937 0.19148937]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[ 6.21340282e+01  1.28003367e+01 -2.53276944e+00 -2.53276944e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [ 5.77034931e+01  1.18875946e+01 -2.35216754e+00 -2.35216754e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [ 6.16210153e+01  1.26946500e+01 -2.51185750e+00 -2.51185750e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [ 6.82018490e+01  1.40503787e+01 -2.78011203e+00 -2.78011203e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [ 2.72465004e+00  5.61309782e-01 -1.11064912e-01 -1.11064912e-01]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]]\n",
      "y_hat:\n",
      " [[1.00000000e+00 3.75534647e-22 8.23316146e-29 8.23316146e-29]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [1.00000000e+00 1.26592540e-20 8.28243402e-27 8.28243402e-27]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [1.00000000e+00 5.64351310e-22 1.40425904e-28 1.40425904e-28]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [1.00000000e+00 3.03609453e-24 1.48910739e-31 1.48910739e-31]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [8.11494878e-01 9.32736663e-02 4.76157280e-02 4.76157280e-02]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[-23.92340227 -23.92340227]\n",
      " [ 30.67529904  30.67529904]\n",
      " [-32.42009557 -32.42009557]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]\n",
      " [-1.03653892]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[-10.58724993  18.99400198  -0.29912071  -0.10763134]\n",
      " [-10.58724993  18.99400198  -0.29912071  -0.10763134]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]\n",
      " [-3.46944695e-18]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[-114.55758854 -114.55758854]\n",
      " [  -3.39328407   -3.39328407]\n",
      " [  12.80204564   12.80204564]\n",
      " [ 110.97538207  110.97538207]\n",
      " [-107.0105578  -107.0105578 ]\n",
      " [  -8.45852383   -8.45852383]\n",
      " [   5.82859989    5.82859989]\n",
      " [-115.79425281 -115.79425281]\n",
      " [   9.49915468    9.49915468]\n",
      " [ 112.34119493  112.34119493]\n",
      " [ 103.86760435  103.86760435]\n",
      " [-122.80873419 -122.80873419]\n",
      " [ 111.07035987  111.07035987]\n",
      " [ -14.73402884  -14.73402884]\n",
      " [  10.79542944   10.79542944]\n",
      " [  -7.00742359   -7.00742359]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[  0.           0.        ]\n",
      " [  0.           0.        ]\n",
      " [ 12.80204564  12.80204564]\n",
      " [110.97538207 110.97538207]\n",
      " [  0.           0.        ]\n",
      " [  0.           0.        ]\n",
      " [  5.82859989   5.82859989]\n",
      " [  0.           0.        ]\n",
      " [  9.49915468   9.49915468]\n",
      " [112.34119493 112.34119493]\n",
      " [103.86760435 103.86760435]\n",
      " [  0.           0.        ]\n",
      " [111.07035987 111.07035987]\n",
      " [  0.           0.        ]\n",
      " [ 10.79542944  10.79542944]\n",
      " [  0.           0.        ]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-2.71076914e+02  4.86324161e+02 -7.65871400e+00 -2.75580258e+00]\n",
      " [-2.34984821e+03  4.21573325e+03 -6.63900705e+01 -2.38888575e+01]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-1.23417687e+02  2.21416876e+02 -3.48690989e+00 -1.25468000e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-2.01139850e+02  3.60853926e+02 -5.68278781e+00 -2.04481344e+00]\n",
      " [-2.37876862e+03  4.26761776e+03 -6.72071563e+01 -2.41828660e+01]\n",
      " [-2.19934457e+03  3.94572297e+03 -6.21379034e+01 -2.23588182e+01]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-2.35185932e+03  4.21934127e+03 -6.64468902e+01 -2.39093027e+01]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]\n",
      " [-2.28587819e+02  4.10096816e+02 -6.45827307e+00 -2.32385301e+00]\n",
      " [-3.46944695e-18 -3.46944695e-18 -3.46944695e-18 -3.46944695e-18]]\n",
      "y_hat:\n",
      " [[2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [0.00000000e+000 1.00000000e+000 2.92390616e-215 3.93795555e-213]\n",
      " [0.00000000e+000             nan 0.00000000e+000 0.00000000e+000]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [1.73880986e-150 1.00000000e+000 2.11605533e-098 1.97229623e-097]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [8.49580603e-245 1.00000000e+000 6.53322970e-160 2.48359128e-158]\n",
      " [0.00000000e+000             nan 0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000             nan 0.00000000e+000 0.00000000e+000]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [0.00000000e+000             nan 0.00000000e+000 0.00000000e+000]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]\n",
      " [4.19553309e-278 1.00000000e+000 1.23715266e-181 7.72643422e-180]\n",
      " [2.50000000e-001 2.50000000e-001 2.50000000e-001 2.50000000e-001]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[ 2.83379797e+01             nan  4.37955421e+02 -1.07631337e-01]\n",
      " [ 2.83379797e+01             nan  4.37955421e+02 -1.07631337e-01]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of Z1: (16, 2)\n",
      "Z1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Activation function: reLU\n",
      "H1 matrix: \n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "Shape of Z2: (16, 4)\n",
      "Z2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "y_hat:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Updated W1 has shape: (3, 2)\n",
      "Updated W1 matrix: \n",
      " [[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n",
      "Shape of updated B: (16, 1)\n",
      "Updated B (bias vector for Z1): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "Shape of updated W2: (2, 4)\n",
      "Updated W2 matrix: \n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Shape of updated  C : (16, 1)\n",
      "Updated C (bias vector for Z2): \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rokka\\AppData\\Local\\Temp\\ipykernel_3576\\1768068881.py:133: RuntimeWarning: overflow encountered in exp\n",
      "  expZ = np.exp(Z2)\n",
      "C:\\Users\\rokka\\AppData\\Local\\Temp\\ipykernel_3576\\1768068881.py:135: RuntimeWarning: invalid value encountered in divide\n",
      "  SM=expZ/np.sum(expZ, axis=1)[:,None]\n"
     ]
    }
   ],
   "source": [
    "epochs =10\n",
    "for i in range(epochs):\n",
    "    NN.FeedForward()\n",
    "    NN.grad_desc(y_hat=NN.y_hat,y=NN.y,LR=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JK:** For some reason I'm getting `NaN`s when certain amount of epochs for this code.\n",
    "\n",
    "But I'm afraid this is far as I'll have to go. I admittedly did not give myself adequate time to finish this assignment. And I have gotten stuck for several hours on this particular code, and am feeling too sick to try to work through it anymore myself. \n",
    "\n",
    "(I will try my best to get something working by the exam, but as far as this assignment is concerned this is as much as I'm going to have to submit)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
