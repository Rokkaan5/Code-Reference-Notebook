{
  "cells": [
    {
      "cell_type": "raw",
      "id": "2e1eb4f1",
      "metadata": {},
      "source": [
        "---\n",
        "title: TF/Keras with Record dataset\n",
        "author: Professor Ami Gates\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "execute:\n",
        "  output: true\n",
        "toc: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a73cc0d",
      "metadata": {},
      "source": [
        "Gates' full, raw (unedited) code\n",
        "Reference: Professor Ami Gates, Dept. Applied Math, Data Science, University of Colorado\n",
        "\n",
        "[Dr. Gates' Website](https://gatesboltonanalytics.com/?page_id=892)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "700e1950",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "This code uses a simple record dataset with numeric data.\n",
        "\n",
        "- The dataset has 3 columns of data (3 features)\n",
        "- The dataset has labels of 0 and 1.\n",
        "\n",
        "There is a link to the data below. \n",
        "\n",
        "This code uses Keras to build a simple NN to predict the label (called \"Decision\") for this dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f3b5d786",
      "metadata": {},
      "outputs": [],
      "source": [
        "# libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06bbc6c7",
      "metadata": {},
      "source": [
        "# Data\n",
        "\n",
        "## Link to dataset\n",
        "<https://drive.google.com/file/d/1JjkJ4q0MMGJP8jht2ZI9qDEvV5Jjfu0r/view?usp=drive_link>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2051a4d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Decision   GPA  WorkExp  TestScore\n",
            "0         0  3.90      6.7        962\n",
            "1         0  3.80      1.4        969\n",
            "2         0  3.80      2.3        970\n",
            "3         0  3.60      0.9        969\n",
            "4         0  3.92      1.2        969\n"
          ]
        }
      ],
      "source": [
        "## Path to dataset on my computer\n",
        "## YOU will update this path for YOUR computer\n",
        "filepath=\"StudentSummerProgramData_Numeric_2NumLabeled_3Cols.csv\"\n",
        "DF=pd.read_csv(filepath)\n",
        "print(DF.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a8b7507",
      "metadata": {},
      "source": [
        "## Prepare the data\n",
        "\n",
        "This means you need to:\n",
        "\n",
        "- Normalize the data - but NOT the label!\n",
        "- Separate the data into a Training set and a Testing set\n",
        "- Remove and retain the labels for both the Training and Testing datasets.\n",
        "    \n",
        "### Step 1 - Use min-max to normalize the data (but NOT the label!)\n",
        "\n",
        "What are the column names? What column is the label?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e8dd9a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Decision', 'GPA', 'WorkExp', 'TestScore'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(DF.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"Decision\" is the label of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fbf58fb1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Decision       GPA   WorkExp  TestScore\n",
            "0         0  0.981132  0.728261   0.963470\n",
            "1         0  0.918239  0.152174   0.995434\n",
            "2         0  0.918239  0.250000   1.000000\n",
            "3         0  0.792453  0.097826   0.995434\n",
            "4         0  0.993711  0.130435   0.995434\n"
          ]
        }
      ],
      "source": [
        "for col in DF.columns:\n",
        "    #print(col)\n",
        "    if col != \"Decision\":\n",
        "        DF[col]=(DF[col]-DF[col].min())/(DF[col].max()-DF[col].min())\n",
        "        #print(DF[col])\n",
        "\n",
        "print(DF.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dae91b9",
      "metadata": {},
      "source": [
        "### Split DF into Training and Testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1963de59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(44, 4)\n",
            "(19, 4)\n",
            "    Decision       GPA   WorkExp  TestScore\n",
            "47         1  0.415094  0.130435   0.077626\n",
            "35         1  0.767296  0.402174   0.675799\n",
            "52         1  0.402516  0.076087   0.054795\n",
            "6          0  0.968553  0.163043   0.986301\n",
            "7          0  0.855346  0.130435   0.995434\n",
            "37         1  0.861635  0.076087   0.173516\n",
            "26         0  0.981132  0.000000   0.986301\n",
            "50         1  0.754717  0.119565   0.073059\n",
            "56         1  0.616352  0.184783   0.077626\n",
            "14         0  0.855346  0.402174   0.995434\n",
            "8          0  0.981132  0.510870   0.958904\n",
            "27         0  0.761006  0.000000   0.963470\n",
            "42         1  0.295597  1.000000   0.059361\n",
            "29         0  0.830189  0.097826   0.936073\n",
            "57         1  0.421384  0.152174   0.082192\n",
            "62         1  0.547170  0.184783   0.068493\n",
            "41         1  0.943396  0.293478   0.662100\n",
            "59         1  0.358491  0.673913   0.009132\n",
            "45         1  0.622642  0.173913   0.068493\n"
          ]
        }
      ],
      "source": [
        "# Random sampling *without replacement*\n",
        "TrainDF, TestDF = train_test_split(DF, test_size=0.3)\n",
        "print(TrainDF.shape)\n",
        "print(TestDF.shape)\n",
        "print(TestDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13bd25b8",
      "metadata": {},
      "source": [
        "### Drop and SAVE the labels from the TrainDF and TestDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "089a9a60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30    0\n",
            "18    0\n",
            "25    0\n",
            "0     0\n",
            "13    0\n",
            "Name: Decision, dtype: int64\n",
            "47    1\n",
            "35    1\n",
            "52    1\n",
            "6     0\n",
            "7     0\n",
            "Name: Decision, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "TrainLabels=TrainDF[\"Decision\"]\n",
        "print(TrainLabels.head())\n",
        "TestLabels=TestDF[\"Decision\"]\n",
        "print(TestLabels.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2cf3723d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         GPA   WorkExp  TestScore\n",
            "30  0.905660  0.130435   0.990868\n",
            "18  0.729560  0.076087   0.977169\n",
            "25  0.830189  0.239130   0.986301\n",
            "0   0.981132  0.728261   0.963470\n",
            "13  0.849057  0.347826   0.986301\n",
            "(44, 3)\n"
          ]
        }
      ],
      "source": [
        "TrainDF = TrainDF.drop(columns=\"Decision\", axis=1)\n",
        "print(TrainDF.head())\n",
        "print(TrainDF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         GPA   WorkExp  TestScore\n",
            "47  0.415094  0.130435   0.077626\n",
            "35  0.767296  0.402174   0.675799\n",
            "52  0.402516  0.076087   0.054795\n",
            "6   0.968553  0.163043   0.986301\n",
            "7   0.855346  0.130435   0.995434\n"
          ]
        }
      ],
      "source": [
        "TestDF = TestDF.drop(columns=\"Decision\", axis=1)\n",
        "print(TestDF.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32ce84c",
      "metadata": {},
      "source": [
        "# Using Keras\n",
        "\n",
        "## Step 1: Create a TF - Keras NN Model\n",
        "\n",
        "<https://keras.io/guides/sequential_model/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69415fbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "My_NN_Model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(4, input_shape=(3,), activation='relu'), ## Our data is flat and 3D\n",
        "  # (*) See note below\n",
        "  \n",
        "  ## second hidden layer -  with 2 units \n",
        "  tf.keras.layers.Dense(2, activation='relu'),   # (**) referenced link below\n",
        "  ## The first value, 2 here, are the units in the hidden layer. \n",
        "  ## (***) referenced link below\n",
        "  \n",
        "  ##tf.keras.layers.Dropout(0.2),                ## We do not need this here. \n",
        "  tf.keras.layers.Dense(1, activation='sigmoid') ## for 0 or 1\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ebe07a",
      "metadata": {},
      "source": [
        "(\\*) **Note:** Here, we are sending our data to a hidden layer that has 4 hidden units.\n",
        "\n",
        "- `Dense` implements the operation: `output = activation(dot(input, kernel) + bias)`\n",
        "    - The \"`kernel`\" are the weights matrix.\n",
        "- In Keras, the input layer itself is not a layer, but a tensor. \n",
        "    - It's the starting tensor you send to the first hidden layer. \n",
        "    - This tensor must have the same shape as your training data\n",
        "\n",
        "Other relevant links referenced in the above code:\n",
        "- `tf.keras.layers.Dense` \n",
        "    - (\\*\\*) <https://keras.io/api/layers/core_layers/dense/>\n",
        "    - (\\*\\*\\*) <https://www.tutorialspoint.com/keras/keras_dense_layer.htm>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ebad72ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 4)                 16        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29\n",
            "Trainable params: 29\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "My_NN_Model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "40eae2a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first layer weights are: \n",
            " [[-0.5025393  -0.05162388  0.8350564   0.5958649 ]\n",
            " [-0.7560888   0.07614303  0.78565943 -0.0158782 ]\n",
            " [ 0.14354777 -0.4847178  -0.13484716 -0.35753334]]\n",
            "The first layer weights shape is\n",
            " (3, 4)\n",
            "The second layer weights are: \n",
            " [[ 0.60221076  0.8026402 ]\n",
            " [-0.5638485   0.41089344]\n",
            " [ 0.49096894 -0.429451  ]\n",
            " [ 0.1907084  -0.6241598 ]]\n",
            "The third layer weights are: \n",
            " [[-1.2455409]\n",
            " [-1.3225081]]\n"
          ]
        }
      ],
      "source": [
        "## Print the weights\n",
        "first_layer_weights = My_NN_Model.layers[0].get_weights()[0]\n",
        "#first_layer_biases  = My_NN_Model.layers[0].get_weights()[1]\n",
        "second_layer_weights = My_NN_Model.layers[1].get_weights()[0]\n",
        "third_layer_weights = My_NN_Model.layers[2].get_weights()[0]\n",
        "\n",
        "print(\"The first layer weights are: \\n\", first_layer_weights)\n",
        "print(\"The first layer weights shape is\\n\",first_layer_weights.shape )\n",
        "print(\"The second layer weights are: \\n\", second_layer_weights)\n",
        "print(\"The third layer weights are: \\n\", third_layer_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb8d552b",
      "metadata": {},
      "source": [
        "## Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "16d18044",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_function = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "My_NN_Model.compile(\n",
        "                 loss=loss_function,\n",
        "                 metrics=[\"accuracy\"],\n",
        "                 optimizer='adam'\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee20ff1",
      "metadata": {},
      "source": [
        "## Fit the Model \n",
        "\n",
        "Fit the model to the data (train the model).\n",
        "\n",
        "(Making the epochs larger can improve the model and prediction accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e38c7539",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 458ms/step - loss: 0.6407 - accuracy: 0.6364 - val_loss: 0.7859 - val_accuracy: 0.3684\n",
            "Epoch 2/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6400 - accuracy: 0.6364 - val_loss: 0.7859 - val_accuracy: 0.3684\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6395 - accuracy: 0.6364 - val_loss: 0.7863 - val_accuracy: 0.3684\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6388 - accuracy: 0.6364 - val_loss: 0.7867 - val_accuracy: 0.3684\n",
            "Epoch 5/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6383 - accuracy: 0.6364 - val_loss: 0.7873 - val_accuracy: 0.3684\n",
            "Epoch 6/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6376 - accuracy: 0.6364 - val_loss: 0.7878 - val_accuracy: 0.3684\n",
            "Epoch 7/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6370 - accuracy: 0.6364 - val_loss: 0.7885 - val_accuracy: 0.3684\n",
            "Epoch 8/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6363 - accuracy: 0.6364 - val_loss: 0.7893 - val_accuracy: 0.3684\n",
            "Epoch 9/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6357 - accuracy: 0.6364 - val_loss: 0.7903 - val_accuracy: 0.3684\n",
            "Epoch 10/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6352 - accuracy: 0.6364 - val_loss: 0.7914 - val_accuracy: 0.3684\n",
            "Epoch 11/300\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6345 - accuracy: 0.6364 - val_loss: 0.7924 - val_accuracy: 0.3684\n",
            "Epoch 12/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6339 - accuracy: 0.6364 - val_loss: 0.7935 - val_accuracy: 0.3684\n",
            "Epoch 13/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6335 - accuracy: 0.6364 - val_loss: 0.7946 - val_accuracy: 0.3684\n",
            "Epoch 14/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6329 - accuracy: 0.6364 - val_loss: 0.7952 - val_accuracy: 0.3684\n",
            "Epoch 15/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6323 - accuracy: 0.6364 - val_loss: 0.7954 - val_accuracy: 0.3684\n",
            "Epoch 16/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6317 - accuracy: 0.6364 - val_loss: 0.7952 - val_accuracy: 0.3684\n",
            "Epoch 17/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6313 - accuracy: 0.6364 - val_loss: 0.7952 - val_accuracy: 0.3684\n",
            "Epoch 18/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6308 - accuracy: 0.6364 - val_loss: 0.7950 - val_accuracy: 0.3684\n",
            "Epoch 19/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6303 - accuracy: 0.6364 - val_loss: 0.7948 - val_accuracy: 0.3684\n",
            "Epoch 20/300\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6298 - accuracy: 0.6364 - val_loss: 0.7948 - val_accuracy: 0.3684\n",
            "Epoch 21/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6293 - accuracy: 0.6364 - val_loss: 0.7950 - val_accuracy: 0.3684\n",
            "Epoch 22/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6288 - accuracy: 0.6364 - val_loss: 0.7951 - val_accuracy: 0.3684\n",
            "Epoch 23/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6283 - accuracy: 0.6364 - val_loss: 0.7950 - val_accuracy: 0.3684\n",
            "Epoch 24/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6278 - accuracy: 0.6364 - val_loss: 0.7950 - val_accuracy: 0.3684\n",
            "Epoch 25/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6273 - accuracy: 0.6364 - val_loss: 0.7950 - val_accuracy: 0.3684\n",
            "Epoch 26/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6267 - accuracy: 0.6364 - val_loss: 0.7956 - val_accuracy: 0.3684\n",
            "Epoch 27/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6263 - accuracy: 0.6364 - val_loss: 0.7962 - val_accuracy: 0.3684\n",
            "Epoch 28/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6258 - accuracy: 0.6364 - val_loss: 0.7966 - val_accuracy: 0.3684\n",
            "Epoch 29/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6253 - accuracy: 0.6364 - val_loss: 0.7969 - val_accuracy: 0.3684\n",
            "Epoch 30/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6248 - accuracy: 0.6364 - val_loss: 0.7969 - val_accuracy: 0.3684\n",
            "Epoch 31/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6243 - accuracy: 0.6364 - val_loss: 0.7972 - val_accuracy: 0.3684\n",
            "Epoch 32/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6238 - accuracy: 0.6364 - val_loss: 0.7976 - val_accuracy: 0.3684\n",
            "Epoch 33/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6233 - accuracy: 0.6364 - val_loss: 0.7981 - val_accuracy: 0.3684\n",
            "Epoch 34/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6229 - accuracy: 0.6364 - val_loss: 0.7987 - val_accuracy: 0.3684\n",
            "Epoch 35/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6224 - accuracy: 0.6364 - val_loss: 0.7990 - val_accuracy: 0.3684\n",
            "Epoch 36/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6219 - accuracy: 0.6364 - val_loss: 0.7989 - val_accuracy: 0.3684\n",
            "Epoch 37/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6214 - accuracy: 0.6364 - val_loss: 0.7987 - val_accuracy: 0.3684\n",
            "Epoch 38/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6209 - accuracy: 0.6364 - val_loss: 0.7983 - val_accuracy: 0.3684\n",
            "Epoch 39/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6205 - accuracy: 0.6364 - val_loss: 0.7982 - val_accuracy: 0.3684\n",
            "Epoch 40/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6200 - accuracy: 0.6364 - val_loss: 0.7982 - val_accuracy: 0.3684\n",
            "Epoch 41/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6196 - accuracy: 0.6364 - val_loss: 0.7983 - val_accuracy: 0.3684\n",
            "Epoch 42/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6191 - accuracy: 0.6364 - val_loss: 0.7982 - val_accuracy: 0.3684\n",
            "Epoch 43/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6186 - accuracy: 0.6364 - val_loss: 0.7982 - val_accuracy: 0.3684\n",
            "Epoch 44/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6182 - accuracy: 0.6364 - val_loss: 0.7981 - val_accuracy: 0.3684\n",
            "Epoch 45/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6177 - accuracy: 0.6364 - val_loss: 0.7981 - val_accuracy: 0.3684\n",
            "Epoch 46/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6172 - accuracy: 0.6364 - val_loss: 0.7980 - val_accuracy: 0.3684\n",
            "Epoch 47/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6167 - accuracy: 0.6364 - val_loss: 0.7983 - val_accuracy: 0.3684\n",
            "Epoch 48/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6163 - accuracy: 0.6364 - val_loss: 0.7989 - val_accuracy: 0.3684\n",
            "Epoch 49/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6159 - accuracy: 0.6364 - val_loss: 0.7991 - val_accuracy: 0.3684\n",
            "Epoch 50/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6153 - accuracy: 0.6364 - val_loss: 0.7991 - val_accuracy: 0.3684\n",
            "Epoch 51/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6149 - accuracy: 0.6364 - val_loss: 0.7994 - val_accuracy: 0.3684\n",
            "Epoch 52/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6144 - accuracy: 0.6364 - val_loss: 0.7997 - val_accuracy: 0.3684\n",
            "Epoch 53/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6139 - accuracy: 0.6364 - val_loss: 0.8003 - val_accuracy: 0.3684\n",
            "Epoch 54/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6135 - accuracy: 0.6364 - val_loss: 0.8008 - val_accuracy: 0.3684\n",
            "Epoch 55/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6130 - accuracy: 0.6364 - val_loss: 0.8011 - val_accuracy: 0.3684\n",
            "Epoch 56/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6126 - accuracy: 0.6364 - val_loss: 0.8013 - val_accuracy: 0.3684\n",
            "Epoch 57/300\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6121 - accuracy: 0.6364 - val_loss: 0.8010 - val_accuracy: 0.3684\n",
            "Epoch 58/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.6116 - accuracy: 0.6364 - val_loss: 0.8007 - val_accuracy: 0.3684\n",
            "Epoch 59/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6111 - accuracy: 0.6364 - val_loss: 0.8004 - val_accuracy: 0.3684\n",
            "Epoch 60/300\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6107 - accuracy: 0.6364 - val_loss: 0.7999 - val_accuracy: 0.3684\n",
            "Epoch 61/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6102 - accuracy: 0.6364 - val_loss: 0.7994 - val_accuracy: 0.3684\n",
            "Epoch 62/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6097 - accuracy: 0.6364 - val_loss: 0.7986 - val_accuracy: 0.3684\n",
            "Epoch 63/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6093 - accuracy: 0.6364 - val_loss: 0.7976 - val_accuracy: 0.3684\n",
            "Epoch 64/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6088 - accuracy: 0.6364 - val_loss: 0.7966 - val_accuracy: 0.3684\n",
            "Epoch 65/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6084 - accuracy: 0.6364 - val_loss: 0.7958 - val_accuracy: 0.3684\n",
            "Epoch 66/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6079 - accuracy: 0.6364 - val_loss: 0.7954 - val_accuracy: 0.3684\n",
            "Epoch 67/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6074 - accuracy: 0.6364 - val_loss: 0.7952 - val_accuracy: 0.3684\n",
            "Epoch 68/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6070 - accuracy: 0.6364 - val_loss: 0.7951 - val_accuracy: 0.3684\n",
            "Epoch 69/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6065 - accuracy: 0.6364 - val_loss: 0.7949 - val_accuracy: 0.3684\n",
            "Epoch 70/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6060 - accuracy: 0.6364 - val_loss: 0.7949 - val_accuracy: 0.3684\n",
            "Epoch 71/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6055 - accuracy: 0.6364 - val_loss: 0.7949 - val_accuracy: 0.3684\n",
            "Epoch 72/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6051 - accuracy: 0.6364 - val_loss: 0.7948 - val_accuracy: 0.3684\n",
            "Epoch 73/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6046 - accuracy: 0.6364 - val_loss: 0.7945 - val_accuracy: 0.3684\n",
            "Epoch 74/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6041 - accuracy: 0.6364 - val_loss: 0.7941 - val_accuracy: 0.3684\n",
            "Epoch 75/300\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.6036 - accuracy: 0.6364 - val_loss: 0.7934 - val_accuracy: 0.3684\n",
            "Epoch 76/300\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6031 - accuracy: 0.6591 - val_loss: 0.7925 - val_accuracy: 0.3684\n",
            "Epoch 77/300\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.6026 - accuracy: 0.6591 - val_loss: 0.7916 - val_accuracy: 0.3684\n",
            "Epoch 78/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6022 - accuracy: 0.6591 - val_loss: 0.7908 - val_accuracy: 0.3684\n",
            "Epoch 79/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6017 - accuracy: 0.6591 - val_loss: 0.7903 - val_accuracy: 0.3684\n",
            "Epoch 80/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6012 - accuracy: 0.6591 - val_loss: 0.7895 - val_accuracy: 0.3684\n",
            "Epoch 81/300\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.6007 - accuracy: 0.6591 - val_loss: 0.7888 - val_accuracy: 0.3684\n",
            "Epoch 82/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6002 - accuracy: 0.6591 - val_loss: 0.7883 - val_accuracy: 0.3684\n",
            "Epoch 83/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5997 - accuracy: 0.6591 - val_loss: 0.7882 - val_accuracy: 0.3684\n",
            "Epoch 84/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5993 - accuracy: 0.6591 - val_loss: 0.7882 - val_accuracy: 0.3684\n",
            "Epoch 85/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5987 - accuracy: 0.6591 - val_loss: 0.7881 - val_accuracy: 0.3684\n",
            "Epoch 86/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5983 - accuracy: 0.6591 - val_loss: 0.7879 - val_accuracy: 0.3684\n",
            "Epoch 87/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5978 - accuracy: 0.6591 - val_loss: 0.7874 - val_accuracy: 0.3684\n",
            "Epoch 88/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5973 - accuracy: 0.6591 - val_loss: 0.7868 - val_accuracy: 0.3684\n",
            "Epoch 89/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5968 - accuracy: 0.6591 - val_loss: 0.7861 - val_accuracy: 0.3684\n",
            "Epoch 90/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5964 - accuracy: 0.6591 - val_loss: 0.7854 - val_accuracy: 0.3684\n",
            "Epoch 91/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5959 - accuracy: 0.6591 - val_loss: 0.7846 - val_accuracy: 0.3684\n",
            "Epoch 92/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5955 - accuracy: 0.6591 - val_loss: 0.7835 - val_accuracy: 0.3684\n",
            "Epoch 93/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5950 - accuracy: 0.6591 - val_loss: 0.7827 - val_accuracy: 0.3684\n",
            "Epoch 94/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5946 - accuracy: 0.6591 - val_loss: 0.7819 - val_accuracy: 0.3684\n",
            "Epoch 95/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5941 - accuracy: 0.6591 - val_loss: 0.7813 - val_accuracy: 0.3684\n",
            "Epoch 96/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5937 - accuracy: 0.6591 - val_loss: 0.7809 - val_accuracy: 0.3684\n",
            "Epoch 97/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5932 - accuracy: 0.6591 - val_loss: 0.7809 - val_accuracy: 0.3684\n",
            "Epoch 98/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5927 - accuracy: 0.6591 - val_loss: 0.7809 - val_accuracy: 0.3684\n",
            "Epoch 99/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5922 - accuracy: 0.6591 - val_loss: 0.7809 - val_accuracy: 0.3684\n",
            "Epoch 100/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5917 - accuracy: 0.6591 - val_loss: 0.7808 - val_accuracy: 0.3684\n",
            "Epoch 101/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5912 - accuracy: 0.6591 - val_loss: 0.7806 - val_accuracy: 0.3684\n",
            "Epoch 102/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5907 - accuracy: 0.6591 - val_loss: 0.7805 - val_accuracy: 0.3684\n",
            "Epoch 103/300\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5902 - accuracy: 0.6591 - val_loss: 0.7806 - val_accuracy: 0.3684\n",
            "Epoch 104/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5897 - accuracy: 0.6591 - val_loss: 0.7806 - val_accuracy: 0.3684\n",
            "Epoch 105/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5892 - accuracy: 0.6591 - val_loss: 0.7805 - val_accuracy: 0.3684\n",
            "Epoch 106/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5886 - accuracy: 0.6591 - val_loss: 0.7801 - val_accuracy: 0.3684\n",
            "Epoch 107/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5882 - accuracy: 0.6591 - val_loss: 0.7800 - val_accuracy: 0.3684\n",
            "Epoch 108/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5876 - accuracy: 0.6591 - val_loss: 0.7797 - val_accuracy: 0.3684\n",
            "Epoch 109/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5871 - accuracy: 0.6591 - val_loss: 0.7793 - val_accuracy: 0.3684\n",
            "Epoch 110/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5866 - accuracy: 0.6591 - val_loss: 0.7790 - val_accuracy: 0.3684\n",
            "Epoch 111/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5861 - accuracy: 0.6591 - val_loss: 0.7783 - val_accuracy: 0.3684\n",
            "Epoch 112/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5856 - accuracy: 0.6591 - val_loss: 0.7777 - val_accuracy: 0.3684\n",
            "Epoch 113/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5851 - accuracy: 0.6591 - val_loss: 0.7768 - val_accuracy: 0.3684\n",
            "Epoch 114/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5846 - accuracy: 0.6591 - val_loss: 0.7757 - val_accuracy: 0.3684\n",
            "Epoch 115/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5841 - accuracy: 0.6591 - val_loss: 0.7749 - val_accuracy: 0.3684\n",
            "Epoch 116/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5836 - accuracy: 0.6591 - val_loss: 0.7743 - val_accuracy: 0.3684\n",
            "Epoch 117/300\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5831 - accuracy: 0.6591 - val_loss: 0.7742 - val_accuracy: 0.3684\n",
            "Epoch 118/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5826 - accuracy: 0.6591 - val_loss: 0.7740 - val_accuracy: 0.3684\n",
            "Epoch 119/300\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5820 - accuracy: 0.6591 - val_loss: 0.7735 - val_accuracy: 0.3684\n",
            "Epoch 120/300\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.5815 - accuracy: 0.6591 - val_loss: 0.7730 - val_accuracy: 0.3684\n",
            "Epoch 121/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5809 - accuracy: 0.6591 - val_loss: 0.7728 - val_accuracy: 0.3684\n",
            "Epoch 122/300\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5804 - accuracy: 0.6591 - val_loss: 0.7728 - val_accuracy: 0.3684\n",
            "Epoch 123/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5798 - accuracy: 0.6591 - val_loss: 0.7728 - val_accuracy: 0.3684\n",
            "Epoch 124/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5793 - accuracy: 0.6591 - val_loss: 0.7727 - val_accuracy: 0.3684\n",
            "Epoch 125/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5788 - accuracy: 0.6591 - val_loss: 0.7726 - val_accuracy: 0.3684\n",
            "Epoch 126/300\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5782 - accuracy: 0.6591 - val_loss: 0.7721 - val_accuracy: 0.3684\n",
            "Epoch 127/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5776 - accuracy: 0.6591 - val_loss: 0.7714 - val_accuracy: 0.3684\n",
            "Epoch 128/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5771 - accuracy: 0.6591 - val_loss: 0.7707 - val_accuracy: 0.3684\n",
            "Epoch 129/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5765 - accuracy: 0.6591 - val_loss: 0.7703 - val_accuracy: 0.3684\n",
            "Epoch 130/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5761 - accuracy: 0.6591 - val_loss: 0.7700 - val_accuracy: 0.3684\n",
            "Epoch 131/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5754 - accuracy: 0.6591 - val_loss: 0.7694 - val_accuracy: 0.3684\n",
            "Epoch 132/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5749 - accuracy: 0.6591 - val_loss: 0.7689 - val_accuracy: 0.3684\n",
            "Epoch 133/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5743 - accuracy: 0.6591 - val_loss: 0.7682 - val_accuracy: 0.3684\n",
            "Epoch 134/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5738 - accuracy: 0.6591 - val_loss: 0.7672 - val_accuracy: 0.3684\n",
            "Epoch 135/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5733 - accuracy: 0.6591 - val_loss: 0.7662 - val_accuracy: 0.3684\n",
            "Epoch 136/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5727 - accuracy: 0.6591 - val_loss: 0.7655 - val_accuracy: 0.3684\n",
            "Epoch 137/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5721 - accuracy: 0.6591 - val_loss: 0.7651 - val_accuracy: 0.3684\n",
            "Epoch 138/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5716 - accuracy: 0.6591 - val_loss: 0.7650 - val_accuracy: 0.3684\n",
            "Epoch 139/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5710 - accuracy: 0.6591 - val_loss: 0.7646 - val_accuracy: 0.3684\n",
            "Epoch 140/300\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.5704 - accuracy: 0.6591 - val_loss: 0.7643 - val_accuracy: 0.3684\n",
            "Epoch 141/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5698 - accuracy: 0.6591 - val_loss: 0.7641 - val_accuracy: 0.3684\n",
            "Epoch 142/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5692 - accuracy: 0.6591 - val_loss: 0.7640 - val_accuracy: 0.3684\n",
            "Epoch 143/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5686 - accuracy: 0.6591 - val_loss: 0.7642 - val_accuracy: 0.3684\n",
            "Epoch 144/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5679 - accuracy: 0.6591 - val_loss: 0.7643 - val_accuracy: 0.3684\n",
            "Epoch 145/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5674 - accuracy: 0.6591 - val_loss: 0.7644 - val_accuracy: 0.3684\n",
            "Epoch 146/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5667 - accuracy: 0.6591 - val_loss: 0.7644 - val_accuracy: 0.3684\n",
            "Epoch 147/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5661 - accuracy: 0.6591 - val_loss: 0.7644 - val_accuracy: 0.3684\n",
            "Epoch 148/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5655 - accuracy: 0.6591 - val_loss: 0.7645 - val_accuracy: 0.3684\n",
            "Epoch 149/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5649 - accuracy: 0.6591 - val_loss: 0.7646 - val_accuracy: 0.3684\n",
            "Epoch 150/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5644 - accuracy: 0.6591 - val_loss: 0.7647 - val_accuracy: 0.3684\n",
            "Epoch 151/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5637 - accuracy: 0.6591 - val_loss: 0.7644 - val_accuracy: 0.3684\n",
            "Epoch 152/300\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.5631 - accuracy: 0.6591 - val_loss: 0.7641 - val_accuracy: 0.3684\n",
            "Epoch 153/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5625 - accuracy: 0.6591 - val_loss: 0.7637 - val_accuracy: 0.3684\n",
            "Epoch 154/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5619 - accuracy: 0.6591 - val_loss: 0.7633 - val_accuracy: 0.3684\n",
            "Epoch 155/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5612 - accuracy: 0.6591 - val_loss: 0.7631 - val_accuracy: 0.3684\n",
            "Epoch 156/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5606 - accuracy: 0.6591 - val_loss: 0.7629 - val_accuracy: 0.3684\n",
            "Epoch 157/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5600 - accuracy: 0.6591 - val_loss: 0.7626 - val_accuracy: 0.3684\n",
            "Epoch 158/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5594 - accuracy: 0.6591 - val_loss: 0.7626 - val_accuracy: 0.3684\n",
            "Epoch 159/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5588 - accuracy: 0.6591 - val_loss: 0.7625 - val_accuracy: 0.3684\n",
            "Epoch 160/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5581 - accuracy: 0.6591 - val_loss: 0.7623 - val_accuracy: 0.3684\n",
            "Epoch 161/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5575 - accuracy: 0.6591 - val_loss: 0.7624 - val_accuracy: 0.3684\n",
            "Epoch 162/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5568 - accuracy: 0.6591 - val_loss: 0.7628 - val_accuracy: 0.3684\n",
            "Epoch 163/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5562 - accuracy: 0.6591 - val_loss: 0.7631 - val_accuracy: 0.3684\n",
            "Epoch 164/300\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5555 - accuracy: 0.6591 - val_loss: 0.7634 - val_accuracy: 0.3684\n",
            "Epoch 165/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5549 - accuracy: 0.6591 - val_loss: 0.7636 - val_accuracy: 0.3684\n",
            "Epoch 166/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5543 - accuracy: 0.6591 - val_loss: 0.7638 - val_accuracy: 0.3684\n",
            "Epoch 167/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5539 - accuracy: 0.6591 - val_loss: 0.7639 - val_accuracy: 0.3684\n",
            "Epoch 168/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5530 - accuracy: 0.6591 - val_loss: 0.7630 - val_accuracy: 0.3684\n",
            "Epoch 169/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5524 - accuracy: 0.6591 - val_loss: 0.7618 - val_accuracy: 0.3684\n",
            "Epoch 170/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5517 - accuracy: 0.6591 - val_loss: 0.7607 - val_accuracy: 0.3684\n",
            "Epoch 171/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5510 - accuracy: 0.6591 - val_loss: 0.7599 - val_accuracy: 0.3684\n",
            "Epoch 172/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5504 - accuracy: 0.6591 - val_loss: 0.7591 - val_accuracy: 0.3684\n",
            "Epoch 173/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5497 - accuracy: 0.6591 - val_loss: 0.7583 - val_accuracy: 0.3684\n",
            "Epoch 174/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5491 - accuracy: 0.6591 - val_loss: 0.7576 - val_accuracy: 0.3684\n",
            "Epoch 175/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5484 - accuracy: 0.6591 - val_loss: 0.7566 - val_accuracy: 0.3684\n",
            "Epoch 176/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5478 - accuracy: 0.6591 - val_loss: 0.7554 - val_accuracy: 0.3684\n",
            "Epoch 177/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5470 - accuracy: 0.6591 - val_loss: 0.7545 - val_accuracy: 0.3684\n",
            "Epoch 178/300\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5464 - accuracy: 0.6591 - val_loss: 0.7535 - val_accuracy: 0.3684\n",
            "Epoch 179/300\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.5457 - accuracy: 0.6591 - val_loss: 0.7525 - val_accuracy: 0.3684\n",
            "Epoch 180/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5450 - accuracy: 0.6591 - val_loss: 0.7513 - val_accuracy: 0.3684\n",
            "Epoch 181/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5444 - accuracy: 0.6591 - val_loss: 0.7497 - val_accuracy: 0.3684\n",
            "Epoch 182/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5436 - accuracy: 0.6591 - val_loss: 0.7484 - val_accuracy: 0.3684\n",
            "Epoch 183/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5429 - accuracy: 0.6591 - val_loss: 0.7469 - val_accuracy: 0.3684\n",
            "Epoch 184/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5423 - accuracy: 0.6591 - val_loss: 0.7456 - val_accuracy: 0.3684\n",
            "Epoch 185/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5415 - accuracy: 0.6591 - val_loss: 0.7445 - val_accuracy: 0.3684\n",
            "Epoch 186/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5408 - accuracy: 0.6591 - val_loss: 0.7431 - val_accuracy: 0.3684\n",
            "Epoch 187/300\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5401 - accuracy: 0.6591 - val_loss: 0.7414 - val_accuracy: 0.3684\n",
            "Epoch 188/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5395 - accuracy: 0.6591 - val_loss: 0.7395 - val_accuracy: 0.3684\n",
            "Epoch 189/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5389 - accuracy: 0.6591 - val_loss: 0.7379 - val_accuracy: 0.3684\n",
            "Epoch 190/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5381 - accuracy: 0.6591 - val_loss: 0.7368 - val_accuracy: 0.3684\n",
            "Epoch 191/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5375 - accuracy: 0.6591 - val_loss: 0.7356 - val_accuracy: 0.3684\n",
            "Epoch 192/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5368 - accuracy: 0.6591 - val_loss: 0.7346 - val_accuracy: 0.3684\n",
            "Epoch 193/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5361 - accuracy: 0.6591 - val_loss: 0.7338 - val_accuracy: 0.3684\n",
            "Epoch 194/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5353 - accuracy: 0.6591 - val_loss: 0.7334 - val_accuracy: 0.3684\n",
            "Epoch 195/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5346 - accuracy: 0.6591 - val_loss: 0.7334 - val_accuracy: 0.3684\n",
            "Epoch 196/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5339 - accuracy: 0.6591 - val_loss: 0.7333 - val_accuracy: 0.3684\n",
            "Epoch 197/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5331 - accuracy: 0.6591 - val_loss: 0.7329 - val_accuracy: 0.3684\n",
            "Epoch 198/300\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.5324 - accuracy: 0.6591 - val_loss: 0.7326 - val_accuracy: 0.3684\n",
            "Epoch 199/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5317 - accuracy: 0.6591 - val_loss: 0.7325 - val_accuracy: 0.3684\n",
            "Epoch 200/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5309 - accuracy: 0.6591 - val_loss: 0.7327 - val_accuracy: 0.3684\n",
            "Epoch 201/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5301 - accuracy: 0.6591 - val_loss: 0.7328 - val_accuracy: 0.3684\n",
            "Epoch 202/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5294 - accuracy: 0.6591 - val_loss: 0.7332 - val_accuracy: 0.3684\n",
            "Epoch 203/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5286 - accuracy: 0.6591 - val_loss: 0.7337 - val_accuracy: 0.3684\n",
            "Epoch 204/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5279 - accuracy: 0.6591 - val_loss: 0.7339 - val_accuracy: 0.3684\n",
            "Epoch 205/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5272 - accuracy: 0.6591 - val_loss: 0.7339 - val_accuracy: 0.3684\n",
            "Epoch 206/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5264 - accuracy: 0.6591 - val_loss: 0.7333 - val_accuracy: 0.3684\n",
            "Epoch 207/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5257 - accuracy: 0.6591 - val_loss: 0.7325 - val_accuracy: 0.3684\n",
            "Epoch 208/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5249 - accuracy: 0.6591 - val_loss: 0.7321 - val_accuracy: 0.3684\n",
            "Epoch 209/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5241 - accuracy: 0.6591 - val_loss: 0.7317 - val_accuracy: 0.3684\n",
            "Epoch 210/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5234 - accuracy: 0.6591 - val_loss: 0.7313 - val_accuracy: 0.3684\n",
            "Epoch 211/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5226 - accuracy: 0.6591 - val_loss: 0.7308 - val_accuracy: 0.3684\n",
            "Epoch 212/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5219 - accuracy: 0.6591 - val_loss: 0.7302 - val_accuracy: 0.3684\n",
            "Epoch 213/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5211 - accuracy: 0.6591 - val_loss: 0.7299 - val_accuracy: 0.3684\n",
            "Epoch 214/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5203 - accuracy: 0.6591 - val_loss: 0.7296 - val_accuracy: 0.3684\n",
            "Epoch 215/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5196 - accuracy: 0.6591 - val_loss: 0.7293 - val_accuracy: 0.3684\n",
            "Epoch 216/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5188 - accuracy: 0.6591 - val_loss: 0.7289 - val_accuracy: 0.3684\n",
            "Epoch 217/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5180 - accuracy: 0.6591 - val_loss: 0.7286 - val_accuracy: 0.3684\n",
            "Epoch 218/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5172 - accuracy: 0.6591 - val_loss: 0.7284 - val_accuracy: 0.3684\n",
            "Epoch 219/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5165 - accuracy: 0.6591 - val_loss: 0.7281 - val_accuracy: 0.3684\n",
            "Epoch 220/300\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5157 - accuracy: 0.6591 - val_loss: 0.7276 - val_accuracy: 0.3684\n",
            "Epoch 221/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5149 - accuracy: 0.6591 - val_loss: 0.7267 - val_accuracy: 0.3684\n",
            "Epoch 222/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5142 - accuracy: 0.6591 - val_loss: 0.7257 - val_accuracy: 0.3684\n",
            "Epoch 223/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5134 - accuracy: 0.6591 - val_loss: 0.7248 - val_accuracy: 0.3684\n",
            "Epoch 224/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5125 - accuracy: 0.6591 - val_loss: 0.7236 - val_accuracy: 0.3684\n",
            "Epoch 225/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5117 - accuracy: 0.6818 - val_loss: 0.7221 - val_accuracy: 0.3684\n",
            "Epoch 226/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5109 - accuracy: 0.6818 - val_loss: 0.7206 - val_accuracy: 0.3684\n",
            "Epoch 227/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5101 - accuracy: 0.6818 - val_loss: 0.7192 - val_accuracy: 0.3684\n",
            "Epoch 228/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5092 - accuracy: 0.6818 - val_loss: 0.7178 - val_accuracy: 0.3684\n",
            "Epoch 229/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5084 - accuracy: 0.6818 - val_loss: 0.7164 - val_accuracy: 0.3684\n",
            "Epoch 230/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5075 - accuracy: 0.6818 - val_loss: 0.7152 - val_accuracy: 0.3684\n",
            "Epoch 231/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5066 - accuracy: 0.6818 - val_loss: 0.7143 - val_accuracy: 0.3684\n",
            "Epoch 232/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5058 - accuracy: 0.6818 - val_loss: 0.7135 - val_accuracy: 0.3684\n",
            "Epoch 233/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5050 - accuracy: 0.6818 - val_loss: 0.7127 - val_accuracy: 0.3684\n",
            "Epoch 234/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5040 - accuracy: 0.6818 - val_loss: 0.7120 - val_accuracy: 0.3684\n",
            "Epoch 235/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5032 - accuracy: 0.6818 - val_loss: 0.7110 - val_accuracy: 0.4211\n",
            "Epoch 236/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5023 - accuracy: 0.6818 - val_loss: 0.7098 - val_accuracy: 0.4211\n",
            "Epoch 237/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5014 - accuracy: 0.6818 - val_loss: 0.7083 - val_accuracy: 0.4211\n",
            "Epoch 238/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5006 - accuracy: 0.6818 - val_loss: 0.7070 - val_accuracy: 0.4211\n",
            "Epoch 239/300\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.4996 - accuracy: 0.6818 - val_loss: 0.7061 - val_accuracy: 0.4211\n",
            "Epoch 240/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4987 - accuracy: 0.6818 - val_loss: 0.7052 - val_accuracy: 0.4211\n",
            "Epoch 241/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4979 - accuracy: 0.6818 - val_loss: 0.7041 - val_accuracy: 0.4211\n",
            "Epoch 242/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4969 - accuracy: 0.6818 - val_loss: 0.7030 - val_accuracy: 0.4211\n",
            "Epoch 243/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4960 - accuracy: 0.6818 - val_loss: 0.7018 - val_accuracy: 0.4211\n",
            "Epoch 244/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4951 - accuracy: 0.6818 - val_loss: 0.7003 - val_accuracy: 0.4211\n",
            "Epoch 245/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4942 - accuracy: 0.7045 - val_loss: 0.6987 - val_accuracy: 0.4211\n",
            "Epoch 246/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4933 - accuracy: 0.7045 - val_loss: 0.6970 - val_accuracy: 0.4211\n",
            "Epoch 247/300\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4923 - accuracy: 0.7045 - val_loss: 0.6954 - val_accuracy: 0.4211\n",
            "Epoch 248/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4914 - accuracy: 0.7045 - val_loss: 0.6937 - val_accuracy: 0.4211\n",
            "Epoch 249/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4905 - accuracy: 0.7045 - val_loss: 0.6925 - val_accuracy: 0.4211\n",
            "Epoch 250/300\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4895 - accuracy: 0.7045 - val_loss: 0.6917 - val_accuracy: 0.4737\n",
            "Epoch 251/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4885 - accuracy: 0.7045 - val_loss: 0.6911 - val_accuracy: 0.4737\n",
            "Epoch 252/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4876 - accuracy: 0.7045 - val_loss: 0.6903 - val_accuracy: 0.4737\n",
            "Epoch 253/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4867 - accuracy: 0.7045 - val_loss: 0.6895 - val_accuracy: 0.4737\n",
            "Epoch 254/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4858 - accuracy: 0.7045 - val_loss: 0.6888 - val_accuracy: 0.4737\n",
            "Epoch 255/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4848 - accuracy: 0.7045 - val_loss: 0.6882 - val_accuracy: 0.4737\n",
            "Epoch 256/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4839 - accuracy: 0.7045 - val_loss: 0.6871 - val_accuracy: 0.4737\n",
            "Epoch 257/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4829 - accuracy: 0.7045 - val_loss: 0.6857 - val_accuracy: 0.4737\n",
            "Epoch 258/300\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.4820 - accuracy: 0.7045 - val_loss: 0.6846 - val_accuracy: 0.5263\n",
            "Epoch 259/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4810 - accuracy: 0.7045 - val_loss: 0.6840 - val_accuracy: 0.5263\n",
            "Epoch 260/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4800 - accuracy: 0.7045 - val_loss: 0.6835 - val_accuracy: 0.5263\n",
            "Epoch 261/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4791 - accuracy: 0.7045 - val_loss: 0.6828 - val_accuracy: 0.5263\n",
            "Epoch 262/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4781 - accuracy: 0.7045 - val_loss: 0.6822 - val_accuracy: 0.5263\n",
            "Epoch 263/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4772 - accuracy: 0.7045 - val_loss: 0.6817 - val_accuracy: 0.5263\n",
            "Epoch 264/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4762 - accuracy: 0.7045 - val_loss: 0.6809 - val_accuracy: 0.5263\n",
            "Epoch 265/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4752 - accuracy: 0.7045 - val_loss: 0.6797 - val_accuracy: 0.5263\n",
            "Epoch 266/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4742 - accuracy: 0.7045 - val_loss: 0.6784 - val_accuracy: 0.5263\n",
            "Epoch 267/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4732 - accuracy: 0.7045 - val_loss: 0.6769 - val_accuracy: 0.5263\n",
            "Epoch 268/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4722 - accuracy: 0.7045 - val_loss: 0.6748 - val_accuracy: 0.5263\n",
            "Epoch 269/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4712 - accuracy: 0.7045 - val_loss: 0.6730 - val_accuracy: 0.5263\n",
            "Epoch 270/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4701 - accuracy: 0.7045 - val_loss: 0.6716 - val_accuracy: 0.5263\n",
            "Epoch 271/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4691 - accuracy: 0.7045 - val_loss: 0.6701 - val_accuracy: 0.5263\n",
            "Epoch 272/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4681 - accuracy: 0.7045 - val_loss: 0.6681 - val_accuracy: 0.5263\n",
            "Epoch 273/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4671 - accuracy: 0.7045 - val_loss: 0.6663 - val_accuracy: 0.5263\n",
            "Epoch 274/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4660 - accuracy: 0.7045 - val_loss: 0.6649 - val_accuracy: 0.5263\n",
            "Epoch 275/300\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4650 - accuracy: 0.7273 - val_loss: 0.6637 - val_accuracy: 0.5263\n",
            "Epoch 276/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4639 - accuracy: 0.7273 - val_loss: 0.6625 - val_accuracy: 0.5263\n",
            "Epoch 277/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4630 - accuracy: 0.7273 - val_loss: 0.6611 - val_accuracy: 0.5263\n",
            "Epoch 278/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4619 - accuracy: 0.7500 - val_loss: 0.6598 - val_accuracy: 0.5263\n",
            "Epoch 279/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4609 - accuracy: 0.7500 - val_loss: 0.6585 - val_accuracy: 0.5263\n",
            "Epoch 280/300\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.4599 - accuracy: 0.7500 - val_loss: 0.6574 - val_accuracy: 0.5263\n",
            "Epoch 281/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.4589 - accuracy: 0.7727 - val_loss: 0.6564 - val_accuracy: 0.5263\n",
            "Epoch 282/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4579 - accuracy: 0.7727 - val_loss: 0.6555 - val_accuracy: 0.5263\n",
            "Epoch 283/300\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.4569 - accuracy: 0.7727 - val_loss: 0.6545 - val_accuracy: 0.5263\n",
            "Epoch 284/300\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4558 - accuracy: 0.7727 - val_loss: 0.6536 - val_accuracy: 0.5263\n",
            "Epoch 285/300\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.4549 - accuracy: 0.7727 - val_loss: 0.6529 - val_accuracy: 0.5263\n",
            "Epoch 286/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4538 - accuracy: 0.7727 - val_loss: 0.6523 - val_accuracy: 0.5263\n",
            "Epoch 287/300\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4529 - accuracy: 0.7727 - val_loss: 0.6517 - val_accuracy: 0.5263\n",
            "Epoch 288/300\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4519 - accuracy: 0.7727 - val_loss: 0.6508 - val_accuracy: 0.5263\n",
            "Epoch 289/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4509 - accuracy: 0.7727 - val_loss: 0.6496 - val_accuracy: 0.5263\n",
            "Epoch 290/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4499 - accuracy: 0.7727 - val_loss: 0.6485 - val_accuracy: 0.5263\n",
            "Epoch 291/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4488 - accuracy: 0.7727 - val_loss: 0.6477 - val_accuracy: 0.5263\n",
            "Epoch 292/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4479 - accuracy: 0.7727 - val_loss: 0.6469 - val_accuracy: 0.5263\n",
            "Epoch 293/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4468 - accuracy: 0.7727 - val_loss: 0.6458 - val_accuracy: 0.5263\n",
            "Epoch 294/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4458 - accuracy: 0.7727 - val_loss: 0.6443 - val_accuracy: 0.5263\n",
            "Epoch 295/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4447 - accuracy: 0.7727 - val_loss: 0.6429 - val_accuracy: 0.5263\n",
            "Epoch 296/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4438 - accuracy: 0.7727 - val_loss: 0.6412 - val_accuracy: 0.5263\n",
            "Epoch 297/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4427 - accuracy: 0.7727 - val_loss: 0.6399 - val_accuracy: 0.5263\n",
            "Epoch 298/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4417 - accuracy: 0.7727 - val_loss: 0.6391 - val_accuracy: 0.5263\n",
            "Epoch 299/300\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.4407 - accuracy: 0.7727 - val_loss: 0.6384 - val_accuracy: 0.5263\n",
            "Epoch 300/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4397 - accuracy: 0.7727 - val_loss: 0.6374 - val_accuracy: 0.5263\n"
          ]
        }
      ],
      "source": [
        "Hist=My_NN_Model.fit(TrainDF,TrainLabels, epochs=300,  validation_data=(TestDF, TestLabels))\n",
        "## batch_size=   is also an option here for batch training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dc883ddf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x208bbec0eb0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(Hist.history['accuracy'], label='accuracy')\n",
        "plt.plot(Hist.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e257a256",
      "metadata": {},
      "source": [
        "## Test and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "935e640f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6374 - accuracy: 0.5263\n"
          ]
        }
      ],
      "source": [
        "Test_Loss, Test_Accuracy = My_NN_Model.evaluate(TestDF, TestLabels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c14b20",
      "metadata": {},
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b1246da7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Example2_NN_Model\\assets\n"
          ]
        }
      ],
      "source": [
        "My_NN_Model.save(\"Example2_NN_Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14326384",
      "metadata": {},
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fdbd3cda",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 127ms/step\n",
            "[[0.55399185]\n",
            " [0.24952714]\n",
            " [0.5670001 ]\n",
            " [0.1765249 ]\n",
            " [0.21249458]\n",
            " [0.3415211 ]\n",
            " [0.19097081]\n",
            " [0.39869913]\n",
            " [0.4496788 ]\n",
            " [0.18093817]\n",
            " [0.14197691]\n",
            " [0.26657587]\n",
            " [0.45018274]\n",
            " [0.23264357]\n",
            " [0.54624206]\n",
            " [0.483801  ]\n",
            " [0.20716172]\n",
            " [0.49750927]\n",
            " [0.4504492 ]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "predictions=My_NN_Model.predict(TestDF)\n",
        "\n",
        "print(predictions)\n",
        "print(type(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d85dfe0b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ],
      "source": [
        "## For predictions >=.5 --> 1 ; else --> 0\n",
        "predictions[predictions >= .5] = 1\n",
        "predictions[predictions < .5] = 0\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "32d99dd1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The prediction accuracy via confusion matrix is:\n",
            "\n",
            "[[7 9]\n",
            " [0 3]]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"The prediction accuracy via confusion matrix is:\\n\")\n",
        "print(confusion_matrix(predictions, TestLabels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38fa41ef",
      "metadata": {},
      "source": [
        "### Pretty Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e912a664",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7 9]\n",
            " [0 3]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0:Admit'), Text(0, 1.5, '1:Decline')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#from sklearn.metrics import confusion_matrix\n",
        "labels = [0, 1]\n",
        "cm = confusion_matrix(predictions, TestLabels, labels = labels)\n",
        "print(cm)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10)) \n",
        "#ax= plt.subplot()\n",
        "#sns.set(font_scale=3)\n",
        "#sns.set (rc = {'figure.figsize':(40, 40)})\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax, annot_kws={'size': 18})\n",
        "#annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "# annot_kws si size  of font in heatmap\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('True labels') \n",
        "ax.set_ylabel('Predicted labels')\n",
        "ax.set_title('Confusion Matrix: NN') \n",
        "ax.xaxis.set_ticklabels([\"0:Admit\",\"1:Decline\"],rotation=90, fontsize = 18)\n",
        "ax.yaxis.set_ticklabels([\"0:Admit\",\"1:Decline\"],rotation=0, fontsize = 18)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
